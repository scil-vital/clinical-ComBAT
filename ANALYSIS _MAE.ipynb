{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS and UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")\n",
    "\n",
    "import os, math\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "BW_FOLDER = \"BS\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from scripts import combat_info\n",
    "from scripts import combat_quick_apply\n",
    "from scripts import combat_quick_QC\n",
    "from robust_evaluation_tools.robust_utils import get_site, robust_text, rwp_text, get_camcan_file, get_diseases, get_metrics, add_nb_patients_and_diseased\n",
    "from robust_evaluation_tools.robust_harmonization import fit, apply, visualize_harmonization, QC, compare_with_compilation, create_presentation, compare_distances, compare_with_compilation_var\n",
    "from robust_evaluation_tools.synthectic_sites_generations import generate_sites\n",
    "from robust_evaluation_tools.robust_outlier_detection import z_score_detection, flag_sid\n",
    "from robust_evaluation_tools.robust_MLP import predict_malades_MLP\n",
    "\n",
    "MAINFOLDER = \"RESULTS/MAE_TEST\"\n",
    "SYNTHETIC_SITES = f\"{MAINFOLDER}/SYNTHETIC_SITES\"\n",
    "\n",
    "ANALYSIS_FOLDER = f\"{MAINFOLDER}/ANALYSIS\"\n",
    "MAE_PLOT_FOLDER = f\"{ANALYSIS_FOLDER}/MAE_PLOTS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonization_method= \"classic\"\n",
    "SYNTHETIC_SITES_VERSION = \"v1\"\n",
    "\n",
    "metrics = get_metrics()\n",
    "#diseases = get_diseases(True)\n",
    "diseases = [\"ASTMIX\", \"AD\", \"SCHZ\", \"TBI\"]\n",
    "robust_methods = [\"Z_SCORE_MAD\", 'Z_SCORE_IQR',\"IQR\",'MAD','MMS', 'VS','FLIP', 'Z_SCORE', ]\n",
    "#robust_methods = [\"MMS\",\"IQR\",'MAD', 'VS', 'VS2', 'TOP30', 'FLIP']\n",
    "#'Z_SCORE'\n",
    "\n",
    "\n",
    "sample_sizes = [30,100,150]  # Différentes tailles d'échantillon\n",
    "sample_sizes = [100]  # Différentes tailles d'échantillon\n",
    "disease_ratios = [0.03, 0.1, 0.3, 0.5, 0.7, 0.8]   # Différents pourcentages de malades\n",
    "num_tests = 20  # Nombre de tests à effectuer pour chaque combinaison\n",
    "n_jobs=-1\n",
    "\n",
    "# for disease in diseases:\n",
    "#     generate_sites_for_disease(\n",
    "#         disease, SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, sample_sizes, disease_ratios, num_tests, n_jobs\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mae_or_maev_compilations(mainfolder, diseases, sample_sizes, disease_ratios, num_tests, mae_or_maev='mae'):\n",
    "    tests, trains = [], []\n",
    "    for d in diseases:\n",
    "        for s in sample_sizes:\n",
    "            for r in disease_ratios:\n",
    "                for i in range(num_tests):\n",
    "                    base = os.path.join(mainfolder, \"PROCESS\", d, f\"{s}_{int(r*100)}\", str(i))\n",
    "                    test_path  = os.path.join(base, f\"{mae_or_maev}_compilation_test.csv\")\n",
    "                    train_path = os.path.join(base, f\"{mae_or_maev}_compilation_train.csv\")\n",
    "                    if os.path.isfile(test_path):\n",
    "                        tests.append(pd.read_csv(test_path))\n",
    "                    if os.path.isfile(train_path):\n",
    "                        trains.append(pd.read_csv(train_path))\n",
    "    df_test  = pd.concat(tests,  ignore_index=True) if tests  else pd.DataFrame()\n",
    "    df_train = pd.concat(trains, ignore_index=True) if trains else pd.DataFrame()\n",
    "    return df_test, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compilation(mae_or_maev: str,\n",
    "                     split: str,\n",
    "                     *,\n",
    "                     mainfolder: str,\n",
    "                     diseases: list[str],\n",
    "                     sample_sizes: list[int],\n",
    "                     disease_ratios: list[int],\n",
    "                     num_tests: int) -> pd.DataFrame:\n",
    "    if mae_or_maev not in {\"mae\", \"maev\", \"smape\", \"std_mae\"}:\n",
    "        raise ValueError(\"mae_or_maev doit être 'mae' ou 'maev'\")\n",
    "    if split not in {\"test\", \"train\"}:\n",
    "        raise ValueError(\"split doit être 'test' ou 'train'\")\n",
    "\n",
    "    df_test, df_train = load_mae_or_maev_compilations(\n",
    "        mainfolder,\n",
    "        diseases,\n",
    "        sample_sizes,\n",
    "        disease_ratios,\n",
    "        num_tests,\n",
    "        mae_or_maev=mae_or_maev\n",
    "    )\n",
    "    return df_test if split == \"test\" else df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_compilation_train_all = load_compilation(\"mae\", \"train\",\n",
    "                      mainfolder=MAINFOLDER,\n",
    "                      diseases=diseases,\n",
    "                      sample_sizes=sample_sizes,\n",
    "                      disease_ratios=disease_ratios,\n",
    "                      num_tests=num_tests)\n",
    "mae_compilation_test_all = load_compilation(\"mae\", \"test\",\n",
    "                      mainfolder=MAINFOLDER,\n",
    "                      diseases=diseases,\n",
    "                      sample_sizes=sample_sizes,\n",
    "                      disease_ratios=disease_ratios,\n",
    "                      num_tests=num_tests)\n",
    "\n",
    "smape_compilation_train_all = load_compilation(\"smape\", \"train\",\n",
    "                      mainfolder=MAINFOLDER,\n",
    "                      diseases=diseases,\n",
    "                      sample_sizes=sample_sizes,\n",
    "                      disease_ratios=disease_ratios,\n",
    "                      num_tests=num_tests)\n",
    "smape_compilation_test_all = load_compilation(\"smape\", \"test\",\n",
    "                      mainfolder=MAINFOLDER,\n",
    "                      diseases=diseases,\n",
    "                      sample_sizes=sample_sizes,\n",
    "                      disease_ratios=disease_ratios,\n",
    "                      num_tests=num_tests)\n",
    "\n",
    "std_mae_compilation_train_all = load_compilation(\"std_mae\", \"train\",\n",
    "                      mainfolder=MAINFOLDER,\n",
    "                      diseases=diseases,\n",
    "                      sample_sizes=sample_sizes,\n",
    "                      disease_ratios=disease_ratios,\n",
    "                      num_tests=num_tests)\n",
    "std_mae_compilation_test_all = load_compilation(\"std_mae\", \"test\",\n",
    "                      mainfolder=MAINFOLDER,\n",
    "                      diseases=diseases,\n",
    "                      sample_sizes=sample_sizes,\n",
    "                      disease_ratios=disease_ratios,\n",
    "                      num_tests=num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_df_large_en_long(df_large):\n",
    "\n",
    "    context_cols = [\"site\", \"method\", \"robust_method\", \"disease\", \"metric\"]\n",
    "    bundle_cols = [col for col in df_large.columns if col not in context_cols]\n",
    "\n",
    "    df_long = df_large.melt(\n",
    "        id_vars=context_cols,\n",
    "        value_vars=bundle_cols,\n",
    "        var_name=\"bundle\",\n",
    "        value_name=\"mae\"\n",
    "    )\n",
    "    df_long.loc[df_long['robust_method'] == 'No', 'robust_method'] = df_long.loc[df_long['robust_method'] == 'No', 'method']\n",
    "\n",
    "\n",
    "    return df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pivot, methods, eps=1e-7):\n",
    "    \"\"\"\n",
    "    - Cas 1 : HC < NoRobust       (score vers HC)\n",
    "    - Cas 2 : NoRobust < HC       (score vers NoRobust)\n",
    "    - Cas 3 : |HC−No| < eps       (quasi égaux : on regarde +/- %Δ)\n",
    "    \"\"\"\n",
    "    E0, Estar = pivot[\"NoRobust\"], pivot[\"hc\"]\n",
    "\n",
    "    mask_eq   = (Estar - E0).abs() < eps\n",
    "    mask_c1   = (Estar < E0) & ~mask_eq\n",
    "    mask_c2   = (E0 < Estar) & ~mask_eq\n",
    "\n",
    "    rows = []\n",
    "    for m in methods:\n",
    "        Em = pivot[m]\n",
    "\n",
    "        # ---------------- Cas 1 ----------------\n",
    "        s1 = pd.Series(np.nan, index=pivot.index)\n",
    "        d1 = E0 - Estar\n",
    "        s1[mask_c1] = 1 - (Em[mask_c1] - Estar[mask_c1]) / d1[mask_c1]\n",
    "\n",
    "        pos1 = s1[s1 >= 0]\n",
    "        neg1 = s1[s1 < 0]\n",
    "        pct_fail_c1  = len(neg1) / mask_c1.sum() * 100 if mask_c1.any() else np.nan\n",
    "        mean_gain_c1 = pos1.mean()\n",
    "        mean_loss_c1 = neg1.mean()\n",
    "\n",
    "        # ---------------- Cas 2 ----------------\n",
    "        s2 = pd.Series(np.nan, index=pivot.index)\n",
    "        d2 = Estar - E0\n",
    "        s2[mask_c2] = 1 - (Em[mask_c2] - E0[mask_c2]) / d2[mask_c2]\n",
    "\n",
    "        pos2 = s2[s2 >= 0]\n",
    "        neg2 = s2[s2 < 0]\n",
    "        pct_fail_c2  = len(neg2) / mask_c2.sum() * 100 if mask_c2.any() else np.nan\n",
    "        mean_gain_c2 = pos2.mean()\n",
    "        mean_loss_c2 = neg2.mean()\n",
    "\n",
    "        # ---------------- Cas 3 ----------------\n",
    "        delta_eq = (E0 - Em) / E0          # %Δ relatif à NoRobust (≈ HC)\n",
    "        eq_imp   = delta_eq[mask_eq & (delta_eq > 0)]\n",
    "        eq_wors  = delta_eq[mask_eq & (delta_eq < 0)]\n",
    "\n",
    "        pct_eq_imp   = len(eq_imp) / mask_eq.sum() * 100 if mask_eq.any() else np.nan\n",
    "        pct_eq_wors  = len(eq_wors) / mask_eq.sum() * 100 if mask_eq.any() else np.nan\n",
    "        mean_eq_gain = eq_imp.mean()\n",
    "        mean_eq_loss = eq_wors.mean()\n",
    "\n",
    "        # ---------------- Global ----------------\n",
    "        score_total = pd.concat([s1, s2])\n",
    "        score_mean_tot = score_total.mean()\n",
    "\n",
    "        rows.append({\n",
    "            \"method\": m,\n",
    "\n",
    "            # Cas 1\n",
    "            \"%fail_c1\": pct_fail_c1,\n",
    "            \"mean_gain_c1\": mean_gain_c1,\n",
    "            \"mean_loss_c1\": mean_loss_c1,\n",
    "\n",
    "            # Cas 2\n",
    "            \"%fail_c2\": pct_fail_c2,\n",
    "            \"mean_gain_c2\": mean_gain_c2,\n",
    "            \"mean_loss_c2\": mean_loss_c2,\n",
    "\n",
    "            # Cas 3\n",
    "            \"%eq_improve\": pct_eq_imp,\n",
    "            \"mean_eq_gain\": mean_eq_gain,\n",
    "            \"%eq_worsen\": pct_eq_wors,\n",
    "            \"mean_eq_loss\": mean_eq_loss,\n",
    "\n",
    "            # Global\n",
    "            \"score_mean_total\": score_mean_tot\n",
    "        })\n",
    "\n",
    "    summary = pd.DataFrame(rows)\n",
    "\n",
    "    info = pd.Series({\n",
    "        \"Lignes cas1 (%)\": mask_c1.mean()*100,\n",
    "        \"Lignes cas2 (%)\": mask_c2.mean()*100,\n",
    "        \"Lignes cas3 (%)\": mask_eq.mean()*100,\n",
    "        \"Total lignes\": len(pivot)\n",
    "    })\n",
    "\n",
    "    return summary, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mae_mean_all_ratios(\n",
    "        pivot_df, sample_size,\n",
    "        directory, dataset_type, Y=\"MAE\"):\n",
    "    \"\"\"\n",
    "    Moyenne du MAE pour chaque méthode en combinant:\n",
    "      • toutes les maladies\n",
    "      • toutes les métriques\n",
    "      • toutes les valeurs de disease_ratio\n",
    "    On filtre uniquement par num_patients et on trace une barre par méthode.\n",
    "    \"\"\"\n",
    "    # 1) Filtre uniquement sur le nombre de patients\n",
    "    df_filt = pivot_df.loc[\n",
    "        pivot_df.index.get_level_values(\"num_patients\") == sample_size\n",
    "    ].reset_index()\n",
    "\n",
    "    # 2) Colonnes de méthodes (numériques)\n",
    "    mae_cols = [c for c in df_filt.columns if c not in\n",
    "                ['site','disease','metric','bundle',\n",
    "                 'num_patients','disease_ratio','num_diseased']]\n",
    "\n",
    "    # 3) Ordre et couleurs\n",
    "    ordered_cols = [c for c in ['hc', 'NoRobust'] if c in mae_cols]\n",
    "    ordered_cols += [c for c in mae_cols if c not in ordered_cols]\n",
    "\n",
    "    col_colors = {'hc': 'green', 'NoRobust': 'red'}\n",
    "    remaining = [c for c in ordered_cols if c not in col_colors]\n",
    "    col_colors.update(dict(zip(remaining,\n",
    "                               sns.color_palette(\"viridis\", len(remaining)))))\n",
    "\n",
    "    # 4) Moyenne globale pour chaque méthode\n",
    "    means = [df_filt[col].dropna().mean() for col in ordered_cols]\n",
    "\n",
    "    x = np.arange(len(ordered_cols))\n",
    "    bar_w = 0.7\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(\n",
    "        x, means,\n",
    "        width=bar_w,\n",
    "        color=[col_colors[c] for c in ordered_cols],\n",
    "        edgecolor='black'\n",
    "    )\n",
    "\n",
    "    # 5) Mise en forme\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(ordered_cols, rotation=45, ha='right')\n",
    "    ax.set_ylabel(f\"Moyenne de {Y}\")\n",
    "    ax.set_title(\n",
    "        f\"Moyenne de {Y} - toutes maladies, métriques et ratios confondus\\n\"\n",
    "        f\"Nb patients: {sample_size}   |   Dataset: {dataset_type}\"\n",
    "    )\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 6) Sauvegarde\n",
    "    out_dir = os.path.join(directory, f\"{Y}_PLOTS_MEAN\",\n",
    "                           \"ALL_DISEASES_ALL_METRICS_ALL_RATIOS\",\n",
    "                           str(sample_size))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    fname = f\"{Y}_mean_all_ratios_{dataset_type}.png\"\n",
    "    plt.savefig(os.path.join(out_dir, fname), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mae_mean_all_diseases_metrics(\n",
    "        pivot_df, sample_size,\n",
    "        directory, dataset_type, Y=\"MAE\"):\n",
    "    \"\"\"\n",
    "    Affiche la moyenne du MAE (pas d’écart‑type) pour chaque méthode\n",
    "    en fonction de disease_ratio, en combinant:\n",
    "        • toutes les maladies\n",
    "        • toutes les métriques\n",
    "        • tous les bundles\n",
    "    \"\"\"\n",
    "    # 1) Filtre: seulement le nombre de patients\n",
    "    df_filt = pivot_df.loc[\n",
    "        pivot_df.index.get_level_values(\"num_patients\") == sample_size\n",
    "    ].reset_index()\n",
    "\n",
    "    # 2) Colonnes de méthodes (numériques)\n",
    "    mae_cols = [c for c in df_filt.columns if c not in\n",
    "                ['site','disease','metric','bundle',\n",
    "                 'num_patients','disease_ratio','num_diseased']]\n",
    "\n",
    "    # 3) Ordre + couleurs\n",
    "    ordered_cols = [c for c in ['hc', 'NoRobust'] if c in mae_cols]\n",
    "    ordered_cols += [c for c in mae_cols if c not in ordered_cols]\n",
    "\n",
    "    col_colors = {'hc': 'green', 'NoRobust': 'red'}\n",
    "    remaining = [c for c in ordered_cols if c not in col_colors]\n",
    "    col_colors.update(dict(zip(remaining,\n",
    "                               sns.color_palette(\"viridis\", len(remaining)))))\n",
    "\n",
    "    # 4) X‑ticks (ratios)\n",
    "    ratios = sorted(df_filt[\"disease_ratio\"].unique())\n",
    "    x = np.arange(len(ratios))\n",
    "    g_width   = .8\n",
    "    n_methods = len(ordered_cols)\n",
    "    bar_w     = g_width / n_methods\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    for i_m, col in enumerate(ordered_cols):\n",
    "        means = [\n",
    "            df_filt[df_filt[\"disease_ratio\"] == r][col].dropna().mean()\n",
    "            for r in ratios\n",
    "        ]\n",
    "\n",
    "        pos = x - g_width / 2 + (i_m + .5) * bar_w\n",
    "        ax.bar(\n",
    "            pos, means,\n",
    "            width=bar_w * .9,\n",
    "            color=col_colors[col],\n",
    "            edgecolor='black',\n",
    "            label=col\n",
    "        )\n",
    "\n",
    "    # 5) Mise en forme\n",
    "    ax.set_xlabel(\"Pourcentage de patients malades\")\n",
    "    ax.set_ylabel(f\"Moyenne de {Y}\")\n",
    "    ax.set_title(\n",
    "        f\"Moyenne de {Y} (toutes maladies et métriques confondues)\\n\"\n",
    "        f\"Nb patients : {sample_size}   |   Dataset : {dataset_type}\"\n",
    "    )\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(ratios)\n",
    "    ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 6) Sauvegarde\n",
    "    out_dir = os.path.join(directory, f\"{Y}_PLOTS_MEAN\",\n",
    "                           f\"ALL_DISEASES_ALL_METRICS\", str(sample_size))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    fname = f\"{Y}_mean_all_diseases_metrics_{dataset_type}.png\"\n",
    "    plt.savefig(os.path.join(out_dir, fname), bbox_inches=\"tight\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_rank(\n",
    "        pivot_df, sample_size, disease, metric,\n",
    "        directory, dataset_type, Y=\"MAE\"):\n",
    "    \"\"\"\n",
    "    Trace, pour chaque méthode, la moyenne du MAE\n",
    "    en fonction de disease_ratio, tous bundles confondus.\n",
    "    \"\"\"\n",
    "    # 1) Filtre\n",
    "    df_filt = pivot_df.loc[\n",
    "        (pivot_df.index.get_level_values(\"num_patients\") == sample_size) &\n",
    "        (pivot_df.index.get_level_values(\"disease\")      == disease) &\n",
    "        (pivot_df.index.get_level_values(\"metric\")       == metric)\n",
    "    ].reset_index()\n",
    "\n",
    "    # 2) Colonnes de méthodes\n",
    "    mae_cols = [c for c in df_filt.columns if c not in\n",
    "                ['site','disease','metric','bundle',\n",
    "                 'num_patients','disease_ratio','num_diseased']]\n",
    "\n",
    "    # 3) Ordre + couleurs\n",
    "    ordered_cols = [c for c in ['hc', 'NoRobust'] if c in mae_cols]\n",
    "    ordered_cols += [c for c in mae_cols if c not in ordered_cols]\n",
    "\n",
    "    col_colors = {'hc': 'green', 'NoRobust': 'red'}\n",
    "    remaining = [c for c in ordered_cols if c not in col_colors]\n",
    "    col_colors.update(dict(zip(remaining,\n",
    "                               sns.color_palette(\"viridis\", len(remaining)))))\n",
    "\n",
    "    # 4) Préparation des x‑ticks\n",
    "    ratios = sorted(df_filt[\"disease_ratio\"].unique())\n",
    "    x = np.arange(len(ratios))\n",
    "    g_width   = .8\n",
    "    n_methods = len(ordered_cols)\n",
    "    bar_w     = g_width / n_methods\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    for i_m, col in enumerate(ordered_cols):\n",
    "        means = [\n",
    "            df_filt[df_filt[\"disease_ratio\"] == r][col].dropna().mean()\n",
    "            for r in ratios\n",
    "        ]\n",
    "\n",
    "        pos = x - g_width / 2 + (i_m + .5) * bar_w\n",
    "        ax.bar(\n",
    "            pos, means,\n",
    "            width=bar_w * .9,\n",
    "            color=col_colors[col],\n",
    "            edgecolor='black',\n",
    "            label=col\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Pourcentage de patients malades\")\n",
    "    ax.set_ylabel(f\"Moyenne de {Y}\")\n",
    "    ax.set_title(\n",
    "        f\"Moyenne de {Y}, tous bundles confondus\\n\"\n",
    "        f\"Maladie : {disease}   |   Metric : {metric}\\n\"\n",
    "        f\"Nb patients : {sample_size}   |   Dataset : {dataset_type}\"\n",
    "    )\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(ratios)\n",
    "\n",
    "    ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.tight_layout()\n",
    "    out_dir = os.path.join(directory, f\"{Y}_PLOTS_MEAN\", disease,\n",
    "                           str(sample_size))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    fname = f\"{Y}_{metric}_mean_{dataset_type}.png\"\n",
    "    plt.savefig(os.path.join(out_dir, fname), bbox_inches=\"tight\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rank_all_metrics(\n",
    "        pivot_df, sample_size, disease,\n",
    "        directory, dataset_type, Y=\"MAE\"):\n",
    "    \"\"\"\n",
    "    Même logique que plot_mae_all_bundles_mean,\n",
    "    mais on agrège TOUTES les métriques (T1, FA, etc.) d’un coup.\n",
    "    \"\"\"\n",
    "    # 1) Filtre (pas de métrique cette fois)\n",
    "    df_filt = pivot_df.loc[\n",
    "        (pivot_df.index.get_level_values(\"num_patients\") == sample_size) &\n",
    "        (pivot_df.index.get_level_values(\"disease\")      == disease)\n",
    "    ].reset_index()\n",
    "\n",
    "    # 2) Colonnes de méthodes\n",
    "    mae_cols = [c for c in df_filt.columns if c not in\n",
    "                ['site','disease','metric','bundle',\n",
    "                 'num_patients','disease_ratio','num_diseased']]\n",
    "\n",
    "    # 3) Ordre + couleurs\n",
    "    ordered_cols = [c for c in ['hc', 'NoRobust'] if c in mae_cols]\n",
    "    ordered_cols += [c for c in mae_cols if c not in ordered_cols]\n",
    "\n",
    "    col_colors = {'hc': 'green', 'NoRobust': 'red'}\n",
    "    remaining = [c for c in ordered_cols if c not in col_colors]\n",
    "    col_colors.update(dict(zip(remaining,\n",
    "                               sns.color_palette(\"viridis\", len(remaining)))))\n",
    "\n",
    "    # 4) X‑ticks (ratios)\n",
    "    ratios = sorted(df_filt[\"disease_ratio\"].unique())\n",
    "    x = np.arange(len(ratios))\n",
    "    g_width   = .8\n",
    "    n_methods = len(ordered_cols)\n",
    "    bar_w     = g_width / n_methods\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    for i_m, col in enumerate(ordered_cols):\n",
    "        means = [\n",
    "            df_filt[df_filt[\"disease_ratio\"] == r][col].dropna().mean()\n",
    "            for r in ratios\n",
    "        ]\n",
    "\n",
    "        pos = x - g_width / 2 + (i_m + .5) * bar_w\n",
    "        ax.bar(\n",
    "            pos, means,\n",
    "            width=bar_w * .9,\n",
    "            color=col_colors[col],\n",
    "            edgecolor='black',\n",
    "            label=col\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Pourcentage de patients malades\")\n",
    "    ax.set_ylabel(f\"Moyenne de {Y} (toutes métriques)\")\n",
    "    ax.set_title(\n",
    "        f\"Moyenne de {Y}, tous bundles et métriques confondus\\n\"\n",
    "        f\"Maladie : {disease}   |   Nb patients : {sample_size}   |   Dataset : {dataset_type}\"\n",
    "    )\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(ratios)\n",
    "\n",
    "    ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.tight_layout()\n",
    "    out_dir = os.path.join(directory, f\"{Y}_PLOTS_MEAN\", disease,\n",
    "                           str(sample_size))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    fname = f\"{Y}_all_metrics_mean_{dataset_type}.png\"\n",
    "    plt.savefig(os.path.join(out_dir, fname), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mae_all_bundles_pivot(\n",
    "        pivot_df, sample_size, disease, metric,\n",
    "        directory, dataset_type, Y=\"MAE\", bundle=None,\n",
    "    ):\n",
    "    # Construit la condition de filtre principale\n",
    "    cond = (\n",
    "        (pivot_df.index.get_level_values(\"num_patients\") == sample_size) &\n",
    "        (pivot_df.index.get_level_values(\"disease\")      == disease) &\n",
    "        (pivot_df.index.get_level_values(\"metric\")       == metric)\n",
    "    )\n",
    "\n",
    "    # Ajoute le filtre bundle si demandé\n",
    "    if bundle is not None:\n",
    "        if isinstance(bundle, (list, tuple, set)):\n",
    "            cond &= pivot_df.index.get_level_values(\"bundle\").isin(bundle)\n",
    "        else:\n",
    "            cond &= pivot_df.index.get_level_values(\"bundle\") == bundle\n",
    "\n",
    "    df_filt = pivot_df.loc[cond].reset_index()\n",
    "\n",
    "    # Colonnes MAE (toutes les numériques)\n",
    "    mae_cols = [c for c in df_filt.columns if c not in\n",
    "                ['site','disease','metric','bundle',\n",
    "                 'num_patients','disease_ratio','num_diseased']]\n",
    "\n",
    "    # Forcer l’ordre désiré\n",
    "    ordered_cols = [col for col in ['hc', 'NoRobust'] if col in mae_cols]\n",
    "    ordered_cols += [c for c in mae_cols if c not in ordered_cols]\n",
    "\n",
    "    # Couleurs\n",
    "    col_colors = {}\n",
    "    if 'hc' in ordered_cols:\n",
    "        col_colors['hc'] = 'green'\n",
    "    if 'NoRobust' in ordered_cols:\n",
    "        col_colors['NoRobust'] = 'red'\n",
    "\n",
    "    remaining = [c for c in ordered_cols if c not in col_colors]\n",
    "    pal = sns.color_palette(\"viridis\", len(remaining))\n",
    "    col_colors.update(dict(zip(remaining, pal)))\n",
    "\n",
    "    # Préparation des x‑ticks\n",
    "    ratios = sorted(df_filt[\"disease_ratio\"].unique())\n",
    "    x = np.arange(len(ratios))\n",
    "    g_width = .8\n",
    "    n_methods = len(ordered_cols)\n",
    "    box_w = g_width / n_methods\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    for i_m, col in enumerate(ordered_cols):\n",
    "        data = [\n",
    "            df_filt[df_filt[\"disease_ratio\"] == r][col].dropna().values\n",
    "            for r in ratios\n",
    "        ]\n",
    "        if not any(len(d) for d in data):\n",
    "            continue\n",
    "\n",
    "        pos = x - g_width / 2 + (i_m + .5) * box_w\n",
    "        ax.boxplot(\n",
    "            data,\n",
    "            positions=pos,\n",
    "            widths=box_w * .8,\n",
    "            patch_artist=True,\n",
    "            showfliers=False,\n",
    "            boxprops=dict(facecolor=col_colors[col],\n",
    "                          edgecolor=col_colors[col]),\n",
    "            medianprops=dict(color='black')\n",
    "        )\n",
    "\n",
    "    # Libellés et titre\n",
    "    ax.set_xlabel(\"Pourcentage de patients malades\")\n",
    "    ax.set_ylabel(Y)\n",
    "    bundle_str = \", \".join(bundle) if isinstance(bundle, (list, tuple, set)) else bundle\n",
    "    ax.set_title(\n",
    "        f\"{Y} d’harmonisation\"\n",
    "        + (f\", bundle : {bundle_str}\" if bundle is not None else \", tous bundles confondus\")\n",
    "        + f\"\\nMaladie : {disease}   |   Metric : {metric}\"\n",
    "        + f\"\\nNb patients : {sample_size}   |   Dataset : {dataset_type}\"\n",
    "    )\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(ratios)\n",
    "\n",
    "    handles = [plt.Line2D([0], [0], color=col_colors[c], lw=3, label=c)\n",
    "               for c in ordered_cols]\n",
    "    ax.legend(handles=handles, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Dossier et nom de fichier\n",
    "    out_dir = os.path.join(directory, f\"{Y}_PLOTS_NEW\", disease, str(sample_size))\n",
    "    if bundle is not None:\n",
    "        out_dir = os.path.join(out_dir,metric)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    bundle_suffix = bundle_str.replace(\" \", \"_\") if bundle is not None else \"all_bundles\"\n",
    "    plt.savefig(os.path.join(out_dir, f\"{Y}_{metric}_{bundle_suffix}_boxplot_{dataset_type}.png\"),\n",
    "                bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mae_each_bundle(\n",
    "        pivot_df, sample_size, disease, metric,\n",
    "        directory, dataset_type, Y=\"MAE\",\n",
    "    ):\n",
    "    # Liste des bundles présents pour le cas demandé\n",
    "    bundles = pivot_df.loc[\n",
    "        (pivot_df.index.get_level_values(\"num_patients\") == sample_size) &\n",
    "        (pivot_df.index.get_level_values(\"disease\")      == disease) &\n",
    "        (pivot_df.index.get_level_values(\"metric\")       == metric)\n",
    "    ].index.get_level_values(\"bundle\").unique()\n",
    "\n",
    "    for b in bundles:\n",
    "        plot_mae_all_bundles_pivot(\n",
    "            pivot_df, sample_size, disease, metric,\n",
    "            directory, dataset_type, Y=Y, bundle=b,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_mae_all_bundles_pivot_3_way(\n",
    "        pivot_df, sample_size, disease, metric,\n",
    "        directory, dataset_type, Y=\"MAE\"):\n",
    "    # 1) Filtre de base\n",
    "    df_filt = pivot_df.loc[\n",
    "        (pivot_df.index.get_level_values(\"num_patients\") == sample_size) &\n",
    "        (pivot_df.index.get_level_values(\"disease\")      == disease) &\n",
    "        (pivot_df.index.get_level_values(\"metric\")       == metric)\n",
    "    ].reset_index()\n",
    "\n",
    "    # 2) Colonnes numériques\n",
    "    mae_cols = [c for c in df_filt.columns if c not in\n",
    "                ['site','disease','metric','bundle',\n",
    "                 'num_patients','disease_ratio','num_diseased']]\n",
    "\n",
    "    # 3) Ordre + couleurs\n",
    "    ordered_cols = [c for c in ['hc', 'NoRobust'] if c in mae_cols]\n",
    "    ordered_cols += [c for c in mae_cols if c not in ordered_cols]\n",
    "\n",
    "    col_colors = {'hc': 'green', 'NoRobust': 'red'}\n",
    "    remaining = [c for c in ordered_cols if c not in col_colors]\n",
    "    col_colors.update(dict(zip(remaining,\n",
    "                               sns.color_palette(\"viridis\", len(remaining)))))\n",
    "\n",
    "    # 4) Classement des lignes\n",
    "    df_filt['hc_vs_no'] = np.select(\n",
    "        [\n",
    "            df_filt['hc'] > df_filt['NoRobust'],\n",
    "            np.isclose(df_filt['hc'], df_filt['NoRobust'])\n",
    "        ],\n",
    "        ['hc_greater', 'hc_equal'],\n",
    "        default='hc_smaller'\n",
    "    )\n",
    "\n",
    "    # 5) Pourcentages\n",
    "    pct_map = (df_filt['hc_vs_no']\n",
    "               .value_counts(normalize=True)\n",
    "               .mul(100).round(1)\n",
    "               .to_dict())\n",
    "\n",
    "    label_map = {\n",
    "        'hc_greater': 'HC > NoRobust',\n",
    "        'hc_equal'  : 'HC = NoRobust',\n",
    "        'hc_smaller': 'HC < NoRobust'\n",
    "    }\n",
    "\n",
    "    groups = ['hc_smaller', 'hc_equal', 'hc_greater']  # ordre voulu\n",
    "    titles = [f\"{label_map[g]} ({pct_map.get(g, 0.0):.1f} %)\" for g in groups]\n",
    "\n",
    "    # 6) Ratios globaux pour garantir le même axe x partout\n",
    "    ratios_all = sorted(df_filt[\"disease_ratio\"].unique())\n",
    "    x = np.arange(len(ratios_all))\n",
    "    g_width   = .8\n",
    "    n_methods = len(ordered_cols)\n",
    "    box_w     = g_width / n_methods\n",
    "\n",
    "    # 7) Sous‑plots\n",
    "    fig, axes = plt.subplots(nrows=3, sharex=True, figsize=(14, 18))\n",
    "\n",
    "    for ax, grp, grp_title in zip(axes, groups, titles):\n",
    "        sub = df_filt[df_filt['hc_vs_no'] == grp]\n",
    "\n",
    "        # Trace chaque méthode\n",
    "        for i_m, col in enumerate(ordered_cols):\n",
    "            # données pour tous les ratios, même si vides\n",
    "            data = [\n",
    "                sub[sub[\"disease_ratio\"] == r][col].dropna().values\n",
    "                for r in ratios_all\n",
    "            ]\n",
    "            if not any(len(d) for d in data):\n",
    "                continue  # rien à tracer pour cette méthode\n",
    "\n",
    "            pos = x - g_width / 2 + (i_m + .5) * box_w\n",
    "            ax.boxplot(\n",
    "                data,\n",
    "                positions=pos,\n",
    "                widths=box_w * .8,\n",
    "                patch_artist=True,\n",
    "                showfliers=False,\n",
    "                boxprops=dict(facecolor=col_colors[col],\n",
    "                              edgecolor=col_colors[col]),\n",
    "                medianprops=dict(color='black')\n",
    "            )\n",
    "\n",
    "        # Ligne zéro et mise en forme\n",
    "        ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "        ax.set_ylabel(Y)\n",
    "        ax.set_title(grp_title, loc='left', fontsize=12)\n",
    "\n",
    "        # Axe x identique partout\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(ratios_all)\n",
    "        ax.set_xlabel(\"Pourcentage de patients malades\")\n",
    "        ax.tick_params(axis='x', labelbottom=True)\n",
    "\n",
    "        # Légende seulement sur le premier subplot\n",
    "        if grp == groups[0]:\n",
    "            handles = [plt.Line2D([0], [0], color=col_colors[c], lw=3, label=c)\n",
    "                       for c in ordered_cols]\n",
    "            ax.legend(handles=handles, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "        # Assure une même largeur de grille pour chaque axe\n",
    "        ax.set_xlim(x[0] - 0.5, x[-1] + 0.5)\n",
    "\n",
    "    # 8) Titre général\n",
    "    fig.suptitle(\n",
    "        f\"{Y} d’harmonisation, tous bundles confondus\\n\"\n",
    "        f\"Maladie: {disease} | Metric: {metric}\\n\"\n",
    "        f\"Nb patients: {sample_size} | Dataset: {dataset_type}\",\n",
    "        fontsize=14\n",
    "    )\n",
    "\n",
    "    # 9) Sauvegarde\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    out_dir = os.path.join(directory, f\"{Y}_PLOTS_NEW\", disease,\n",
    "                           str(sample_size))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    fname = f\"{Y}_{metric}_all_bundles_boxplot_split_{dataset_type}_3_way.png\"\n",
    "    plt.savefig(os.path.join(out_dir, fname), bbox_inches=\"tight\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_methods_per_row(pivot_df):\n",
    "    \"\"\"\n",
    "    Retourne un DataFrame des mêmes dimensions que pivot_df\n",
    "    où chaque cellule contient le rang (1 = meilleur, N = pire)\n",
    "    calculé ligne par ligne.\n",
    "\n",
    "    Les colonnes non numériques (s’il y en a) sont ignorées.\n",
    "    \"\"\"\n",
    "    # On ne garde que les colonnes numériques (les méthodes)\n",
    "    method_cols = pivot_df.select_dtypes(include='number').columns\n",
    "\n",
    "    # Ranking ligne par ligne\n",
    "    rank_df = (pivot_df[method_cols]\n",
    "               .rank(axis=1, method='min', ascending=True)  # 1 = plus petit\n",
    "               .astype(int))\n",
    "\n",
    "    # Si tu veux conserver l’index multi‑index d’origine, c’est déjà le cas.\n",
    "    # Si tu veux rajouter d’autres colonnes (non numériques) à côté :\n",
    "    # return pivot_df.drop(columns=method_cols).join(rank_df)\n",
    "\n",
    "    return rank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['site', 'method', 'robust_method', 'disease', 'metric', 'bundle', 'mae',\n",
      "       'num_patients', 'disease_ratio', 'num_diseased'],\n",
      "      dtype='object')\n",
      "Sites exclus pour NaN : 0 / 480\n",
      "Sites exclus pour NaN : 0 / 480\n",
      "Sites exclus pour NaN : 0 / 480\n"
     ]
    }
   ],
   "source": [
    "# site, disease, n_patients, ratio, metric, bundle, robust_method, mae\n",
    "mae_compilation_train_all_long = transformer_df_large_en_long(mae_compilation_train_all)\n",
    "mae_compilation_test_all_long  = transformer_df_large_en_long(mae_compilation_test_all)\n",
    "smape_compilation_test_all_long  = transformer_df_large_en_long(smape_compilation_test_all)\n",
    "smape_compilation_train_all_long = transformer_df_large_en_long(smape_compilation_train_all)\n",
    "std_mae_compilation_train_all_long = transformer_df_large_en_long(std_mae_compilation_train_all)\n",
    "std_mae_compilation_test_all_long  = transformer_df_large_en_long(std_mae_compilation_test_all)\n",
    "\n",
    "\n",
    "df_long = mae_compilation_train_all_long\n",
    "df_long = add_nb_patients_and_diseased(df_long)\n",
    "df_long = df_long[df_long[\"robust_method\"].isin(['NoRobust', \n",
    "                                                 'hc', \n",
    "                                                 'raw',\n",
    "                                                 \"IQR\", \n",
    "                                                 \"MAD\",\n",
    "                                                 \"VS\",\n",
    "                                                 \"Z_SCORE\",\n",
    "                                                 \"Z_SCORE_MAD\",\n",
    "                                                 \"MLP2_ALL_5\",\n",
    "                                                 \"SN\",\n",
    "                                                 \"QN\",\n",
    "                                                 \"LOF\",\n",
    "                                                 \"MLP2_ALL_6\",\n",
    "                                                 \"MLP2_ALL_5_MAD\",\n",
    "                                                 \"MLP2_ALL_6_MAD\",\n",
    "                                                 \"MLP2_ALL_9\",])]\n",
    "print(df_long.columns)\n",
    "# ⬛️ CELLULE 3‑bis — Filtrer les sites contenant des NaN\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# 1)  Identifie les sites à exclure\n",
    "sites_with_nan = (\n",
    "    df_long\n",
    "      .groupby(\"site\")\n",
    "      .filter(lambda g: g.isna().any().any())   # True si NaN dans le groupe\n",
    "      [\"site\"]\n",
    "      .unique()\n",
    ")\n",
    "\n",
    "# 2)  Statistiques\n",
    "n_nan_sites   = len(sites_with_nan)\n",
    "n_total_sites = df_long[\"site\"].nunique()\n",
    "\n",
    "print(f\"Sites exclus pour NaN : {n_nan_sites} / {n_total_sites}\")\n",
    "if n_nan_sites:\n",
    "    print(\"Liste :\", list(sites_with_nan))\n",
    "\n",
    "# 3)  Filtre le DataFrame pour la suite\n",
    "df_long = df_long[~df_long[\"site\"].isin(sites_with_nan)].copy()\n",
    "\n",
    "pivot_df = (\n",
    "    df_long\n",
    "    .pivot_table(\n",
    "        index=['site', 'disease', 'metric', 'bundle',\n",
    "               'num_patients', 'disease_ratio', 'num_diseased'],\n",
    "        columns='robust_method',\n",
    "        values='mae',\n",
    "        aggfunc='first'   # ou 'mean' si tu peux avoir plusieurs lignes identiques\n",
    "    )\n",
    ")\n",
    "\n",
    "diff_df = pivot_df.sub(pivot_df['NoRobust'], axis=0)\n",
    "\n",
    "ranked = rank_methods_per_row(pivot_df)\n",
    "\n",
    "df_long = smape_compilation_train_all_long\n",
    "df_long = add_nb_patients_and_diseased(df_long)\n",
    "df_long = df_long[df_long[\"robust_method\"].isin(['NoRobust', \n",
    "                                                 'hc', \n",
    "                                                 'raw',\n",
    "                                                 \"IQR\", \n",
    "                                                 \"MAD\",\n",
    "                                                 \"VS\",\n",
    "                                                 \"Z_SCORE\",\n",
    "                                                 \"Z_SCORE_MAD\",\n",
    "                                                 \"MLP2_ALL_5\",\n",
    "                                                 \"SN\",\n",
    "                                                 \"QN\",\n",
    "                                                 \"LOF\",\n",
    "                                                 \"MLP2_ALL_6\",\n",
    "                                                 \"MLP2_ALL_5_MAD\",\n",
    "                                                 \"MLP2_ALL_6_MAD\",\n",
    "                                                 \"MLP2_ALL_9\",])]\n",
    "\n",
    "# 1)  Identifie les sites à exclure\n",
    "sites_with_nan_smape = (\n",
    "    df_long\n",
    "      .groupby(\"site\")\n",
    "      .filter(lambda g: g.isna().any().any())   # True si NaN dans le groupe\n",
    "      [\"site\"]\n",
    "      .unique()\n",
    ")\n",
    "\n",
    "# 2)  Statistiques\n",
    "n_nan_sites_smape   = len(sites_with_nan_smape)\n",
    "n_total_sites_smape = df_long[\"site\"].nunique()\n",
    "\n",
    "print(f\"Sites exclus pour NaN : {n_nan_sites_smape} / {n_total_sites_smape}\")\n",
    "if n_nan_sites_smape:\n",
    "    print(\"Liste :\", list(sites_with_nan_smape))\n",
    "\n",
    "# 3)  Filtre le DataFrame pour la suite\n",
    "df_long = df_long[~df_long[\"site\"].isin(sites_with_nan)].copy()\n",
    "\n",
    "pivot_df_smape = (\n",
    "    df_long\n",
    "    .pivot_table(\n",
    "        index=['site', 'disease', 'metric', 'bundle',\n",
    "               'num_patients', 'disease_ratio', 'num_diseased'],\n",
    "        columns='robust_method',\n",
    "        values='mae',\n",
    "        aggfunc='first'   # ou 'mean' si tu peux avoir plusieurs lignes identiques\n",
    "    )\n",
    ")\n",
    "\n",
    "diff_df_smape= pivot_df_smape.sub(pivot_df_smape['NoRobust'], axis=0)\n",
    "\n",
    "ranked_smape = rank_methods_per_row(pivot_df_smape)\n",
    "\n",
    "\n",
    "df_long = std_mae_compilation_train_all_long\n",
    "df_long = add_nb_patients_and_diseased(df_long)\n",
    "df_long = df_long[df_long[\"robust_method\"].isin(['NoRobust', \n",
    "                                                 'hc', \n",
    "                                                 'raw',\n",
    "                                                 \"IQR\", \n",
    "                                                 \"MAD\",\n",
    "                                                 \"VS\",\n",
    "                                                 \"Z_SCORE\",\n",
    "                                                 \"Z_SCORE_MAD\",\n",
    "                                                 \"MLP2_ALL_5\",\n",
    "                                                 \"SN\",\n",
    "                                                 \"QN\",\n",
    "                                                 \"LOF\",\n",
    "                                                 \"MLP2_ALL_6\",\n",
    "                                                 \"MLP2_ALL_5_MAD\",\n",
    "                                                 \"MLP2_ALL_6_MAD\",\n",
    "                                                 \"MLP2_ALL_9\",])]\n",
    "\n",
    "\n",
    "# 1)  Identifie les sites à exclure\n",
    "sites_with_nan_std = (\n",
    "    df_long\n",
    "      .groupby(\"site\")\n",
    "      .filter(lambda g: g.isna().any().any())   # True si NaN dans le groupe\n",
    "      [\"site\"]\n",
    "      .unique()\n",
    ")\n",
    "\n",
    "# 2)  Statistiques\n",
    "n_nan_sites_std   = len(sites_with_nan_std)\n",
    "n_total_sites_std = df_long[\"site\"].nunique()\n",
    "\n",
    "print(f\"Sites exclus pour NaN : {n_nan_sites_std} / {n_total_sites_std}\")\n",
    "if n_nan_sites_std:\n",
    "    print(\"Liste :\", list(sites_with_nan_std))\n",
    "\n",
    "# 3)  Filtre le DataFrame pour la suite\n",
    "df_long = df_long[~df_long[\"site\"].isin(sites_with_nan)].copy()\n",
    "\n",
    "pivot_df_std = (\n",
    "    df_long\n",
    "    .pivot_table(\n",
    "        index=['site', 'disease', 'metric', 'bundle',\n",
    "               'num_patients', 'disease_ratio', 'num_diseased'],\n",
    "        columns='robust_method',\n",
    "        values='mae',\n",
    "        aggfunc='first'   # ou 'mean' si tu peux avoir plusieurs lignes identiques\n",
    "    )\n",
    ")\n",
    "\n",
    "diff_df_std= pivot_df_std.sub(pivot_df_std['NoRobust'], axis=0)\n",
    "\n",
    "ranked_std = rank_methods_per_row(pivot_df_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXEC PLOTS MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crée les tâches pour chaque combinaison\n",
    "pivot_df_std = pivot_df_std.drop(columns=['raw', 'FLIP'], errors='ignore')\n",
    "\n",
    "tasks = [\n",
    "    (pivot_df_std, sample_size, MAE_PLOT_FOLDER, \"train\", \"STD_MAE\")\n",
    "    for sample_size  in sample_sizes\n",
    "]\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_mean_all_diseases_metrics)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_mean_all_ratios)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "\n",
    "tasks = [\n",
    "    (pivot_df_std, sample_size, disease, MAE_PLOT_FOLDER, \"train\", \"STD_MAE\")\n",
    "    for disease      in diseases\n",
    "    for sample_size  in sample_sizes\n",
    "]\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_rank_all_metrics)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "tasks = [\n",
    "    (pivot_df_std, sample_size, disease, metric, MAE_PLOT_FOLDER, \"train\", \"STD_MAE\")\n",
    "    for disease      in diseases\n",
    "    for sample_size  in sample_sizes\n",
    "    for metric       in metrics\n",
    "]\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_rank)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_all_bundles_pivot)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_each_bundle)(*task) for task in tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crée les tâches pour chaque combinaison\n",
    "diff_df_std = diff_df_std.drop(columns=['raw', 'FLIP'], errors='ignore')\n",
    "\n",
    "tasks = [\n",
    "    (diff_df_std, sample_size, disease, metric, MAE_PLOT_FOLDER, \"train\", \"STD_MAE_DIFF\")\n",
    "    for disease      in diseases\n",
    "    for sample_size  in sample_sizes\n",
    "    for metric       in metrics\n",
    "]\n",
    "\n",
    "# # Exécution parallèle\n",
    "# Parallel(n_jobs=1)(\n",
    "#     delayed(plot_mae_all_bundles_pivot_3_way)(*task) for task in tasks\n",
    "# )\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_all_bundles_pivot)(*task) for task in tasks\n",
    ")\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_each_bundle)(*task) for task in tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crée les tâches pour chaque combinaison\n",
    "pivot_df_smape = pivot_df_smape.drop(columns=['raw', 'FLIP'], errors='ignore')\n",
    "\n",
    "tasks = [\n",
    "    (pivot_df_smape, sample_size, MAE_PLOT_FOLDER, \"train\", \"SMAPE\")\n",
    "    for sample_size  in sample_sizes\n",
    "]\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_mean_all_diseases_metrics)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_mean_all_ratios)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "\n",
    "tasks = [\n",
    "    (pivot_df_smape, sample_size, disease, MAE_PLOT_FOLDER, \"train\", \"SMAPE\")\n",
    "    for disease      in diseases\n",
    "    for sample_size  in sample_sizes\n",
    "]\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_rank_all_metrics)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "tasks = [\n",
    "    (pivot_df_smape, sample_size, disease, metric, MAE_PLOT_FOLDER, \"train\", \"SMAPE\")\n",
    "    for disease      in diseases\n",
    "    for sample_size  in sample_sizes\n",
    "    for metric       in metrics\n",
    "]\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_rank)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_all_bundles_pivot)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_each_bundle)(*task) for task in tasks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crée les tâches pour chaque combinaison\n",
    "diff_df_smape = diff_df_smape.drop(columns=['raw', 'FLIP'], errors='ignore')\n",
    "\n",
    "tasks = [\n",
    "    (diff_df_smape, sample_size, disease, metric, MAE_PLOT_FOLDER, \"train\", \"SMAPE_DIFF\")\n",
    "    for disease      in diseases\n",
    "    for sample_size  in sample_sizes\n",
    "    for metric       in metrics\n",
    "]\n",
    "\n",
    "# # Exécution parallèle\n",
    "# Parallel(n_jobs=1)(\n",
    "#     delayed(plot_mae_all_bundles_pivot_3_way)(*task) for task in tasks\n",
    "# )\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_all_bundles_pivot)(*task) for task in tasks\n",
    ")\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_each_bundle)(*task) for task in tasks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crée les tâches pour chaque combinaison\n",
    "pivot_df = pivot_df.drop(columns=['raw', 'FLIP'], errors='ignore')\n",
    "\n",
    "tasks = [\n",
    "    (pivot_df, sample_size, MAE_PLOT_FOLDER, \"train\", \"MAE\")\n",
    "    for sample_size  in sample_sizes\n",
    "]\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_mean_all_diseases_metrics)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_mean_all_ratios)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "\n",
    "tasks = [\n",
    "    (pivot_df, sample_size, disease, MAE_PLOT_FOLDER, \"train\", \"MAE\")\n",
    "    for disease      in diseases\n",
    "    for sample_size  in sample_sizes\n",
    "]\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_rank_all_metrics)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "tasks = [\n",
    "    (pivot_df, sample_size, disease, metric, MAE_PLOT_FOLDER, \"train\", \"MAE\")\n",
    "    for disease      in diseases\n",
    "    for sample_size  in sample_sizes\n",
    "    for metric       in metrics\n",
    "]\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_rank)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_all_bundles_pivot)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_each_bundle)(*task) for task in tasks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crée les tâches pour chaque combinaison\n",
    "diff_df = diff_df.drop(columns=['raw', 'FLIP'], errors='ignore')\n",
    "\n",
    "tasks = [\n",
    "    (diff_df, sample_size, disease, metric, MAE_PLOT_FOLDER, \"train\", \"MAE_DIFF\")\n",
    "    for disease      in diseases\n",
    "    for sample_size  in sample_sizes\n",
    "    for metric       in metrics\n",
    "]\n",
    "\n",
    "# # Exécution parallèle\n",
    "# Parallel(n_jobs=-1)(\n",
    "#     delayed(plot_mae_all_bundles_pivot_3_way)(*task) for task in tasks\n",
    "# )\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_all_bundles_pivot)(*task) for task in tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crée les tâches pour chaque combinaison\n",
    "ranked = ranked.drop(columns='raw', errors='ignore')\n",
    "\n",
    "tasks = [\n",
    "    (ranked, sample_size, MAE_PLOT_FOLDER, \"train\", \"RANK\")\n",
    "    for sample_size  in sample_sizes\n",
    "]\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_mean_all_ratios)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mae_mean_all_diseases_metrics)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "tasks = [\n",
    "    (ranked, sample_size, disease, MAE_PLOT_FOLDER, \"train\", \"RANK\")\n",
    "    for disease      in diseases\n",
    "    for sample_size  in sample_sizes\n",
    "]\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_rank_all_metrics)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "tasks = [\n",
    "    (ranked, sample_size, disease, metric, MAE_PLOT_FOLDER, \"train\", \"RANK\")\n",
    "    for disease      in diseases\n",
    "    for sample_size  in sample_sizes\n",
    "    for metric       in metrics\n",
    "]\n",
    "\n",
    "# Exécution parallèle\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_rank)(*task) for task in tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST/WORST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_worst_cases(df, top_n=1):\n",
    "    \"\"\"\n",
    "    Retourne deux DataFrames :\n",
    "      1. worst_df : top_n pires erreurs (valeur la plus élevée)\n",
    "      2. best_df  : top_n meilleures erreurs (valeur la plus basse)\n",
    "    Groupage sur : disease, num_patients, disease_ratio, metric\n",
    "    \"\"\"\n",
    "    # Colonnes purement contextuelles\n",
    "    context_cols = [\n",
    "        'site', 'disease', 'metric', 'bundle',\n",
    "        'num_patients', 'disease_ratio', 'num_diseased', 'raw'\n",
    "    ]\n",
    "    \n",
    "    # Chaque autre colonne est une méthode robuste\n",
    "    method_cols = [col for col in df.columns if col not in context_cols]\n",
    "    \n",
    "    \n",
    "    worst_rows = []\n",
    "    best_rows  = []\n",
    "    \n",
    "    # Nouveau groupage incluant metric\n",
    "    grp = df.groupby(['disease', 'num_patients', 'disease_ratio', 'metric'])\n",
    "    \n",
    "    # for (disease, num_patients, disease_ratio, metric), gdf in grp:\n",
    "    for method in method_cols:\n",
    "        # tmp = gdf.copy()\n",
    "        tmp = df.copy()\n",
    "        tmp['error']  = tmp[method]\n",
    "        tmp['method'] = method\n",
    "        \n",
    "        # Top N pires\n",
    "        worst_rows.append(\n",
    "            tmp.nlargest(top_n, 'error')\n",
    "                [['disease','num_patients','disease_ratio',\n",
    "                  'metric','bundle','site','method','error']]\n",
    "        )\n",
    "        # Top N meilleures\n",
    "        best_rows.append(\n",
    "            tmp.nsmallest(top_n, 'error')\n",
    "                [['disease','num_patients','disease_ratio',\n",
    "                  'metric','bundle','site','method','error']]\n",
    "        )\n",
    "    \n",
    "    worst_df = pd.concat(worst_rows, ignore_index=True)\n",
    "    best_df  = pd.concat(best_rows,  ignore_index=True)\n",
    "    \n",
    "    return worst_df, best_df\n",
    "\n",
    "worst_df, best_df = get_best_worst_cases(diff_df_std.reset_index(), top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_df = worst_df[(worst_df['num_patients'] == 100)]\n",
    "worst_df\n",
    "\n",
    "best_df = best_df[(best_df['num_patients'] == 100)]\n",
    "best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "def combine_imgs(outdir, site, harmonization_method, metric, bundle, test_idx ,error, method=\"Robust\", delete_originals=True):\n",
    "    if method == 'hc':\n",
    "        method_dir = \"NoRobust\"  # Harmonization Control is a NoRobust method\n",
    "    else:\n",
    "        method_dir = method\n",
    "    outdir = Path(outdir)\n",
    "    suf = f\"{metric}_{bundle.replace('_', '')}\"\n",
    "    files = {\n",
    "        \"tl\": f\"{site}_No_Robust_raw_{suf}_{site}_No_Robust.png\",\n",
    "        \"tr\": f\"{site}_No_Robust_{harmonization_method}_{suf}_{site}_No_Robust.png\",\n",
    "        \"bl\": f\"{site}_{method_dir}_{harmonization_method}_{suf}_{site}_{method_dir}.png\",\n",
    "        \"br\": f\"{site}_HC_raw_{suf}_{site}_HC.png\"\n",
    "    }\n",
    "    others = [f\"{site}_{method_dir}_raw_{suf}_{site}_{method_dir}.png\", f\"{site}_HC_{harmonization_method}_{suf}_{site}_HC.png\"]\n",
    "    if method == \"hc\":\n",
    "        others.append(files[\"bl\"])\n",
    "        files[\"bl\"] = f\"{site}_HC_{harmonization_method}_{suf}_{site}_HC.png\"\n",
    "        (outdir / f\"{site}_{method_dir}_{harmonization_method}_{suf}_{site}_{method_dir}.png\").unlink(missing_ok=True)\n",
    "    imgs = [Image.open(outdir / f) for f in files.values()]\n",
    "    w, h = imgs[0].size\n",
    "    cmb = Image.new(\"RGB\", (2*w, 2*h), \"white\")\n",
    "    cmb.paste(imgs[0], (0, 0)), cmb.paste(imgs[1], (w, 0))\n",
    "    cmb.paste(imgs[2], (0, h)), cmb.paste(imgs[3], (w, h))\n",
    "    out = outdir / f\"{test_idx}_{method}_{float(error):.2f}_{site}_combined_{suf}.png\"\n",
    "    cmb.save(out)\n",
    "    for im in imgs: im.close()\n",
    "    if delete_originals:\n",
    "        for f in list(files.values()) + others:\n",
    "            (outdir / f).unlink(missing_ok=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VIZ(metric, bundle, site, method, error,\n",
    "        disease, num_patients, disease_ratio):\n",
    "    \n",
    "    if method == 'hc':\n",
    "        method_dir = \"NoRobust\"  # Harmonization Control is a NoRobust method\n",
    "    else:\n",
    "        method_dir = method\n",
    "    # Crée le dossier au besoin\n",
    "    test_index = site.split(\"_\")[-1]\n",
    "    dir = os.path.join(\"RESULTS/MAE_TEST\", 'PROCESS', disease,\n",
    "                           f\"{num_patients}_{disease_ratio}\",\n",
    "                           f\"{test_index}\", metric)\n",
    "    dir_robust = os.path.join(dir,method)\n",
    "    dir_norobust = os.path.join(dir, \"NoRobust\")\n",
    "    dir_hc = os.path.join(dir, \"hc\")\n",
    "    directory_site = os.path.join(\"RESULTS/MAE_TEST/SYNTHETIC_SITES/v1\", disease, f\"{num_patients}_{disease_ratio}\",f\"{test_index}\")\n",
    "    train_file_name = os.path.join(directory_site,f\"train_{num_patients}_{disease_ratio}_{test_index}_{metric}.csv\")\n",
    "    gt_file_name = os.path.join(directory_site,f\"gt_train_{num_patients}_{disease_ratio}_{test_index}_{metric}.csv\")\n",
    "    train_file_name_2 = os.path.join(directory_site,f\"train_{num_patients}_{disease_ratio}_{test_index}_{metric}_{str(error)}.csv\")\n",
    "    gt_file_name_2 = os.path.join(directory_site,f\"gt_train_{num_patients}_{disease_ratio}_{test_index}_{metric}_{str(error)}.csv\")\n",
    "    # Ouvre le fichier train, supprime la colonne 'model' si elle existe, puis sauvegarde\n",
    "    if os.path.isfile(train_file_name):\n",
    "        if os.path.getsize(train_file_name) == 0:\n",
    "            print(\"Fichier vide ou manquant :\", train_file_name)\n",
    "            return\n",
    "        df_train = pd.read_csv(train_file_name)\n",
    "        df_gt = pd.read_csv(gt_file_name)\n",
    "        if 'model' in df_train.columns:\n",
    "            df_train = df_train.drop(columns=['model'])\n",
    "        if 'model' in df_gt.columns:\n",
    "            df_gt = df_gt.drop(columns=['model'])\n",
    "        if 'harmonization' in df_gt.columns:\n",
    "            df_gt = df_gt.drop(columns=['harmonization'])\n",
    "        if 'harmonization' in df_train.columns:\n",
    "            df_train = df_train.drop(columns=['harmonization'])\n",
    "        df_train['site'] = site\n",
    "        df_train.to_csv(train_file_name_2, index=False)\n",
    "        df_gt['site'] = site\n",
    "        df_gt.to_csv(gt_file_name_2, index=False)\n",
    "    \n",
    "    robust_file = os.path.join(\n",
    "            dir_robust,\n",
    "            site\n",
    "            + \".\"\n",
    "            + metric\n",
    "            + \".\"\n",
    "            + harmonization_method\n",
    "            + \".\"\n",
    "            + method_dir\n",
    "            + \".\"\n",
    "            + rwp_text(False)\n",
    "            + \".csv\"\n",
    "        )\n",
    "    norobust_file = os.path.join(\n",
    "            dir_norobust,\n",
    "            site\n",
    "            + \".\"\n",
    "            + metric\n",
    "            + \".\"\n",
    "            + harmonization_method\n",
    "            + \".NoRobust\"\n",
    "            + \".\"\n",
    "            + rwp_text(False)\n",
    "            + \".csv\"\n",
    "        )\n",
    "    hc_file = os.path.join(\n",
    "            dir_hc,\n",
    "            site\n",
    "            + \".\"\n",
    "            + metric\n",
    "            + \".\"\n",
    "            + harmonization_method\n",
    "            + \".NoRobust\"\n",
    "            + \".\"\n",
    "            + rwp_text(False)\n",
    "            + \".csv\"\n",
    "        )\n",
    "    ref_data_file = get_camcan_file(metric)\n",
    "    if BW_FOLDER in [\"BEST\", \"WORST\"]:\n",
    "        outdir = os.path.join(ANALYSIS_FOLDER, BW_FOLDER ,method, str(num_patients))\n",
    "    else:\n",
    "        outdir = os.path.join(ANALYSIS_FOLDER, BW_FOLDER, disease,\n",
    "                           f\"{num_patients}_{disease_ratio}\",\n",
    "                             metric, bundle)\n",
    "\n",
    "        \n",
    "    visualize_harmonization(train_file_name_2, norobust_file, ref_data_file, outdir, bundles = bundle, title=f\"{site}_No_Robust\")\n",
    "    visualize_harmonization(train_file_name_2, robust_file, ref_data_file, outdir, bundles = bundle, title=f\"{site}_{method}\")\n",
    "    visualize_harmonization(gt_file_name_2, hc_file, ref_data_file, outdir, bundles = bundle, title=f\"{site}_HC\")\n",
    "\n",
    "    if \"Z_SCORE\" in method:\n",
    "        z_score_sids = z_score_detection(os.path.join(\n",
    "        directory_site, f\"train_{num_patients}_{disease_ratio}_{test_index}_all.csv\"))\n",
    "        df_train = flag_sid(df_train, z_score_sids, \"Z_SCORE\")\n",
    "\n",
    "    if \"MLP2_ALL_5\" in method:\n",
    "        mlp2all5_sid = predict_malades_MLP(os.path.join(\n",
    "            directory_site, f\"train_{num_patients}_{disease_ratio}_{test_index}_all.csv\"), \"mlp2_ALL\", threshold=0.5)\n",
    "        df_train = flag_sid(df_train, mlp2all5_sid, \"MLP2_ALL_5\")\n",
    "    if \"MLP2_ALL_6\" in method:\n",
    "        mlp2all6_sid = predict_malades_MLP(os.path.join(\n",
    "            directory_site, f\"train_{num_patients}_{disease_ratio}_{test_index}_all.csv\"), \"mlp2_ALL\", threshold=0.6)\n",
    "        df_train = flag_sid(df_train, mlp2all6_sid, \"MLP2_ALL_6\")\n",
    "    if \"MLP2_ALL_9\" in method:\n",
    "        mlp2all9_sid = predict_malades_MLP(os.path.join(\n",
    "            directory_site, f\"train_{num_patients}_{disease_ratio}_{test_index}_all.csv\"), \"mlp2_ALL\", threshold=0.9)\n",
    "        df_train = flag_sid(df_train, mlp2all9_sid, \"MLP2_ALL_9\")\n",
    "        \n",
    "    df_train['site'] = site + \"viz\"\n",
    "    df_train['error'] = error\n",
    "    df_train['nasty_bundle'] = bundle\n",
    "    temp_file = os.path.join(outdir, f\"temp_{str(error)}.csv\")\n",
    "    df_train.to_csv(temp_file, index=False)\n",
    "\n",
    "    output_model_filename = fit(temp_file, ref_data_file, metric, harmonization_method, method_dir, False, outdir, False)\n",
    "\n",
    "    if os.path.isfile(temp_file):\n",
    "        os.remove(temp_file)\n",
    "    if os.path.isfile(train_file_name_2):\n",
    "        os.remove(train_file_name_2)\n",
    "    if output_model_filename and os.path.isfile(output_model_filename):\n",
    "        os.remove(output_model_filename)\n",
    "    outlier_file = os.path.join(outdir, f\"outliers_{site}viz_{method}_NoRWP.csv\")\n",
    "    if os.path.isfile(outlier_file):\n",
    "        os.remove(outlier_file)\n",
    "    combine_imgs(outdir, site, harmonization_method, metric, bundle, test_index, str(error), method)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BW_FOLDER = \"WORST\"\n",
    "# Parallel(n_jobs=1)(delayed(VIZ)(**r) for r in worst_df.to_dict(\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BW_FOLDER = \"BEST\"\n",
    "# Parallel(n_jobs=1)(delayed(VIZ)(**r) for r in best_df.to_dict(\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_errors(\n",
    "    df,\n",
    "    metric=None,\n",
    "    disease=None,\n",
    "    bundle=None,\n",
    "    num_patients=None,\n",
    "    disease_ratio=None,\n",
    "    method=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Filtre le DataFrame long sur les colonnes demandées.\n",
    "    Laisse un paramètre à None pour l’ignorer.\n",
    "\n",
    "    Retour : DataFrame filtré.\n",
    "    \"\"\"\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "\n",
    "    if metric is not None:\n",
    "        mask &= df[\"metric\"] == metric\n",
    "    if disease is not None:\n",
    "        mask &= df[\"disease\"] == disease\n",
    "    if bundle is not None:\n",
    "        mask &= df[\"bundle\"] == bundle\n",
    "    if num_patients is not None:\n",
    "        mask &= df[\"num_patients\"] == num_patients\n",
    "    if disease_ratio is not None:\n",
    "        mask &= df[\"disease_ratio\"] == disease_ratio\n",
    "    if method is not None:\n",
    "        mask &= df[\"method\"] == method\n",
    "\n",
    "    return df.loc[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_format_all_errors(df):\n",
    "    \"\"\"\n",
    "    Convertit le DataFrame large (une colonne par méthode) en\n",
    "    format long avec toutes les erreurs conservées.\n",
    "\n",
    "    Retour : DataFrame avec colonnes\n",
    "        ['disease', 'num_patients', 'disease_ratio',\n",
    "         'metric', 'bundle', 'site', 'method', 'error']\n",
    "    \"\"\"\n",
    "    # Colonnes de contexte (on garde celles‑ci telles quelles)\n",
    "    context_cols = [\n",
    "        'site', 'disease', 'metric', 'bundle',\n",
    "        'num_patients', 'disease_ratio', 'num_diseased'\n",
    "    ]\n",
    "\n",
    "    # Colonnes correspondant aux méthodes robustes\n",
    "    method_cols = [c for c in df.columns if c not in context_cols]\n",
    "\n",
    "    # Transformation wide → long\n",
    "    long_df = (\n",
    "        df\n",
    "        .melt(\n",
    "            id_vars=context_cols,\n",
    "            value_vars=method_cols,\n",
    "            var_name='method',\n",
    "            value_name='error'\n",
    "        )\n",
    "        .drop(columns=['num_diseased'])  # retire si inutiles\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return long_df\n",
    "long_allMethos = long_format_all_errors(diff_df_std.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BW_FOLDER = \"ISOLATE\"\n",
    "long_allMethos\n",
    "subset = filter_errors(\n",
    "    long_allMethos,\n",
    "    metric=\"fw\",\n",
    "    disease=\"AD\",\n",
    "    bundle=\"mni_OPT_L\",\n",
    "    num_patients=100,\n",
    "    disease_ratio=30,\n",
    "    method=\"MAD\"\n",
    ")\n",
    "Parallel(n_jobs=1)(delayed(VIZ)(**r) for r in subset.to_dict(\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_c = [\n",
    "        'site', 'disease', 'metric', 'bundle',\n",
    "        'num_patients', 'disease_ratio', 'num_diseased', \"raw\", \"NoRobust\"\n",
    "    ]\n",
    "\n",
    "    # Colonnes correspondant aux méthodes robustes\n",
    "methodi = [c for c in diff_df_smape.columns if c not in context_c]\n",
    "methodi = [\"hc\",\"Z_SCORE\", \"MAD\", \"VS2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bund in [\"mni_STT_L\", \"mni_AC\", \"mni_SLF_R\"]:\n",
    "#     for meth in methodi:\n",
    "#         # Filtre le DataFrame pour la méthode en cours\n",
    "#         BW_FOLDER = \"ISOLATE\"\n",
    "#         long_allMethos\n",
    "#         subset = filter_errors(\n",
    "#             long_allMethos,\n",
    "#             metric=\"fa\",\n",
    "#             disease=\"AD\",\n",
    "#             bundle=bund,\n",
    "#             num_patients=100,\n",
    "#             disease_ratio=30,\n",
    "#             method=meth\n",
    "#         )\n",
    "#         subset = subset.sort_values(\"site\").head(5)\n",
    "#         Parallel(n_jobs=1)(delayed(VIZ)(**r) for r in subset.to_dict(\"records\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE vs DISTANCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tracer_corr_par_ratio(\n",
    "    df_dist,\n",
    "    df_errors,\n",
    "    methods,\n",
    "    disease_ratios,\n",
    "    out_root=\"PLOTS_CORRELATION\",\n",
    "    distance_col=\"d_cohen\"\n",
    "):\n",
    "\n",
    "    ratios_pct = [int(r * 100) for r in disease_ratios]\n",
    "\n",
    "    for ratio_float, ratio_pct in zip(disease_ratios, ratios_pct):\n",
    "        df_ratio = df_errors[df_errors[\"disease_ratio\"] == ratio_pct]\n",
    "        out_dir = os.path.join(out_root, f\"{ratio_pct}pc\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        for meth in methods:\n",
    "            col_err = f\"{meth}_error\"\n",
    "            df_mean = df_ratio.groupby([\"disease\", \"metric\", \"bundle\"], as_index=False).agg(**{col_err: (meth, \"mean\")})\n",
    "            merged = df_dist.merge(df_mean, on=[\"disease\", \"metric\", \"bundle\"], how=\"inner\")\n",
    "            if merged.empty:\n",
    "                continue\n",
    "\n",
    "            pearson = merged[distance_col].corr(merged[col_err], method=\"pearson\")\n",
    "            spearman = merged[distance_col].corr(merged[col_err], method=\"spearman\")\n",
    "\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            sns.regplot(data=merged, x=distance_col, y=col_err, scatter_kws={\"alpha\": 0.7})\n",
    "            plt.title(f\"{meth} | disease ratio {ratio_pct}%\\nPearson={pearson:.2f}, Spearman={spearman:.2f}\")\n",
    "            plt.xlabel(distance_col)\n",
    "            plt.ylabel(col_err)\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            file_path = os.path.join(out_dir, f\"{meth}.png\")\n",
    "            plt.savefig(file_path, dpi=300)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def tracer_corr_par_ratio_brut(\n",
    "    df_dist,\n",
    "    df_errors,\n",
    "    methods,\n",
    "    disease_ratios,\n",
    "    out_root=\"PLOTS_CORRELATION_RAW\",\n",
    "    distance_col=\"d_cohen\",\n",
    "):\n",
    "\n",
    "    for ratio in disease_ratios:\n",
    "        pct = int(ratio * 100)\n",
    "        df_ratio = df_errors[df_errors[\"disease_ratio\"] == pct]\n",
    "        out_dir = os.path.join(out_root, f\"{pct}pc\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        for meth in methods:\n",
    "            if meth not in df_ratio.columns:\n",
    "                continue\n",
    "            merged = df_dist.merge(\n",
    "                df_ratio[[\"disease\", \"metric\", \"bundle\", meth]],\n",
    "                on=[\"disease\", \"metric\", \"bundle\"]\n",
    "            )\n",
    "            if merged.empty:\n",
    "                continue\n",
    "\n",
    "            pearson = merged[distance_col].corr(merged[meth], \"pearson\")\n",
    "            spearman = merged[distance_col].corr(merged[meth], \"spearman\")\n",
    "\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            sns.regplot(data=merged, x=distance_col, y=meth, scatter_kws={\"alpha\": 0.7})\n",
    "            plt.title(f\"{meth} | disease ratio {pct}%\\nPearson={pearson:.2f}, Spearman={spearman:.2f}\")\n",
    "            plt.xlabel(distance_col)\n",
    "            plt.ylabel(meth)\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            plt.savefig(os.path.join(out_dir, f\"{meth}.png\"), dpi=300)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist = pd.read_csv(\"RESULTS/DISTRIBUTION_ANALYSIS/distance_metrics_results.csv\")\n",
    "diff_df_smape.reset_index()\n",
    "methodi = [c for c in diff_df_smape.columns if c not in context_c]\n",
    "\n",
    "base_out_dir   = os.path.join(MAINFOLDER,\"PLOTS_CORRELATION_MEAN\") \n",
    "\n",
    "tracer_corr_par_ratio(\n",
    "    df_dist=df_dist,\n",
    "    df_errors=diff_df_smape.reset_index(),\n",
    "    methods=methodi,\n",
    "    disease_ratios=disease_ratios,\n",
    "    out_root=os.path.join(base_out_dir,\"SMAPE_DIFF\")\n",
    ")\n",
    "\n",
    "tracer_corr_par_ratio(\n",
    "    df_dist=df_dist,\n",
    "    df_errors=diff_df_std.reset_index(),\n",
    "    methods=methodi,\n",
    "    disease_ratios=disease_ratios,\n",
    "    out_root=os.path.join(base_out_dir,\"STD_MAE_DIFF\")\n",
    ")\n",
    "\n",
    "base_out_dir   = os.path.join(MAINFOLDER,\"PLOTS_CORRELATION_RAW\") \n",
    "tracer_corr_par_ratio_brut(\n",
    "    df_dist=df_dist,\n",
    "    df_errors=diff_df_smape.reset_index(),\n",
    "    methods=methodi,\n",
    "    disease_ratios=disease_ratios,\n",
    "    out_root=os.path.join(base_out_dir,\"SMAPE_DIFF\")\n",
    ")\n",
    "\n",
    "tracer_corr_par_ratio_brut(\n",
    "    df_dist=df_dist,\n",
    "    df_errors=diff_df_std.reset_index(),\n",
    "    methods=methodi,\n",
    "    disease_ratios=disease_ratios,\n",
    "    out_root=os.path.join(base_out_dir,\"STD_MAE_DIFF\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEILLEURS PIRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moyenne_par_disease_metric_bundle(df, colonnes_valeurs, disease_ratio=None):\n",
    "    if isinstance(colonnes_valeurs, str):\n",
    "        colonnes_valeurs = [colonnes_valeurs]\n",
    "    if disease_ratio is not None:\n",
    "        df = df[df[\"disease_ratio\"] == disease_ratio]\n",
    "    return (\n",
    "        df.groupby([\"disease\", \"metric\", \"bundle\"])[colonnes_valeurs]\n",
    "          .mean()\n",
    "          .reset_index()\n",
    "    )\n",
    "def meilleurs_par_methode(df, methods, top=1):\n",
    "    for meth in methods:\n",
    "        print(f\"\\n========== {meth} =========\")\n",
    "        for d_r in disease_ratios:\n",
    "            d_r = d_r * 100\n",
    "            if meth not in df.columns:\n",
    "                continue\n",
    "            best = (\n",
    "                moyenne_par_disease_metric_bundle(df, meth, d_r)\n",
    "                .sort_values(meth, ascending=False)\n",
    "                .head(top)\n",
    "            )\n",
    "            print(f\"\\n== {d_r} ==\")\n",
    "            for _, row in best.iterrows():\n",
    "                print(f\"{row['disease']} | {row['metric']} | {row['bundle']} : {row[meth]:.4f}\")\n",
    "\n",
    "def meilleurs_par_methode_site(df, methods, top=1):\n",
    "    for meth in methods:\n",
    "        if meth not in df.columns:\n",
    "            continue\n",
    "        print(f\"\\n========== {meth} =========\")\n",
    "        for d_r in disease_ratios:\n",
    "            d_r = d_r * 100\n",
    "            sub = df[df[\"disease_ratio\"] == d_r]\n",
    "            if sub.empty:\n",
    "                continue\n",
    "            sub = (sub.sort_values(meth, ascending=False)\n",
    "                       .drop_duplicates([\"disease\", \"site\", \"metric\", \"bundle\"]))\n",
    "            best = sub.head(top)\n",
    "            print(f\"\\n== {d_r:.0f}% ==\")\n",
    "            for _, row in best.iterrows():\n",
    "                print(f\"{row['disease']} | {row['site']} | {row['metric']} | {row['bundle']} : {row[meth]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_c = [\n",
    "        'site', 'disease', 'metric', 'bundle',\n",
    "        'num_patients', 'disease_ratio', 'num_diseased', \"raw\", \"NoRobust\"\n",
    "    ]\n",
    "\n",
    "methodi = [c for c in diff_df_smape.columns if c not in context_c]\n",
    "top_df = meilleurs_par_methode(diff_df_std.reset_index(), methodi, top=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = meilleurs_par_methode_site(diff_df_std.reset_index(), methodi, top=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# 0. CONFIG DE BASE\n",
    "# =============================================================\n",
    "df   = pivot_df_std.reset_index()         # ton DataFrame initial\n",
    "folder = os.path.join(ANALYSIS_FOLDER, 'METHODS_STATS')\n",
    "\n",
    "site_cols = ['site', 'disease', 'metric', 'bundle',\n",
    "             'num_patients', 'disease_ratio', 'num_diseased']\n",
    "refs = ['NoRobust', 'hc']\n",
    "method_cols = [c for c in df.columns if c not in site_cols + refs]\n",
    "\n",
    "LABELS4 = ['M > HC et No', 'No > M > HC',\n",
    "           'HC > M > No', 'HC et No > M']\n",
    "COLORS4 = ['red', 'green', 'yellow', 'pink']\n",
    "LABEL5  = '2+3+4'\n",
    "COLOR5  = 'purple'      # couleur pour le Scénario 5\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 1. CLASSIFY & SUMMARY\n",
    "# =============================================================\n",
    "def classify(row, meth):\n",
    "    m, hc, nr = row[meth], row['hc'], row['NoRobust']\n",
    "    if m >  hc and m >  nr: return 1\n",
    "    if m >= hc and m <= nr: return 2\n",
    "    if m <= hc and m >= nr: return 3\n",
    "    if m <  hc and m <  nr: return 4\n",
    "    return 0                           # égaux ou hors-scope\n",
    "\n",
    "def summarize(df_sub, meths):\n",
    "    \"\"\"Retourne un DataFrame indexé par (method, disease_ratio)\n",
    "       avec s1…s5_perc / s1…s5_mean_diff.\"\"\"\n",
    "    rows = []\n",
    "    for meth in meths:\n",
    "        scen = df_sub.apply(classify, axis=1, meth=meth)\n",
    "        dn   = df_sub[meth] - df_sub['NoRobust']   # diff Scénarios 1-2-4\n",
    "        dh   = df_sub[meth] - df_sub['hc']         # diff Scénario 3\n",
    "        for ratio, dfr in df_sub.groupby('disease_ratio'):\n",
    "            mask_r  = scen.index.isin(dfr.index)\n",
    "            scen_r  = scen[mask_r]\n",
    "            dn_r, dh_r = dn[mask_r], dh[mask_r]\n",
    "\n",
    "            stats = {'method': meth, 'disease_ratio': ratio}\n",
    "            # Scénarios 1 à 4\n",
    "            for s in (1, 2, 3, 4):\n",
    "                msk = scen_r == s\n",
    "                n   = msk.sum()\n",
    "                if n == 0:\n",
    "                    stats[f's{s}_perc']      = 0\n",
    "                    stats[f's{s}_mean_diff'] = None\n",
    "                    continue\n",
    "                diff = dn_r[msk] if s in (1, 2, 4) else dh_r[msk]\n",
    "                stats[f's{s}_perc']      = 100 * n / len(dfr)\n",
    "                stats[f's{s}_mean_diff'] = diff.mean()\n",
    "\n",
    "            # Scénario 5  = union 2,3,4\n",
    "            msk_5 = scen_r.isin([2, 3, 4])\n",
    "            n5 = msk_5.sum()\n",
    "            if n5 == 0:\n",
    "                stats['s5_perc']      = 0\n",
    "                stats['s5_mean_diff'] = None\n",
    "            else:\n",
    "                # composer la diff pour chaque ligne (switch sur le s)\n",
    "                diff_vec = pd.Series(index=scen_r.index, dtype=float)\n",
    "                m24 = scen_r.isin([2, 4])\n",
    "                diff_vec[m24] = dn_r[m24]\n",
    "                diff_vec[scen_r == 3] = dh_r[scen_r == 3]\n",
    "                stats['s5_perc']      = 100 * n5 / len(dfr)\n",
    "                stats['s5_mean_diff'] = diff_vec[msk_5].mean()\n",
    "\n",
    "            rows.append(stats)\n",
    "    return pd.DataFrame(rows).set_index(['method', 'disease_ratio'])\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 2. PLOTS (param include_s5)\n",
    "# =============================================================\n",
    "def stacked_perc(df_plot, title, out_path, include_s5=False):\n",
    "    cols = ['s1_perc','s2_perc','s3_perc','s4_perc']\n",
    "    lbls = LABELS4\n",
    "    cols_col = COLORS4\n",
    "    if include_s5:\n",
    "        cols.append('s5_perc')\n",
    "        lbls = LABELS4 + [LABEL5]\n",
    "        cols_col = COLORS4 + [COLOR5]\n",
    "\n",
    "    df_plot[cols].rename(columns=dict(zip(cols, lbls))) \\\n",
    "          .plot(kind='bar', stacked=True, color=cols_col,\n",
    "                edgecolor='black', linewidth=0.5, figsize=(10,6))\n",
    "    plt.ylabel('% des cas'); plt.xlabel('disease_ratio')\n",
    "    plt.title(title); plt.legend(lbls, bbox_to_anchor=(1.02,1),\n",
    "                                 loc='upper left', title='Scénarios')\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150)\n",
    "    plt.close(); print('Sauvé :', out_path)\n",
    "\n",
    "def bar_mean(df_plot, title, out_path, include_s5=False):\n",
    "    cols = ['s1_mean_diff','s2_mean_diff','s3_mean_diff','s4_mean_diff']\n",
    "    lbls = LABELS4\n",
    "    cols_col = COLORS4\n",
    "    if include_s5:\n",
    "        cols.append('s5_mean_diff')\n",
    "        lbls = LABELS4 + [LABEL5]\n",
    "        cols_col = COLORS4 + [COLOR5]\n",
    "\n",
    "    df_plot[cols].rename(columns=dict(zip(cols, lbls))) \\\n",
    "          .plot(kind='bar', color=cols_col, edgecolor='black',\n",
    "                linewidth=0.5, figsize=(10,6))\n",
    "    plt.ylabel('Différence moyenne'); plt.xlabel('disease_ratio')\n",
    "    plt.title(title)#; plt.axhline(0, ls='--', lw=0.7, c='grey')\n",
    "    plt.legend(lbls, bbox_to_anchor=(1.02,1), loc='upper left',\n",
    "               title='Scénarios')\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150)\n",
    "    plt.close(); print('Sauvé :', out_path)\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 3. RUN  : GLOBAL + PAR RATIO + PAR MÉTHODE + MÉTHODE×MALADIE\n",
    "# =============================================================\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "smry_all = summarize(df, method_cols)\n",
    "\n",
    "# -- A) global (pas de Scénario 5)\n",
    "dir_ratio = os.path.join(folder, 'SCENARIOS_PROPORTIONS')\n",
    "os.makedirs(dir_ratio, exist_ok=True)\n",
    "stacked_perc(smry_all.groupby('method').mean(),\n",
    "             'Tous ratios', os.path.join(dir_ratio, 'scenarios_ALL.png'))\n",
    "\n",
    "# -- B) par disease_ratio (toujours sans Scénario 5)\n",
    "\n",
    "for ratio in smry_all.index.get_level_values(1).unique():\n",
    "    sub = smry_all.xs(ratio, level='disease_ratio')\n",
    "    f = f'scenarios_ratio_{str(ratio).replace(\".\",\"_\")}.png'\n",
    "    stacked_perc(sub, f'ratio {ratio}', os.path.join(dir_ratio, f))\n",
    "\n",
    "# -- C) METHOD_STATS (inclut Scénario 5)\n",
    "dir_method = os.path.join(folder, 'METHOD_STATS')\n",
    "os.makedirs(dir_method, exist_ok=True)\n",
    "for meth in method_cols:\n",
    "    sm = smry_all.xs(meth, level='method')\n",
    "    stacked_perc(sm, f'Scénarios – {meth}',\n",
    "                 os.path.join(dir_method, f'{meth}_scenario_perc.png'),\n",
    "                 include_s5=False)\n",
    "    bar_mean(sm, f'Différence moyenne – {meth}',\n",
    "             os.path.join(dir_method, f'{meth}_mean_diff.png'),\n",
    "             include_s5=True)\n",
    "\n",
    "# -- D) METHOD_STATS_BY_DISEASE (inclut Scénario 5)\n",
    "dir_md_dis = os.path.join(folder, 'METHOD_STATS_BY_DISEASE')\n",
    "for meth in method_cols:\n",
    "    safe_m = re.sub(r'[^A-Za-z0-9_\\-\\.]', '_', meth)\n",
    "    for dis in df['disease'].dropna().unique():\n",
    "        subset = df[df['disease'] == dis]\n",
    "        sm = summarize(subset, [meth]).xs(meth, level='method')\n",
    "        if sm.empty: continue\n",
    "        safe_d = re.sub(r'[^A-Za-z0-9_\\-\\.]', '_', dis)\n",
    "        outdir = os.path.join(dir_md_dis, safe_m, safe_d)\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        stacked_perc(sm, f'% Scénarios – {meth} – {dis}',\n",
    "                     os.path.join(outdir, f'{safe_m}_{safe_d}_scenario_perc.png'),\n",
    "                     include_s5=False)\n",
    "        bar_mean(sm, f'Mean diff – {meth} – {dis}',\n",
    "                 os.path.join(outdir, f'{safe_m}_{safe_d}_mean_diff.png'),\n",
    "                 include_s5=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
