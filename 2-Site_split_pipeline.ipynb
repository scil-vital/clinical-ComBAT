{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation split (all / mlp / harmonized) par patient\n",
    "\n",
    "On coupe les compilations en deux moitiés en garantissant qu'un même `sid` \n",
    "(patient) reste toujours dans la même moitié pour **toutes** les métriques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from robust_evaluation_tools.synthectic_sites_generations import augment_df\n",
    "\n",
    "# Paramètres principaux\n",
    "METHOD_TAG = \"classic\"\n",
    "STRAT_COL = \"disease\"\n",
    "RANDOM_STATE = 13\n",
    "AUGMENT_COPIES = 5  # nombre total de copies (original inclus) pour l'augmentation\n",
    "\n",
    "# Répertoires\n",
    "PROCESSED_ROOT = Path(\"DONNES\") / \"processed\"\n",
    "COMPILATION_DIR = PROCESSED_ROOT / \"compilation\" / METHOD_TAG\n",
    "ALL_DIR = COMPILATION_DIR / \"all\"\n",
    "MLP_DIR = COMPILATION_DIR / \"mlp\"\n",
    "HARMONIZED_DIR = COMPILATION_DIR / \"harmonized\"\n",
    "MASTER_FILE = ALL_DIR / \"compilation.all_metrics.csv.gz\"\n",
    "MASTER_FILE_CAMCAN = ALL_DIR / \"compilation.all_metrics.with_camcan.csv.gz\"\n",
    "\n",
    "for path in [ALL_DIR, MLP_DIR, HARMONIZED_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Input (all): {ALL_DIR}\")\n",
    "print(f\"MLP split -> {MLP_DIR}\")\n",
    "print(f\"Harmonized split -> {HARMONIZED_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disease_ratio(df, strat_col=STRAT_COL):\n",
    "    return (\n",
    "        df[strat_col]\n",
    "        .value_counts(normalize=True)\n",
    "        .sort_index()\n",
    "        .round(4)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "\n",
    "def build_sid_split(master_path=MASTER_FILE, strat_col=STRAT_COL):\n",
    "    if not master_path.exists():\n",
    "        raise FileNotFoundError(f\"Master file introuvable: {master_path}\")\n",
    "\n",
    "    base = pd.read_csv(master_path, usecols=[\"sid\", strat_col]).drop_duplicates()\n",
    "    mlp_sids, harmonized_sids = [], []\n",
    "    toggle_extra = True\n",
    "    for _, group in base.groupby(strat_col):\n",
    "        shuffled = group.sample(frac=1, random_state=RANDOM_STATE)\n",
    "        split_point = len(shuffled) // 2\n",
    "        if len(shuffled) % 2:  # répartir l'item en trop en alternance\n",
    "            if toggle_extra:\n",
    "                split_point += 1\n",
    "            toggle_extra = not toggle_extra\n",
    "        mlp_sids.extend(shuffled[\"sid\"].iloc[:split_point])\n",
    "        harmonized_sids.extend(shuffled[\"sid\"].iloc[split_point:])\n",
    "    mlp_sids, harmonized_sids = set(mlp_sids), set(harmonized_sids)\n",
    "    overlap = mlp_sids & harmonized_sids\n",
    "    if overlap:\n",
    "        raise ValueError(\n",
    "            f\"Les sids apparaissent dans les deux splits: {sorted(list(overlap))[:5]}\"\n",
    "        )\n",
    "    return base, mlp_sids, harmonized_sids\n",
    "\n",
    "\n",
    "def split_and_save(input_path, mlp_sids, harmonized_sids, master_ratio):\n",
    "    df = pd.read_csv(input_path)\n",
    "    if \"old_site\" not in df.columns:\n",
    "        if \"site\" in df.columns:\n",
    "            df[\"old_site\"] = df[\"site\"]\n",
    "        elif \"source_site\" in df.columns:\n",
    "            df[\"old_site\"] = df[\"source_site\"]\n",
    "        else:\n",
    "            print(\n",
    "                f\"[warn] {input_path.name} : colonne 'site' absente, impossible de renseigner old_site\"\n",
    "            )\n",
    "    if \"sid\" not in df.columns:\n",
    "        print(f\"[skip] {input_path.name} : colonne 'sid' absente\")\n",
    "        return None\n",
    "    if STRAT_COL not in df.columns:\n",
    "        print(f\"[skip] {input_path.name} : colonne '{STRAT_COL}' absente\")\n",
    "        return None\n",
    "\n",
    "    file_sids = set(df[\"sid\"].unique())\n",
    "    extra_sids = file_sids - mlp_sids - harmonized_sids\n",
    "    if extra_sids:\n",
    "        print(f\"[warn] {input_path.name}: {len(extra_sids)} sid hors master split\")\n",
    "    mlp_df = df[df[\"sid\"].isin(mlp_sids)]\n",
    "    harmonized_df = df[df[\"sid\"].isin(harmonized_sids)]\n",
    "\n",
    "    mlp_path = MLP_DIR / input_path.name\n",
    "    harmonized_path = HARMONIZED_DIR / input_path.name\n",
    "    mlp_df.to_csv(mlp_path, index=False, compression=\"gzip\")\n",
    "    harmonized_df.to_csv(harmonized_path, index=False, compression=\"gzip\")\n",
    "\n",
    "    return {\n",
    "        \"file\": input_path.name,\n",
    "        \"rows_in\": len(df),\n",
    "        \"rows_mlp\": len(mlp_df),\n",
    "        \"rows_harmonized\": len(harmonized_df),\n",
    "        \"ratio_master\": master_ratio,\n",
    "        \"ratio_in\": disease_ratio(df),\n",
    "        \"ratio_mlp\": disease_ratio(mlp_df),\n",
    "        \"ratio_harmonized\": disease_ratio(harmonized_df),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire les splits master sur les sids (avec/sans CamCAN)\n",
    "split_configs = [\n",
    "    {\n",
    "        \"name\": \"standard\",\n",
    "        \"master_path\": MASTER_FILE,\n",
    "        \"file_filter\": lambda path: \"with_camcan\" not in path.name,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"with_camcan\",\n",
    "        \"master_path\": MASTER_FILE_CAMCAN,\n",
    "        \"file_filter\": lambda path: \"with_camcan\" in path.name,\n",
    "    },\n",
    "]\n",
    "\n",
    "summaries = []\n",
    "for config in split_configs:\n",
    "    master_path = config[\"master_path\"]\n",
    "    if not master_path.exists():\n",
    "        print(f\"[skip] Master file introuvable pour {config['name']}: {master_path}\")\n",
    "        continue\n",
    "\n",
    "    master_df, MLP_SIDS, HARMONIZED_SIDS = build_sid_split(master_path=master_path)\n",
    "    master_ratio = disease_ratio(master_df)\n",
    "    print(\n",
    "        f\"[{config['name']}] Master sids -> MLP: {len(MLP_SIDS)} | Harmonized: {len(HARMONIZED_SIDS)}\"\n",
    "    )\n",
    "    print(f\"[{config['name']}] Ratios master (disease): {master_ratio}\")\n",
    "\n",
    "    compilation_files = [\n",
    "        path\n",
    "        for path in sorted(ALL_DIR.glob(\"compilation.*.csv.gz\"))\n",
    "        if config[\"file_filter\"](path)\n",
    "    ]\n",
    "\n",
    "    print(f\"[{config['name']}] {len(compilation_files)} fichiers à couper\")\n",
    "    for file_path in compilation_files:\n",
    "        summary = split_and_save(file_path, MLP_SIDS, HARMONIZED_SIDS, master_ratio)\n",
    "        if summary:\n",
    "            summary[\"split\"] = config[\"name\"]\n",
    "            summaries.append(summary)\n",
    "\n",
    "summary_df = pd.DataFrame(summaries)\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmenter les datasets splittés en garantissant des deltas cohérents par sid\n",
    "\n",
    "def build_sid_augmentations(sids, copies=AUGMENT_COPIES, random_state=RANDOM_STATE):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    return {sid: rng.choice([-1, 1], size=copies - 1) for sid in sorted(sids)}\n",
    "\n",
    "\n",
    "def apply_aug_with_mapping(df, sid_aug_map, copies=AUGMENT_COPIES):\n",
    "    augmented = [df]\n",
    "    for copy_idx in range(1, copies):\n",
    "        temp = df.copy()\n",
    "        temp_age = []\n",
    "        for _, row in temp.iterrows():\n",
    "            deltas = sid_aug_map.get(row[\"sid\"])\n",
    "            delta = deltas[copy_idx - 1] if deltas is not None else 0\n",
    "            temp_age.append(row[\"age\"] + delta)\n",
    "        temp[\"age\"] = temp_age\n",
    "        temp[\"sid\"] = temp[\"sid\"].astype(str) + f\"_aug{copy_idx}\"\n",
    "        if \"mean\" in temp.columns:\n",
    "            temp[\"mean\"] = temp[\"mean\"] * (\n",
    "                1\n",
    "                + np.random.default_rng(RANDOM_STATE + copy_idx).choice(\n",
    "                    [-0.02, -0.01, 0.01, 0.02], size=len(temp)\n",
    "                )\n",
    "            )\n",
    "        augmented.append(temp)\n",
    "    return pd.concat(augmented, ignore_index=True)\n",
    "\n",
    "\n",
    "def augment_folder_consistent(src_dir, copies=AUGMENT_COPIES, master_filename=\"compilation.all_metrics.csv.gz\"):\n",
    "    src_dir = Path(src_dir)\n",
    "    dst_dir = src_dir.parent / f\"{src_dir.name}_AUG_{copies}\"\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    master_path = src_dir / master_filename\n",
    "    if not master_path.exists():\n",
    "        print(f\"[skip] master de référence introuvable dans {src_dir}: {master_filename}\")\n",
    "        return\n",
    "\n",
    "    master_df = pd.read_csv(master_path, usecols=[\"sid\", \"age\"])\n",
    "    sid_aug_map = build_sid_augmentations(master_df[\"sid\"].unique(), copies=copies)\n",
    "\n",
    "    written = 0\n",
    "    for file_path in sorted(src_dir.glob(\"*.csv.gz\")):\n",
    "        df = pd.read_csv(file_path)\n",
    "        aug_df = apply_aug_with_mapping(df, sid_aug_map, copies=copies)\n",
    "        compression = \"gzip\" if file_path.suffixes and file_path.suffixes[-1] == \".gz\" else None\n",
    "        out_path = dst_dir / file_path.name\n",
    "        aug_df.to_csv(out_path, index=False, compression=compression)\n",
    "        written += 1\n",
    "    print(f\"[augment] {written} fichiers écrits dans {dst_dir}\")\n",
    "\n",
    "augment_folder_consistent(MLP_DIR)\n",
    "augment_folder_consistent(HARMONIZED_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
