{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS and UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from scripts import combat_info\n",
    "from scripts import combat_quick_apply\n",
    "from scripts import combat_quick_QC\n",
    "from robust_evaluation_tools.robust_utils import get_site, robust_text, rwp_text, get_camcan_file, get_diseases, get_metrics, add_nb_patients_and_diseased, get_disease, remove_covariates_effects\n",
    "from robust_evaluation_tools.robust_harmonization import fit, apply, visualize_harmonization, QC, compare_with_compilation, create_presentation, compare_distances\n",
    "from robust_evaluation_tools.synthectic_sites_generations import generate_sites\n",
    "from robust_evaluation_tools.robust_outlier_detection import scatter_plot_with_colors, find_outliers, get_matching_indexes\n",
    "\n",
    "MAINFOLDER = \"RESULTS/SEUIL\"\n",
    "SYNTHETIC_SITES = f\"{MAINFOLDER}/SYNTHETIC_SITES\"\n",
    "\n",
    "ANALYSIS_FOLDER = f\"{MAINFOLDER}/ANALYSIS\"\n",
    "\n",
    "robust_methods_for_analysis = ['TOP5', 'TOP10', 'TOP20', 'TOP30','TOP40', 'TOP50',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HARMONIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, directory, robust, rwp,hc, disease, sample_size, disease_ratio, test_index):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f_train)\n",
    "    \n",
    "    # Fit the model\n",
    "    output_model_filename = fit(f_train, ref_data_file, metric, harmonizartion_method, robust, rwp, directory, hc,)\n",
    "    # Apply the model\n",
    "    output_filename = apply(f_test, output_model_filename, metric, harmonizartion_method, robust, rwp, directory)\n",
    "    \n",
    "    # Visualize the harmonization\n",
    "    visualize_harmonization(f_test, output_filename, ref_data_file, directory, bundles = '')\n",
    "    mae = compare_with_compilation(pd.read_csv(output_filename))\n",
    "    if robust != \"No\":\n",
    "        outliers_idx = get_matching_indexes(f_train, os.path.join(directory,f'outliers_{sample_size}_patients_{int(disease_ratio*100)}_percent_{test_index}_{robust_text(robust)}_{rwp_text(rwp)}.csv'))\n",
    "        df = pd.read_csv(f_train)\n",
    "        df_no_cov = remove_covariates_effects(df)\n",
    "        df_no_cov = df_no_cov.loc[df.index]\n",
    "        scatter_plot_with_colors(\n",
    "            df_no_cov, outliers_idx, 'mean_no_cov', os.path.join(directory,'SCATTER_PLOT'),\n",
    "            f'Scatter_{robust_text(robust)}_{rwp_text(rwp)},_{disease}_{sample_size}_{int(disease_ratio*100)}_{test_index}',\n",
    "            f'Scatter for method {robust} disease: {disease}, with {sample_size} patients, {disease_ratio * 100} % of sick #{test_index}'\n",
    "        )\n",
    "    \n",
    "    mae['site'] = get_site(f_train)\n",
    "    \n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_site(f_train,f_test, robust, directory, ref_data_file, metric,harmonizartion_method, disease, sample_size, disease_ratio, test_index):\n",
    "    # 4 harmonization\n",
    "    harmonization_hc = harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, os.path.join(directory, \"hc\"), \"No\", False, True, disease, sample_size, disease_ratio, test_index)\n",
    "    harmonization_no_robust = harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, os.path.join(directory, \"NoRobust\"), \"No\", False, False, disease, sample_size, disease_ratio, test_index)\n",
    "    harmonization_robust = harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, os.path.join(directory, \"robust\"), robust, False, False, disease, sample_size, disease_ratio, test_index)\n",
    "    harmonization_robust_rwp = harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, os.path.join(directory, \"robust_rwp\"), robust, True, False, disease, sample_size, disease_ratio, test_index)\n",
    "\n",
    "\n",
    "    #create_presentation(directory, harmonizartion_method)\n",
    "\n",
    "    # Combine MEA in a single DataFrame\n",
    "    mea_combined = pd.concat([harmonization_hc, harmonization_no_robust, harmonization_robust, harmonization_robust_rwp], ignore_index=True)\n",
    "    mea_combined['method'] = ['hc', 'no_robust', 'robust', 'robust_rwp']\n",
    "\n",
    "\n",
    "    #TODO bundles et analyze outliers\n",
    "    return mea_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to analyze a single (sample_size, disease_ratio) combination\n",
    "def process_analysis(disease, metric, sample_size, disease_ratio,harmonization_method, robust_method, SYNTHETIC_SITES_VERSION, num_tests):\n",
    "    directory = os.path.join(MAINFOLDER, robust_method, disease, metric)\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION,disease)\n",
    "    \n",
    "    sizeDir = os.path.join(directory, f\"{sample_size}_{int(disease_ratio * 100)}\")\n",
    "    sizeDir_site = os.path.join(directory_site, f\"{sample_size}_{int(disease_ratio * 100)}\")\n",
    "\n",
    "    mea_compilation = pd.DataFrame()\n",
    "\n",
    "    for test_index in range(num_tests):\n",
    "        tempDir = os.path.join(sizeDir, f\"{test_index}\")\n",
    "        tempDir_site = os.path.join(sizeDir_site, f\"{test_index}\")\n",
    "        os.makedirs(tempDir, exist_ok=True)\n",
    "\n",
    "        train_file_name = f\"train_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\"\n",
    "        test_file_name = f\"test_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\"\n",
    "\n",
    "        # Load and save training dataset\n",
    "        train_file = os.path.join(tempDir_site, train_file_name)\n",
    "        train_df = pd.read_csv(train_file)\n",
    "        train_df = train_df[~train_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "        train_df = train_df.drop(columns=['mean_no_cov', 'metric_bundle'])\n",
    "        new_train_file = os.path.join(tempDir, train_file_name)\n",
    "        train_df.to_csv(new_train_file, index=False)\n",
    "        \n",
    "\n",
    "        # Load and save test dataset\n",
    "        test_file = os.path.join(tempDir_site, test_file_name)\n",
    "        test_df = pd.read_csv(test_file)\n",
    "        test_df = test_df[~test_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "        test_df = test_df.drop(columns=['mean_no_cov', 'metric_bundle'])\n",
    "        new_test_file = os.path.join(tempDir, test_file_name)\n",
    "        test_df.to_csv(new_test_file, index=False)\n",
    "\n",
    "        ref_data_file = get_camcan_file(metric)\n",
    "\n",
    "        # Analyze the site\n",
    "        mea_analyze = analyse_site(\n",
    "            new_train_file, new_test_file, robust_method, tempDir, ref_data_file, metric, harmonization_method , disease, sample_size, disease_ratio, test_index\n",
    "        )\n",
    "\n",
    "        outliers_idx = find_outliers(pd.read_csv(train_file), robust_method)\n",
    "\n",
    "        scatter_plot_with_colors(\n",
    "            pd.read_csv(train_file), outliers_idx, 'mean_no_cov', os.path.join(sizeDir,'SCATTER_PLOT'),\n",
    "            f'Scatter_{robust_method}_{disease}_{sample_size}_{int(disease_ratio*100)}_{test_index}',\n",
    "            f'Scatter for method {robust_method} disease: {disease}, with {sample_size} patients, {disease_ratio * 100} % of sick #{test_index}'\n",
    "        )\n",
    "\n",
    "        # df = pd.read_csv(new_train_file)\n",
    "        # df_no_cov = remove_covariates_effects(df)\n",
    "\n",
    "        # print(f\"Outliers {df_no_cov['bundle'].iloc[0]} 'sid':\", df_no_cov.loc[outliers_idx]['sid'].tolist())\n",
    "\n",
    "        # scatter_plot_with_colors(\n",
    "        #     df_no_cov , outliers_idx, 'mean_no_cov', os.path.join(sizeDir,'SCATTER_PLOT'),\n",
    "        #     f'Scatter_{robust_method}_{disease}_{sample_size}_{int(disease_ratio*100)}_{test_index}',\n",
    "        #     f'Scatter for method {robust_method} disease: {disease}, with {sample_size} patients, {disease_ratio * 100} % of sick #{test_index}'\n",
    "        # )\n",
    "\n",
    "\n",
    "\n",
    "        mea_analyze['robust_method'] = robust_method\n",
    "        mea_analyze['disease'] = disease\n",
    "        mea_analyze['metric'] = metric\n",
    "        mea_compilation = pd.concat([mea_compilation, mea_analyze], ignore_index=True)\n",
    "\n",
    "    # Save results for this combination\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    mea_compilation.to_csv(os.path.join(sizeDir, \"mea_compilation.csv\"), index=False)\n",
    "\n",
    "    return os.path.join(sizeDir, \"mea_compilation.csv\")\n",
    "\n",
    "# Parallelized analysis method (excluding num_tests from parallelization)\n",
    "def analyse_method(sample_sizes, disease_ratios, num_tests, robust_methods,diseases, metrics, harmonization_method, SYNTHETIC_SITES_VERSION):\n",
    "    # Generate all task combinations (excluding num_tests)\n",
    "    tasks = [\n",
    "        (disease,metric, sample_size, disease_ratio,harmonization_method, robust_method, SYNTHETIC_SITES_VERSION, num_tests)\n",
    "        for robust_method in robust_methods\n",
    "        for disease in diseases\n",
    "        for sample_size in sample_sizes\n",
    "        for disease_ratio in disease_ratios\n",
    "        for metric in metrics\n",
    "    ]\n",
    "\n",
    "    # Run all combinations in parallel and collect file paths\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_analysis)(*task) for task in tasks)\n",
    "\n",
    "    mea_compilation = pd.concat([pd.read_csv(file) for file in results], ignore_index=True)\n",
    "\n",
    "    # Save final compiled results\n",
    "    directory = os.path.join(MAINFOLDER)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    mea_compilation.to_csv(os.path.join(directory, \"mea_compilation.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sites_for_disease(disease, SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, sample_sizes, disease_ratios, num_tests):\n",
    "    # Load data for the disease\n",
    "    data_path = path = os.path.join('DONNES','COMPILATIONS_AUG_3', f'{disease}_combination_all_metrics_CamCAN.csv.gz')\n",
    "\n",
    "    # Define site directory\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, disease)\n",
    "\n",
    "    # Generate synthetic sites\n",
    "    generate_sites(sample_sizes, disease_ratios, num_tests, directory_site, data_path, disease=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonization_method= \"classic\"\n",
    "\n",
    "SYNTHETIC_SITES_VERSION = \"v1\"\n",
    "\n",
    "metrics = get_metrics()\n",
    "#diseases = get_diseases(True)\n",
    "diseases = [\"SYN_2\"]\n",
    "robust_methods = [\"TOP5\", \"TOP10\", \"TOP20\", \"TOP30\", \"TOP40\", \"TOP50\", 'CHEAT']\n",
    "\n",
    "\n",
    "sample_sizes = [100]  # Différentes tailles d'échantillon\n",
    "disease_ratios = [0.1, 0.3, 0.5]  # Différents pourcentages de malades\n",
    "num_tests = 6  # Nombre de tests à effectuer pour chaque combinaison\n",
    "\n",
    "# Parallel(n_jobs=-1)(\n",
    "#     delayed(generate_sites_for_disease)(disease, SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, sample_sizes, disease_ratios, num_tests)\n",
    "#     for disease in diseases\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_method(sample_sizes, disease_ratios, num_tests, robust_methods,diseases, metrics, harmonization_method, SYNTHETIC_SITES_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier principal\n",
    "mea_compilation = pd.read_csv(os.path.join(MAINFOLDER, \"mea_compilation.csv\"))\n",
    "\n",
    "# Récupérer les méthodes uniques\n",
    "methods = mea_compilation['robust_method'].unique()\n",
    "\n",
    "# Sauvegarder un fichier CSV pour chaque méthode\n",
    "for method in methods:\n",
    "    # Filtrer les lignes correspondant à la méthode\n",
    "    method_df = mea_compilation[mea_compilation['robust_method'] == method]\n",
    "    \n",
    "    # Créer un dossier pour la méthode\n",
    "    method_directory = os.path.join(MAINFOLDER, method)\n",
    "    os.makedirs(method_directory, exist_ok=True)\n",
    "    \n",
    "    # Sauvegarder le fichier CSV dans le dossier\n",
    "    method_file_path = os.path.join(method_directory, f\"{method}_mea_compilation.csv\")\n",
    "    method_df.to_csv(method_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_all_method_files(main_folder, methods):\n",
    "    all_dfs = []\n",
    "    for m in methods:\n",
    "        path = os.path.join(main_folder, m, f\"{m}_mea_compilation.csv\")\n",
    "        if os.path.exists(path):\n",
    "            df = pd.read_csv(path)\n",
    "            all_dfs.append(df)\n",
    "    return pd.concat(all_dfs, ignore_index=True) if all_dfs else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69722.89s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69723.06s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69723.23s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69723.39s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69723.56s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69723.73s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69723.90s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69724.06s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69724.23s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69724.40s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69724.57s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69724.74s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69724.90s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69725.08s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69725.24s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69725.42s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69725.58s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69725.75s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69725.92s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69726.09s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69726.26s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69726.43s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69726.60s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "69726.77s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def plot_mea(df, sample_size, disease, metric, directory):\n",
    "    directory = os.path.join(directory, \"MAE_PLOTS\", disease, metric, str(sample_size))\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    df_filtered = df[\n",
    "        (df['num_patients'] == sample_size) & \n",
    "        (df['disease'] == disease) & \n",
    "        (df['metric'] == metric)\n",
    "    ]\n",
    "\n",
    "    # Méthodes de base + méthodes robustes\n",
    "    robust_methods = df_filtered['robust_method'].dropna().unique()\n",
    "    base_methods = [\"hc\", \"no_robust\"]\n",
    "    robust_base_methods = [\"robust\",]\n",
    "    methods = base_methods + [f\"{rb}_{rm}\" for rb in robust_base_methods for rm in robust_methods]\n",
    "    \n",
    "    # Couleurs\n",
    "    method_colors = {\n",
    "        \"hc\": \"green\",\n",
    "        \"no_robust\": \"red\"\n",
    "    }\n",
    "    robust_palette = sns.color_palette(\"viridis\", len(robust_methods))\n",
    "    robust_rwp_palette = sns.color_palette(\"magma\", len(robust_methods))\n",
    "    for i, rm in enumerate(robust_methods):\n",
    "        method_colors[f\"robust_{rm}\"] = robust_palette[i]\n",
    "        method_colors[f\"robust_rwp_{rm}\"] = robust_rwp_palette[i]\n",
    "\n",
    "    # Boucle sur les \"bundles\"\n",
    "    for bundle_column in df_filtered.columns:\n",
    "        # On ignore les colonnes non-numériques\n",
    "        if bundle_column in ['site', 'method', 'num_patients', 'disease_ratio',\n",
    "                             'num_diseased', 'metric', 'disease', 'robust_method']:\n",
    "            continue\n",
    "\n",
    "        bundle_df = df_filtered[[bundle_column, 'site', 'method', 'num_patients',\n",
    "                                 'disease_ratio', 'num_diseased', 'robust_method']].copy()\n",
    "        unique_ratios = sorted(bundle_df['disease_ratio'].unique())  # Trié pour être sûr de l'ordre\n",
    "\n",
    "        # *** ICI on paramètre la figure + le positionnement ***\n",
    "        fig, ax = plt.subplots(figsize=(14, 7))  # Ajuster au besoin\n",
    "\n",
    "        # Abscisses pour chaque ratio\n",
    "        x = np.arange(len(unique_ratios))\n",
    "        \n",
    "        # Largeur totale allouée pour le « groupe » de méthodes à chaque ratio\n",
    "        group_width = 0.8  \n",
    "        # On répartit cette largeur entre toutes les méthodes\n",
    "        n_methods = len(methods)\n",
    "        box_width = group_width / n_methods\n",
    "\n",
    "        # Tracé des boxplots pour chaque méthode\n",
    "        for i_m, method in enumerate(methods):\n",
    "            if \"_\" in method and method != \"no_robust\":\n",
    "                method_base, robust_type = method.rsplit(\"_\", 1)\n",
    "                method_df = bundle_df[\n",
    "                    (bundle_df['method'] == method_base) & \n",
    "                    (bundle_df['robust_method'] == robust_type)\n",
    "                ]\n",
    "            else:\n",
    "                method_df = bundle_df[bundle_df['method'] == method]\n",
    "\n",
    "            # On prépare la liste de valeurs par ratio\n",
    "            data = [\n",
    "                method_df[method_df['disease_ratio'] == ratio][bundle_column].values \n",
    "                for ratio in unique_ratios\n",
    "            ]\n",
    "\n",
    "            # Positions: on centre autour de chaque x\n",
    "            # Exemple: x - group_width/2 + (i_m+0.5)*box_width\n",
    "            positions = x - group_width/2 + (i_m + 0.5)*box_width\n",
    "\n",
    "            color = method_colors.get(method, \"black\")\n",
    "            \n",
    "            # S’il y a au moins un point de données\n",
    "            if any(len(d) > 0 for d in data):\n",
    "                ax.boxplot(\n",
    "                    data,\n",
    "                    positions=positions,\n",
    "                    widths=box_width * 0.8,  # Légèrement plus petit que box_width\n",
    "                    patch_artist=True,\n",
    "                    boxprops=dict(facecolor=color, color=color),\n",
    "                    medianprops=dict(color='black')\n",
    "                )\n",
    "\n",
    "        ax.set_xlabel('Prct de patients malades')\n",
    "        ax.set_ylabel('MAE')\n",
    "        ax.set_title(\n",
    "            f\"MAE de l'harmonization selon le pourcentage de patients malades\\n\"\n",
    "            f\"Maladie: {disease}  |  Metric: {metric}  |  Bundle: {bundle_column}\\n\"\n",
    "            f\"Nb patient total: {sample_size}\"\n",
    "        )\n",
    "\n",
    "        # On place les ticks au milieu de chaque groupe (i.e. sur x)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(unique_ratios)\n",
    "\n",
    "        # Légende manuelle\n",
    "        legend_handles = [\n",
    "            plt.Line2D([0], [0], color=method_colors[m], lw=3, label=f'Method: {m}')\n",
    "            for m in methods\n",
    "        ]\n",
    "        ax.legend(handles=legend_handles, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(directory, f'{bundle_column}_boxplot.png'), bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "mea_df = gather_all_method_files(MAINFOLDER, robust_methods_for_analysis)\n",
    "add_nb_patients_and_diseased(mea_df)\n",
    "\n",
    "# Generate all task combinations\n",
    "tasks = [\n",
    "    (mea_df, sample_size, disease, metric, ANALYSIS_FOLDER)\n",
    "    for disease in diseases\n",
    "    for sample_size in sample_sizes\n",
    "    for metric in metrics\n",
    "]\n",
    "\n",
    "# Run all tasks in parallel\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mea)(*task) for task in tasks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
