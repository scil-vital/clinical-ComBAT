{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS and UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from math import sqrt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from robust_evaluation_tools.robust_utils import get_complete_combination, get_metrics, get_diseases\n",
    "from robust_evaluation_tools.robust_outlier_detection import find_outliers, analyze_detection_performance\n",
    "from robust_evaluation_tools.synthectic_sites_generations import generate_sites\n",
    "from robust_evaluation_tools.robust_analysis import calculate_precision_by_bundle\n",
    "from clinical_combat.harmonization.QuickCombat import QuickCombat\n",
    "\n",
    "all_metrics = get_metrics()\n",
    "all_diseases = get_diseases(False)\n",
    "\n",
    "MAINFOLDER = \"RESULTS/DISTRIBUTION_ANALYSIS\"\n",
    "SYNTHETIC_SITES = f\"{MAINFOLDER}/SYNTHETIC_SITES\"\n",
    "\n",
    "ANALYSIS_FOLDER = \"ANALYSIS\"\n",
    "\n",
    "raw_directory = os.path.join('DONNES_F', 'COMPILATIONS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer la divergence KL\n",
    "def kl_divergence(p, q):\n",
    "    return entropy(p, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AFFICHE LES SCATTER PLOTS AU LIEU DES DISTRIBUZTIONS\n",
    "\n",
    "# # Assuming 'HC' is a specific value in the 'disease' column that indicates healthy controls\n",
    "# HC_LABEL = 'HC'\n",
    "\n",
    "# # Plot distribution for each bundle\n",
    "# for disease in all_diseases:\n",
    "#     combination = pd.read_csv(os.path.join(raw_directory, f'{disease}_combination_all_metrics_CamCAN.csv.gz'))\n",
    "#     metric_bundles = combination['metric_bundle'].unique()\n",
    "#     for metric_bundle in metric_bundles:\n",
    "#         subset_all = combination[combination['metric_bundle'] == metric_bundle]\n",
    "#         subset = subset_all[subset_all['old_site'] != 'CamCAN']\n",
    "#         bundle = subset_all.bundle.unique()[0]\n",
    "#         metric = subset_all.metric.unique()[0]\n",
    "#         camCan_subset = subset_all[subset_all['old_site'] == 'CamCAN']\n",
    "        \n",
    "#         # Scatter plot with mean\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.scatter(subset[subset['disease'] == HC_LABEL]['age'], subset[subset['disease'] == HC_LABEL]['mean'], color='blue', label='HC', alpha=0.5)\n",
    "#         plt.scatter(camCan_subset['age'], camCan_subset['mean'], color='green', label='CamCAN', alpha=0.5)\n",
    "#         plt.scatter(subset[subset['disease'] != HC_LABEL]['age'], subset[subset['disease'] != HC_LABEL]['mean'], color='red', label=f'{disease}', alpha=0.5)\n",
    "        \n",
    "#         plt.title(f'Distribution of {disease} in metric {metric} for bundle: {bundle} (mean)')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Mean')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "        \n",
    "#         # Scatter plot with mean_no_cov\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.scatter(subset[subset['disease'] == HC_LABEL]['age'], subset[subset['disease'] == HC_LABEL]['mean_no_cov'], color='blue', label='HC', alpha=0.5)\n",
    "#         plt.scatter(camCan_subset['age'], camCan_subset['mean_no_cov'], color='green', label='CamCAN', alpha=0.5)\n",
    "#         plt.scatter(subset[subset['disease'] != HC_LABEL]['age'], subset[subset['disease'] != HC_LABEL]['mean_no_cov'], color='red', label=f'{disease}', alpha=0.5)\n",
    "        \n",
    "#         plt.title(f'Distribution of {disease} in metric {metric} for bundle: {bundle} (mean_no_cov)')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Mean_no_cov')\n",
    "#         plt.legend()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFFICHE LES SCATTER PLOTS AU LIEU DES DISTRIBUZTIONS\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "HC_LABEL = 'HC'\n",
    "SCATTER_FOLDER = os.path.join(MAINFOLDER, 'COMPILATION_SCATTER_PLOTS')\n",
    "os.makedirs(SCATTER_FOLDER, exist_ok=True)\n",
    "\n",
    "\n",
    "def process_disease(disease, raw_directory, out_root):\n",
    "    combination = pd.read_csv(\n",
    "        os.path.join(raw_directory, f'{disease}_combination_all_metrics_CamCAN.csv.gz')\n",
    "    )\n",
    "\n",
    "    for metric_bundle, subset_all in combination.groupby('metric_bundle'):\n",
    "        subset = subset_all[subset_all['old_site'] != 'CamCAN']\n",
    "        bundle = subset_all.bundle.iloc[0]\n",
    "        metric = subset_all.metric.iloc[0]\n",
    "\n",
    "        if subset.empty:\n",
    "            continue\n",
    "\n",
    "        plot_specs = (\n",
    "            ('mean', 'Mean', False),\n",
    "            ('mean_no_cov', 'Mean (no covariates)', True),\n",
    "        )\n",
    "\n",
    "        for value_col, ylabel, with_marginals in plot_specs:\n",
    "            subset_plot = subset.dropna(subset=['age', value_col])\n",
    "            if subset_plot.empty:\n",
    "                continue\n",
    "\n",
    "            hc_mask = subset_plot['disease'] == HC_LABEL\n",
    "            patient_mask = subset_plot['disease'] != HC_LABEL\n",
    "\n",
    "            if with_marginals:\n",
    "                fig = plt.figure(figsize=(12, 6))\n",
    "                gs = fig.add_gridspec(1, 2, width_ratios=[4, 1], wspace=0.05)\n",
    "                ax = fig.add_subplot(gs[0])\n",
    "                ax_marginal = fig.add_subplot(gs[1], sharey=ax)\n",
    "            else:\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                ax_marginal = None\n",
    "\n",
    "            ax.scatter(subset_plot[hc_mask]['age'],\n",
    "                       subset_plot[hc_mask][value_col],\n",
    "                       color='blue', alpha=0.5, label='HC')\n",
    "            ax.scatter(subset_plot[patient_mask]['age'],\n",
    "                       subset_plot[patient_mask][value_col],\n",
    "                       color='red', alpha=0.5, label=disease)\n",
    "            ax.set_title(f'{disease} - {metric_bundle} ({ylabel})')\n",
    "            ax.set_xlabel('Age')\n",
    "            ax.set_ylabel(ylabel)\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.2)\n",
    "\n",
    "            if ax_marginal is not None:\n",
    "                sns.kdeplot(\n",
    "                    y=subset_plot[hc_mask][value_col],\n",
    "                    ax=ax_marginal,\n",
    "                    fill=True,\n",
    "                    bw_adjust=0.8,\n",
    "                    linewidth=0,\n",
    "                    color='blue',\n",
    "                    alpha=0.35,\n",
    "                )\n",
    "                sns.kdeplot(\n",
    "                    y=subset_plot[patient_mask][value_col],\n",
    "                    ax=ax_marginal,\n",
    "                    fill=True,\n",
    "                    bw_adjust=0.8,\n",
    "                    linewidth=0,\n",
    "                    color='red',\n",
    "                    alpha=0.35,\n",
    "                )\n",
    "                ax_marginal.set_xlabel('Density')\n",
    "                ax_marginal.grid(False)\n",
    "                ax_marginal.tick_params(labelleft=False)\n",
    "                ax_marginal.set_xlim(left=0)\n",
    "                ax_marginal.spines['top'].set_visible(False)\n",
    "                ax_marginal.spines['right'].set_visible(False)\n",
    "\n",
    "            out_dir = os.path.join(out_root, disease, metric)\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "            suffix = 'mean' if value_col == 'mean' else 'mean_no_cov'\n",
    "            out_path = os.path.join(out_dir, f'{metric_bundle}_{suffix}.png')\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(out_path)\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(process_disease)(d, raw_directory, SCATTER_FOLDER)\n",
    "    for d in all_diseases\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'HC' is a specific value in the 'disease' column that indicates healthy controls\n",
    "HC_LABEL = 'HC'\n",
    "DISTRIBUTION_FOLDER = os.path.join(MAINFOLDER, 'COMPILATION_DISTRIBUTION')\n",
    "os.makedirs(DISTRIBUTION_FOLDER, exist_ok=True)\n",
    "\n",
    "def process_disease(disease, raw_directory, DISTRIBUTION_FOLDER):\n",
    "    print(f\"Processing {disease}...\")  # Debugging info\n",
    "    combination = pd.read_csv(os.path.join(raw_directory, f'{disease}_combination_all_metrics_CamCAN.csv.gz'))\n",
    "    metric_bundles = combination['metric_bundle'].unique()\n",
    "    \n",
    "    for metric_bundle in metric_bundles:\n",
    "        subset_all = combination[combination['metric_bundle'] == metric_bundle]\n",
    "        subset = subset_all[subset_all['old_site'] != 'CamCAN']\n",
    "        \n",
    "        bundle = subset_all.bundle.unique()[0]\n",
    "        metric = subset_all.metric.unique()[0]\n",
    "        camCan_subset = subset_all[subset_all['old_site'] == 'CamCAN']\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.kdeplot(subset[subset['disease'] == HC_LABEL]['mean_no_cov'], color='blue', label='HC', fill=True)\n",
    "        # sns.kdeplot(camCan_subset['mean_no_cov'], color='green', label='CamCAN', fill=True)\n",
    "        sns.kdeplot(subset[subset['disease'] != HC_LABEL]['mean_no_cov'], color='red', label=f'{disease}', fill=True)\n",
    "        plt.title(f'Distribution of {disease} in metric {metric} for bundle: {bundle}')\n",
    "        plt.xlabel('Residual mean (covariate-corrected)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "\n",
    "        output_dir = os.path.join(DISTRIBUTION_FOLDER, disease, metric)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Save the plot\n",
    "        output_path = os.path.join(output_dir, f'{metric_bundle}.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "# Run diseases in parallel, but keep metric bundles sequential\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(process_disease)(disease, raw_directory, DISTRIBUTION_FOLDER)\n",
    "    for disease in all_diseases\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'HC' is a specific value in the 'disease' column that indicates healthy controls\n",
    "HC_LABEL = 'HC'\n",
    "\n",
    "# Function to process one disease\n",
    "def process_disease(disease, raw_directory):\n",
    "    print(f\"Processing {disease}...\")  # Debugging info\n",
    "    results = []\n",
    "    \n",
    "    # Load the data for the disease\n",
    "    combination = pd.read_csv(os.path.join(raw_directory, f'{disease}_combination_all_metrics_CamCAN.csv.gz'))\n",
    "    metric_bundles = combination['metric_bundle'].unique()\n",
    "    \n",
    "    for metric_bundle in metric_bundles:\n",
    "        subset_all = combination[combination['metric_bundle'] == metric_bundle]\n",
    "        bundle = subset_all.bundle.unique()[0]\n",
    "        metric = subset_all.metric.unique()[0]\n",
    "\n",
    "        # Subsets for HC and non-HC\n",
    "        hc_data = subset_all[(subset_all['disease'] == HC_LABEL) & (subset_all['old_site'] == 'CamCAN')]['mean_no_cov'].dropna()\n",
    "        non_hc_data = subset_all[subset_all['disease'] != HC_LABEL]['mean_no_cov'].dropna()\n",
    "\n",
    "        # Ensure both distributions are not empty\n",
    "        if len(hc_data) > 1 and len(non_hc_data) > 1:\n",
    "            # Create histograms to normalize distributions\n",
    "            hc_hist, bins = np.histogram(hc_data, bins=50, density=True)\n",
    "            non_hc_hist, _ = np.histogram(non_hc_data, bins=bins, density=True)\n",
    "\n",
    "            # Compute metrics\n",
    "            mean_hc = np.mean(hc_data)\n",
    "            mean_non_hc = np.mean(non_hc_data)\n",
    "            std_hc = np.std(hc_data)\n",
    "            std_non_hc = np.std(non_hc_data)\n",
    "            var_hc = np.var(hc_data, ddof=1)\n",
    "            var_non_hc = np.var(non_hc_data, ddof=1)\n",
    "            n_hc = len(hc_data)\n",
    "            n_non_hc = len(non_hc_data)\n",
    "\n",
    "            # Pooled standard deviation\n",
    "            pooled_std = abs(np.sqrt(((n_hc - 1) * var_hc + (n_non_hc - 1) * var_non_hc) / (n_hc + n_non_hc - 2)))\n",
    "\n",
    "            # Compute distance metrics\n",
    "            bhatt_dist = QuickCombat.bhattacharyya_distance(hc_data, non_hc_data)\n",
    "            kl_div = kl_divergence(hc_hist + 1e-10, non_hc_hist + 1e-10)  # Add epsilon to avoid division by zero\n",
    "            euclidean_dist = abs(mean_hc - mean_non_hc)\n",
    "            mahalanobis_dist = abs(mean_hc - mean_non_hc) / sqrt((std_hc**2 + std_non_hc**2) / 2)\n",
    "            d_cohen = abs(mean_hc - mean_non_hc) / pooled_std\n",
    "\n",
    "            # Store results\n",
    "            results.append({\n",
    "                'disease': disease,\n",
    "                'metric_bundle': metric_bundle,\n",
    "                'bundle': bundle,\n",
    "                'metric': metric,\n",
    "                'bhattacharyya_distance': bhatt_dist,\n",
    "                'kl_divergence': kl_div,\n",
    "                'euclidean_distance': euclidean_dist,\n",
    "                'mahalanobis_distance': mahalanobis_dist,\n",
    "                'prct_distance': abs(euclidean_dist / mean_hc),\n",
    "                'd_cohen': d_cohen\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run diseases in parallel, but keep metric bundles sequential\n",
    "all_results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_disease)(disease, raw_directory)\n",
    "    for disease in all_diseases\n",
    ")\n",
    "\n",
    "# Flatten results\n",
    "results = [item for sublist in all_results for item in sublist]\n",
    "\n",
    "# Convert results into DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results\n",
    "output_dir = MAINFOLDER\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'distance_metrics_results.csv')\n",
    "results_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du DataFrame de résultat pour les valeurs maximales\n",
    "max_results = []\n",
    "\n",
    "output_path = f'{MAINFOLDER}/distance_metrics_results.csv'\n",
    "results_df = pd.read_csv(output_path)\n",
    "\n",
    "# Parcourir chaque maladie\n",
    "for disease in results_df['disease'].unique():\n",
    "    disease_subset = results_df[results_df['disease'] == disease]\n",
    "    \n",
    "    # Identifier les metric_bundles avec les valeurs maximales pour chaque mesure de distance\n",
    "    max_bhatt = disease_subset.loc[disease_subset['bhattacharyya_distance'].idxmax()]\n",
    "    max_kl = disease_subset.loc[disease_subset['kl_divergence'].idxmax()]\n",
    "    max_euclidean = disease_subset.loc[disease_subset['euclidean_distance'].idxmax()]\n",
    "    max_mahalanobis = disease_subset.loc[disease_subset['mahalanobis_distance'].idxmax()]\n",
    "    \n",
    "    # Ajouter les résultats dans une liste\n",
    "    max_results.append({\n",
    "        'disease': disease,\n",
    "        'metric_bundle_max_bhatt': max_bhatt['metric_bundle'],\n",
    "        'bhattacharyya_distance': max_bhatt['bhattacharyya_distance'],\n",
    "        'metric_bundle_max_kl': max_kl['metric_bundle'],\n",
    "        'kl_divergence': max_kl['kl_divergence'],\n",
    "        'metric_bundle_max_euclidean': max_euclidean['metric_bundle'],\n",
    "        'euclidean_distance': max_euclidean['euclidean_distance'],\n",
    "        'metric_bundle_max_mahalanobis': max_mahalanobis['metric_bundle'],\n",
    "        'mahalanobis_distance': max_mahalanobis['mahalanobis_distance']\n",
    "    })\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "max_results_df = pd.DataFrame(max_results)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(max_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df\n",
    "results_df = results_df[~results_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "column = 'prct_distance'\n",
    "\n",
    "output_dir = f'{MAINFOLDER}/PRCT_HISTOGRAMS/{column}/PER_METRIC'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Parcourir chaque maladie\n",
    "for disease in results_df['disease'].unique():\n",
    "    disease_subset = results_df[results_df['disease'] == disease]\n",
    "    \n",
    "    # Parcourir chaque metric\n",
    "    for metric in disease_subset['metric'].unique():\n",
    "        metric_subset = disease_subset[disease_subset['metric'] == metric]\n",
    "        \n",
    "        # Afficher l'histogramme de la distribution de prct_distance\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(metric_subset[column], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "        plt.title(f'Distribution of {column} for {disease} - {metric}')\n",
    "        plt.xlabel(f'{column}')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Create the directory for the disease and metric\n",
    "        disease_dir = os.path.join(output_dir, disease)\n",
    "        os.makedirs(disease_dir, exist_ok=True)\n",
    "        \n",
    "        # Save the plot\n",
    "        output_path = os.path.join(disease_dir, f'{disease}_{metric}_{column}_histogram.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()# Define the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_dir = f'{MAINFOLDER}/PRCT_HISTOGRAMS/{column}/PER_DISEASE'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Parcourir chaque maladie\n",
    "for disease in results_df['disease'].unique():\n",
    "    disease_subset = results_df[results_df['disease'] == disease]  \n",
    "    # Afficher l'histogramme de la distribution de prct_distance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(disease_subset[column], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title(f'Distribution of {column} for {disease} -')\n",
    "    plt.xlabel(f'{column}')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot\n",
    "    output_path = os.path.join(output_dir, f'{disease}__{column}_histogram.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'{MAINFOLDER}/PRCT_HISTOGRAMS/{column}/PER_METRIC_ALL'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Récupérer la liste unique des metrics\n",
    "all_metrics = results_df['metric'].unique()\n",
    "\n",
    "# Boucle sur chaque metric\n",
    "for metric in all_metrics:\n",
    "    # Filtrer le DataFrame sur le metric courant\n",
    "    metric_subset = results_df[results_df['metric'] == metric]\n",
    "    \n",
    "    # Créer une figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Récupérer la liste unique des maladies pour ce metric\n",
    "    all_diseases = metric_subset['disease'].unique()\n",
    "    \n",
    "    # Pour chaque maladie, tracer l’histogramme de prct_distance\n",
    "    for disease in all_diseases:\n",
    "        disease_subset = metric_subset[metric_subset['disease'] == disease]\n",
    "        plt.hist(\n",
    "            disease_subset[column], \n",
    "            bins=30, \n",
    "            alpha=0.5, \n",
    "            label=disease, \n",
    "            edgecolor='black'\n",
    "        )\n",
    "    \n",
    "    # Ajouter légende et titres\n",
    "    plt.title(f'Distribution de prct_distance pour le metric : {metric}')\n",
    "    plt.xlabel(f'{column}')\n",
    "    plt.ylabel('Fréquence')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Enregistrer la figure\n",
    "    output_path = os.path.join(output_dir, f'{metric}_all_diseases_{column}_histogram.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'{MAINFOLDER}/PRCT_HISTOGRAMS/{column}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Boucle sur chaque metric\n",
    "    \n",
    "# Créer une figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Récupérer la liste unique des maladies pour ce metric\n",
    "all_diseases = results_df['disease'].unique()\n",
    "\n",
    "# Pour chaque maladie, tracer l’histogramme de prct_distance\n",
    "for disease in all_diseases:\n",
    "    disease_subset = results_df[results_df['disease'] == disease]\n",
    "    plt.hist(\n",
    "        disease_subset[column], \n",
    "        bins=30, \n",
    "        alpha=0.5, \n",
    "        label=disease, \n",
    "        edgecolor='black'\n",
    "    )\n",
    "\n",
    "# Ajouter légende et titres\n",
    "plt.title(f'Distribution de {column} pour le metric : {metric}')\n",
    "plt.xlabel('prct_distance')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Enregistrer la figure\n",
    "output_path = os.path.join(output_dir, f'all_diseases_{column}_histogram.png')\n",
    "plt.savefig(output_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset of diseases where the string starts with 'SYN'\n",
    "syn_diseases = [\"SYN_0.5\", \"SYN_1\",]\n",
    "output_dir = f'{MAINFOLDER}/PRCT_HISTOGRAMS/{column}/PER_METRIC_WITH_SYN'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Parcourir chaque maladie\n",
    "for disease in all_diseases:\n",
    "    disease_subset = results_df[results_df['disease'] == disease]\n",
    "    \n",
    "    # Parcourir chaque metric\n",
    "    for metric in disease_subset['metric'].unique():\n",
    "        metric_subset = disease_subset[disease_subset['metric'] == metric]\n",
    "        \n",
    "        # Afficher l'histogramme de la distribution de prct_distance\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for dis in syn_diseases:\n",
    "            syn_sub = results_df[results_df['disease'] == dis]\n",
    "            syn_met = syn_sub[syn_sub['metric'] == metric]\n",
    "            plt.hist(\n",
    "                syn_met[column], \n",
    "                bins=30, \n",
    "                alpha=0.2, \n",
    "                label=dis, \n",
    "                edgecolor='black'\n",
    "            )\n",
    "        plt.hist(metric_subset[column], bins=30, alpha=0.7, color='blue', edgecolor='black', label=disease)\n",
    "        plt.title(f'Distribution of {column} for {disease} - {metric}')\n",
    "        plt.xlabel(f'{column}')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Pour chaque maladie, tracer l’histogramme de prct_distance\n",
    "        \n",
    "        # Create the directory for the disease and metric\n",
    "        disease_dir = os.path.join(output_dir, disease)\n",
    "        os.makedirs(disease_dir, exist_ok=True)\n",
    "        \n",
    "        # Save the plot\n",
    "        output_path = os.path.join(disease_dir, f'{disease}_{metric}_{column}_histogram.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = 'RESULTS/DISTRIBUTION_RESULTS/distance_metrics_results.csv'\n",
    "# distance_metrics_results = pd.read_csv(output_path)\n",
    "\n",
    "# average_results = distance_metrics_results.groupby(['disease', 'metric']).mean(numeric_only=True).reset_index()\n",
    "# average_results\n",
    "# highest_lowest_metrics = average_results.groupby('disease').agg(\n",
    "#     highest_bhattacharyya=('bhattacharyya_distance', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "#     lowest_bhattacharyya=('bhattacharyya_distance', lambda x: average_results.loc[x.idxmin(), 'metric']),\n",
    "#     highest_kl=('kl_divergence', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "#     lowest_kl=('kl_divergence', lambda x: average_results.loc[x.idxmin(), 'metric']),\n",
    "#     highest_euclidean=('euclidean_distance', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "#     lowest_euclidean=('euclidean_distance', lambda x: average_results.loc[x.idxmin(), 'metric']),\n",
    "#     highest_mahalanobis=('mahalanobis_distance', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "#     lowest_mahalanobis=('mahalanobis_distance', lambda x: average_results.loc[x.idxmin(), 'metric'])\n",
    "# ).reset_index()\n",
    "\n",
    "# highest_lowest_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = 'RESULTS/DISTRIBUTION_RESULTS/distance_metrics_results.csv'\n",
    "# distance_metrics_results = pd.read_csv(output_path)\n",
    "\n",
    "# # Find the bundle/metric with the highest and lowest value for each distance metric for each disease\n",
    "# highest_lowest_values = distance_metrics_results.groupby('disease').agg(\n",
    "#     highest_bhattacharyya=('bhattacharyya_distance', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "#     lowest_bhattacharyya=('bhattacharyya_distance', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle']),\n",
    "#     highest_kl=('kl_divergence', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "#     lowest_kl=('kl_divergence', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle']),\n",
    "#     highest_euclidean=('euclidean_distance', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "#     lowest_euclidean=('euclidean_distance', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle']),\n",
    "#     highest_mahalanobis=('mahalanobis_distance', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "#     lowest_mahalanobis=('mahalanobis_distance', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle'])\n",
    "# ).reset_index()\n",
    "\n",
    "# highest_lowest_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'{MAINFOLDER}/distance_metrics_results.csv'\n",
    "results_df = pd.read_csv(output_path)\n",
    "# Create a DataFrame to store the results\n",
    "top_3_smallest_d_cohen = []\n",
    "\n",
    "# Iterate over each disease\n",
    "for disease in results_df['disease'].unique():\n",
    "    disease_subset = results_df[results_df['disease'] == disease]\n",
    "    \n",
    "    # Iterate over each metric\n",
    "    for metric in disease_subset['metric'].unique():\n",
    "        metric_subset = disease_subset[disease_subset['metric'] == metric]\n",
    "        \n",
    "        # Sort by d_cohen and select the top 3 smallest values\n",
    "        smallest_d_cohen = metric_subset.nsmallest(3, 'd_cohen')\n",
    "        \n",
    "        # Add the results to the list\n",
    "        for _, row in smallest_d_cohen.iterrows():\n",
    "            top_3_smallest_d_cohen.append({\n",
    "                'disease': disease,\n",
    "                'metric': metric,\n",
    "                'bundle': row['metric_bundle'],\n",
    "                'd_cohen': row['d_cohen']\n",
    "            })\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "top_3_smallest_d_cohen_df = pd.DataFrame(top_3_smallest_d_cohen)\n",
    "\n",
    "# Display the results\n",
    "print(top_3_smallest_d_cohen_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'{MAINFOLDER}/distance_metrics_results.csv'\n",
    "results_df = pd.read_csv(output_path)\n",
    "# Create a DataFrame to store the results\n",
    "top_3_worst_d_cohen = []\n",
    "\n",
    "# Iterate over each disease\n",
    "for disease in results_df['disease'].unique():\n",
    "    disease_subset = results_df[results_df['disease'] == disease]\n",
    "    \n",
    "    # Iterate over each metric\n",
    "    for metric in disease_subset['metric'].unique():\n",
    "        metric_subset = disease_subset[disease_subset['metric'] == metric]\n",
    "        \n",
    "        # Sort by d_cohen and select the top 3 largest values\n",
    "        worst_d_cohen = metric_subset.nlargest(3, 'd_cohen')\n",
    "        \n",
    "        # Add the results to the list\n",
    "        for _, row in worst_d_cohen.iterrows():\n",
    "            top_3_worst_d_cohen.append({\n",
    "                'disease': disease,\n",
    "                'metric': metric,\n",
    "                'bundle': row['metric_bundle'],\n",
    "                'd_cohen': row['d_cohen']\n",
    "            })\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "top_3_worst_d_cohen_df = pd.DataFrame(top_3_worst_d_cohen)\n",
    "\n",
    "# Display the results\n",
    "print(top_3_worst_d_cohen_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Enlève les maladies SYN\n",
    "filtered_df = results_df[~results_df['disease'].str.startswith('SYN')]\n",
    "\n",
    "# 2. Moyenne de d_cohen pour chaque combinaison metric + bundle\n",
    "mean_dcohen = (\n",
    "    filtered_df\n",
    "    .groupby(['metric', 'bundle'])['d_cohen']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 3. Top 3 des bundles avec la plus petite moyenne de d_cohen pour chaque metric\n",
    "top3_per_metric = (\n",
    "    mean_dcohen\n",
    "    .sort_values(['metric', 'd_cohen'])\n",
    "    .groupby('metric')\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Affichage\n",
    "print(top3_per_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Toujours filtrer les maladies SYN\n",
    "filtered_df = results_df[~results_df['disease'].str.startswith('SYN')]\n",
    "\n",
    "# 2. Moyenne de d_cohen pour chaque (metric, bundle)\n",
    "mean_dcohen_metric_bundle = (\n",
    "    filtered_df\n",
    "    .groupby(['metric', 'bundle'])['d_cohen']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 3. Moyenne de d_cohen pour chaque bundle (tous metrics confondus)\n",
    "mean_dcohen_per_bundle = (\n",
    "    mean_dcohen_metric_bundle\n",
    "    .groupby('bundle')['d_cohen']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 4. Prendre les 3 bundles avec la plus petite moyenne overall\n",
    "top3_bundles_overall = mean_dcohen_per_bundle.nsmallest(3, 'd_cohen')\n",
    "\n",
    "# Afficher le résultat\n",
    "print(top3_bundles_overall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Reprend les 3 meilleurs bundles (si pas déjà dans la variable)\n",
    "top_bundles = top3_bundles_overall['bundle'].tolist()\n",
    "\n",
    "# 2. Filtrer les lignes associées à ces bundles (et exclure SYN)\n",
    "worst_cases = results_df[\n",
    "    (results_df['bundle'].isin(top_bundles)) &\n",
    "    (~results_df['disease'].str.startswith('SYN'))\n",
    "]\n",
    "\n",
    "# 3. Trouver le pire cas pour chaque bundle\n",
    "worst_per_bundle = (\n",
    "    worst_cases.loc[\n",
    "        worst_cases.groupby('bundle')['d_cohen'].idxmax()\n",
    "    ][['bundle', 'disease', 'metric', 'd_cohen']]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Afficher le résultat\n",
    "print(worst_per_bundle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}