{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS and UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")\n",
    "\n",
    "import os, math\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from scripts import combat_info\n",
    "from scripts import combat_quick_apply\n",
    "from scripts import combat_quick_QC\n",
    "from robust_evaluation_tools.robust_utils import get_site, robust_text, rwp_text, get_camcan_file, get_diseases, get_metrics, add_nb_patients_and_diseased, remove_covariates_effects_metrics\n",
    "from robust_evaluation_tools.robust_harmonization import fit, apply, visualize_harmonization, QC, compare_with_compilation, compare_with_compilation_SMAPE, compare_with_compilation_STD, create_presentation, compare_distances, compare_with_compilation_var\n",
    "from robust_evaluation_tools.synthectic_sites_generations import generate_sites\n",
    "from robust_evaluation_tools.robust_outlier_detection import z_score_detection, flag_sid\n",
    "from robust_evaluation_tools.robust_MLP import predict_malades_MLP\n",
    "\n",
    "MAINFOLDER = \"RESULTS/MAE_TEST\"\n",
    "SYNTHETIC_SITES = f\"{MAINFOLDER}/SYNTHETIC_SITES\"\n",
    "\n",
    "ANALYSIS_FOLDER = f\"{MAINFOLDER}/ANALYSIS\"\n",
    "\n",
    "robust_methods_for_analysis = [\"No\",\"raw\", \"IQR\",'MAD','MMS', 'VS', 'VS2', 'FLIP', 'G_ZS', \"G_ZS_IQR\", \"G_ZS_MAD\"]\n",
    "\n",
    "SMAPE_ONLY = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HARMONIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, directory, method, robust, rwp,hc, gt_train_file_name, gt_test_file_name):\n",
    "     \n",
    "    if method == 'robust':\n",
    "        dir =os.path.join(directory,robust)\n",
    "    else:\n",
    "        dir = os.path.join(directory,method)\n",
    "    print(f_train)\n",
    "    \n",
    "    if robust == 'raw':\n",
    "        output_filename_train = f_train\n",
    "        output_filename_test = f_test\n",
    "    else:\n",
    "        # Fit the model\n",
    "        output_model_filename = fit(f_train, ref_data_file, metric, harmonizartion_method, robust, rwp, dir, hc,)\n",
    "        # Apply the model\n",
    "        output_filename_train = apply(f_train, output_model_filename, metric, harmonizartion_method, robust, rwp, dir)\n",
    "        output_filename_test = apply(f_test, output_model_filename, metric, harmonizartion_method, robust, rwp, dir)\n",
    "    \n",
    "    # Visualize the harmonization\n",
    "    #visualize_harmonization(f_test, output_filename, ref_data_file, dir, bundles = '')\n",
    "    \n",
    "    std_mae_train = compare_with_compilation_STD(pd.read_csv(output_filename_train), pd.read_csv(gt_train_file_name))\n",
    "    std_mae_test = compare_with_compilation_STD(pd.read_csv(output_filename_test), pd.read_csv(gt_test_file_name))\n",
    "\n",
    "    if not SMAPE_ONLY:\n",
    "        smape_test = compare_with_compilation_SMAPE(pd.read_csv(output_filename_test), pd.read_csv(gt_test_file_name))\n",
    "        smape_train = compare_with_compilation_SMAPE(pd.read_csv(output_filename_train), pd.read_csv(gt_train_file_name))\n",
    "        \n",
    "        mae_test = compare_with_compilation(pd.read_csv(output_filename_test), pd.read_csv(gt_test_file_name))\n",
    "        maev_test = compare_with_compilation_var(pd.read_csv(output_filename_test), pd.read_csv(gt_test_file_name))\n",
    "\n",
    "        mae_train = compare_with_compilation(pd.read_csv(output_filename_train), pd.read_csv(gt_train_file_name))\n",
    "        maev_train = compare_with_compilation_var(pd.read_csv(output_filename_train), pd.read_csv(gt_train_file_name))\n",
    "    else:\n",
    "        mae_test = pd.DataFrame()\n",
    "        maev_test = pd.DataFrame()\n",
    "        mae_train = pd.DataFrame()\n",
    "        maev_train = pd.DataFrame()\n",
    "        smape_test = pd.DataFrame()\n",
    "        smape_train = pd.DataFrame()\n",
    "\n",
    "\n",
    "    mae_test['site'] = get_site(f_train)\n",
    "    mae_test['method'] = method\n",
    "    mae_test['robust_method'] = robust\n",
    "\n",
    "    maev_test['site'] = get_site(f_train)\n",
    "    maev_test['method'] = method\n",
    "    maev_test['robust_method'] = robust\n",
    "\n",
    "    mae_train['site'] = get_site(f_train)\n",
    "    mae_train['method'] = method\n",
    "    mae_train['robust_method'] = robust\n",
    "\n",
    "    maev_train['site'] = get_site(f_train)\n",
    "    maev_train['method'] = method\n",
    "    maev_train['robust_method'] = robust\n",
    "\n",
    "    smape_test['site'] = get_site(f_train)\n",
    "    smape_test['method'] = method\n",
    "    smape_test['robust_method'] = robust\n",
    "\n",
    "    smape_train['site'] = get_site(f_train)\n",
    "    smape_train['method'] = method\n",
    "    smape_train['robust_method'] = robust\n",
    "\n",
    "    std_mae_train['site'] = get_site(f_train)\n",
    "    std_mae_train['method'] = method\n",
    "    std_mae_train['robust_method'] = robust\n",
    "\n",
    "    std_mae_test['site'] = get_site(f_train)\n",
    "    std_mae_test['method'] = method\n",
    "    std_mae_test['robust_method'] = robust\n",
    "    \n",
    "    return mae_test, maev_test, mae_train, maev_train, smape_test, smape_train, std_mae_test, std_mae_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_site(f_train, f_test, robust_methods, directory, ref_data_file,\n",
    "                 metric, harmonizartion_method, gt_train_file_name, gt_test_file_name):\n",
    "    # Accumulateurs\n",
    "    df_mae_test_robust   = pd.DataFrame()\n",
    "    df_maev_test_robust  = pd.DataFrame()\n",
    "    df_mae_train_robust  = pd.DataFrame()\n",
    "    df_maev_train_robust = pd.DataFrame()\n",
    "    df_smape_test_robust = pd.DataFrame()\n",
    "    df_smape_train_robust = pd.DataFrame()\n",
    "    df_std_mae_test_robust = pd.DataFrame()\n",
    "    df_std_mae_train_robust = pd.DataFrame()\n",
    "\n",
    "    for robust in robust_methods:\n",
    "        if robust == \"raw\":\n",
    "            (mae_test, maev_test, mae_train, maev_train,\n",
    "             smape_test, smape_train, std_mae_test, std_mae_train) = harmonize(\n",
    "                 f_train, ref_data_file, metric, harmonizartion_method,\n",
    "                 f_test, directory, \"raw\", \"raw\", False, False, gt_train_file_name, gt_test_file_name)\n",
    "\n",
    "        elif robust == \"No\":\n",
    "            # hc‚Äëonly\n",
    "            (mae_test_hc, maev_test_hc, mae_train_hc, maev_train_hc,\n",
    "             smape_test_hc, smape_train_hc, std_mae_test_hc, std_mae_train_hc) = harmonize(\n",
    "                 f_train, ref_data_file, metric, harmonizartion_method,\n",
    "                 f_test, directory, \"hc\", \"No\", False, True, gt_train_file_name, gt_test_file_name)\n",
    "            # NoRobust\n",
    "            (mae_test_no, maev_test_no, mae_train_no, maev_train_no,\n",
    "             smape_test_no, smape_train_no, std_mae_test_no, std_mae_train_no) = harmonize(\n",
    "                 f_train, ref_data_file, metric, harmonizartion_method,\n",
    "                 f_test, directory, \"NoRobust\", \"No\", False, False, gt_train_file_name, gt_test_file_name)\n",
    "\n",
    "            mae_test   = pd.concat([mae_test_no,   mae_test_hc],   ignore_index=True)\n",
    "            maev_test  = pd.concat([maev_test_no,  maev_test_hc],  ignore_index=True)\n",
    "            mae_train  = pd.concat([mae_train_no,  mae_train_hc],  ignore_index=True)\n",
    "            maev_train = pd.concat([maev_train_no, maev_train_hc], ignore_index=True)\n",
    "            smape_test = pd.concat([smape_test_no, smape_test_hc], ignore_index=True)\n",
    "            smape_train = pd.concat([smape_train_no, smape_train_hc], ignore_index=True)\n",
    "            std_mae_test = pd.concat([std_mae_test_no, std_mae_test_hc], ignore_index=True)\n",
    "            std_mae_train = pd.concat([std_mae_train_no, std_mae_train_hc], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            (mae_test, maev_test, mae_train, maev_train,\n",
    "             smape_test, smape_train, std_mae_test, std_mae_train) = harmonize(\n",
    "                 f_train, ref_data_file, metric, harmonizartion_method,\n",
    "                 f_test, directory, \"robust\", robust, False, False, gt_train_file_name, gt_test_file_name)\n",
    "\n",
    "        # Empile tout\n",
    "        df_mae_test_robust   = pd.concat([df_mae_test_robust,   mae_test],   ignore_index=True)\n",
    "        df_maev_test_robust  = pd.concat([df_maev_test_robust,  maev_test],  ignore_index=True)\n",
    "        df_mae_train_robust  = pd.concat([df_mae_train_robust,  mae_train],  ignore_index=True)\n",
    "        df_maev_train_robust = pd.concat([df_maev_train_robust, maev_train], ignore_index=True)\n",
    "        df_smape_test_robust = pd.concat([df_smape_test_robust, smape_test], ignore_index=True)\n",
    "        df_smape_train_robust = pd.concat([df_smape_train_robust, smape_train], ignore_index=True)\n",
    "        df_std_mae_test_robust = pd.concat([df_std_mae_test_robust, std_mae_test], ignore_index=True)\n",
    "        df_std_mae_train_robust = pd.concat([df_std_mae_train_robust, std_mae_train], ignore_index=True)\n",
    "\n",
    "    return (df_mae_test_robust, df_maev_test_robust,\n",
    "            df_mae_train_robust, df_maev_train_robust,\n",
    "            df_smape_test_robust, df_smape_train_robust,\n",
    "            df_std_mae_test_robust, df_std_mae_train_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_analysis(disease, sample_size, disease_ratio, test_index,\n",
    "                     harmonization_method, SYNTHETIC_SITES_VERSION,\n",
    "                     metrics, robust_methods):\n",
    "    \n",
    "    # D√©finition des chemins\n",
    "    sizeDir = os.path.join(MAINFOLDER, f'PROCESS_{harmonization_method}', disease,\n",
    "                           f\"{sample_size}_{int(disease_ratio * 100)}\",\n",
    "                           f\"{test_index}\")\n",
    "    mae_test_file_path  = os.path.join(sizeDir, \"mae_compilation_test.csv\")\n",
    "    maev_test_file_path = os.path.join(sizeDir, \"maev_compilation_test.csv\")\n",
    "    mae_train_file_path = os.path.join(sizeDir, \"mae_compilation_train.csv\")\n",
    "    maev_train_file_path= os.path.join(sizeDir, \"maev_compilation_train.csv\")\n",
    "    smape_test_file_path = os.path.join(sizeDir, \"smape_compilation_test.csv\")\n",
    "    smape_train_file_path= os.path.join(sizeDir, \"smape_compilation_train.csv\")\n",
    "    std_mae_train_file_path = os.path.join(sizeDir, \"std_mae_compilation_train.csv\")\n",
    "    std_mae_test_file_path = os.path.join(sizeDir, \"std_mae_compilation_test.csv\")\n",
    "\n",
    "    # Chargement existant (ou vide)\n",
    "    def _load_if_exists(path):\n",
    "        return pd.read_csv(path) if os.path.isfile(path) else pd.DataFrame()\n",
    "\n",
    "    mae_compilation_test  = _load_if_exists(mae_test_file_path)\n",
    "    maev_compilation_test = _load_if_exists(maev_test_file_path)\n",
    "    mae_compilation_train = _load_if_exists(mae_train_file_path)\n",
    "    maev_compilation_train= _load_if_exists(maev_train_file_path)\n",
    "    smape_compilation_test = _load_if_exists(smape_test_file_path)\n",
    "    smape_compilation_train = _load_if_exists(smape_train_file_path)\n",
    "    std_mae_compilation_train = _load_if_exists(std_mae_train_file_path)\n",
    "    std_mae_compilation_test = _load_if_exists(std_mae_test_file_path)\n",
    "\n",
    "\n",
    "    robust_methods = [\"No\",\"raw\"] + robust_methods\n",
    "    # üí° V√©rification une seule fois au d√©but : est-ce que certaines m√©thodes sont d√©j√† pr√©sentes ?\n",
    "    if not std_mae_compilation_test.empty:\n",
    "        existing_methods = set(std_mae_compilation_test['robust_method'].unique())\n",
    "        missing_methods = [m for m in robust_methods if m not in existing_methods]\n",
    "\n",
    "        if not missing_methods:\n",
    "            print(f\"‚úîÔ∏è Toutes les m√©thodes d√©j√† trait√©es pour {disease} {sample_size}_{int(disease_ratio*100)} test_index {test_index}.\")\n",
    "            return (mae_test_file_path, maev_test_file_path,\n",
    "                    mae_train_file_path, maev_train_file_path,\n",
    "                    smape_test_file_path, smape_train_file_path,\n",
    "                    std_mae_test_file_path, std_mae_train_file_path\n",
    "                    )\n",
    "        \n",
    "        # ‚¨áÔ∏è on ne garde que les m√©thodes manquantes\n",
    "        robust_methods = missing_methods\n",
    "\n",
    "    # Si on est ici, c‚Äôest qu‚Äôil reste des m√©thodes √† faire\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, disease)\n",
    "    sizeDir_site   = os.path.join(directory_site, f\"{sample_size}_{int(disease_ratio * 100)}\")\n",
    "    tempDir_site   = os.path.join(sizeDir_site, f\"{test_index}\")\n",
    "\n",
    "    df_for_tags = pd.read_csv(os.path.join(tempDir_site, f\"train_{sample_size}_{int(disease_ratio * 100)}_{test_index}_all.csv\"))\n",
    "    df_for_tags = df_for_tags[~df_for_tags['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "    df_for_tags = remove_covariates_effects_metrics(df_for_tags)\n",
    "\n",
    "    z_score_sids = z_score_detection(df_for_tags)\n",
    "    \n",
    "    \n",
    "        # ‚Äî 1) Pr√©pare les pr√©dictions une seule fois ‚Äî\n",
    "    thresholds = [0.5, 0.6, 0.9, 0.95, 0.99]\n",
    "    models     = [\"mlp2_ALL\", \"mlp3_ALL\", \"mlp4_ALL\"]          # ajoute-en d‚Äôautres au besoin\n",
    "\n",
    "    preds = {f\"{m.upper()}_{str(int(t*100)).rstrip('0')}\": predict_malades_MLP(df_for_tags, m, threshold=t)\n",
    "         for m in models for t in thresholds}\n",
    "\n",
    "\n",
    "\n",
    "    for metric in metrics:\n",
    "        tempDir = os.path.join(sizeDir, metric)\n",
    "        os.makedirs(tempDir, exist_ok=True)\n",
    "\n",
    "        # Pr√©paration fichiers train/test\n",
    "        train_file_name = f\"train_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\"\n",
    "        test_file_name  = f\"test_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\"\n",
    "        gt_train_file_name = os.path.join(tempDir_site,f\"gt_train_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\")\n",
    "        gt_test_file_name  = os.path.join(tempDir_site,f\"gt_test_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\")\n",
    "\n",
    "        train_file = os.path.join(tempDir_site, train_file_name)\n",
    "        train_df = pd.read_csv(train_file)\n",
    "        train_df = train_df[~train_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "        train_df = train_df.drop(columns=['mean_no_cov', 'metric_bundle'])\n",
    "        train_df = flag_sid(train_df, z_score_sids, \"G_ZS\")\n",
    "        for label, sid_list in preds.items():\n",
    "            train_df = flag_sid(train_df, sid_list, label)\n",
    "\n",
    "\n",
    "        train_df[\"site\"] = disease + \"_\" + train_df[\"site\"]\n",
    "        new_train_file = os.path.join(tempDir, train_file_name)\n",
    "        train_df.to_csv(new_train_file, index=False)\n",
    "\n",
    "        test_file = os.path.join(tempDir_site, test_file_name)\n",
    "        test_df = pd.read_csv(test_file)\n",
    "        test_df = test_df[~test_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "        test_df = test_df.drop(columns=['mean_no_cov', 'metric_bundle'])\n",
    "        test_df[\"site\"] = train_df[\"site\"]\n",
    "        new_test_file = os.path.join(tempDir, test_file_name)\n",
    "        test_df.to_csv(new_test_file, index=False)\n",
    "\n",
    "        ref_data_file = get_camcan_file(metric)\n",
    "\n",
    "        # Lancement de l‚Äôanalyse pour toutes les m√©thodes manquantes\n",
    "        mae_analyze_test, maev_analyze_test, mae_analyze_train, maev_analyze_train, \\\n",
    "        smape_analyze_test, smape_analyze_train, std_mae_analyze_test, std_mae_analyze_train = analyse_site(\n",
    "            new_train_file, new_test_file, robust_methods, tempDir,\n",
    "            ref_data_file, metric, harmonization_method, gt_train_file_name, gt_test_file_name\n",
    "        )\n",
    "\n",
    "        # Ajout des infos\n",
    "        for df in [mae_analyze_test, maev_analyze_test, mae_analyze_train, maev_analyze_train, smape_analyze_test, smape_analyze_train, std_mae_analyze_test, std_mae_analyze_train]:\n",
    "            df['disease'] = disease\n",
    "            df['metric']  = metric\n",
    "\n",
    "        std_mae_compilation_test = pd.concat([std_mae_compilation_test, std_mae_analyze_test],\n",
    "                                                ignore_index=True).drop_duplicates()\n",
    "        std_mae_compilation_train = pd.concat([std_mae_compilation_train, std_mae_analyze_train],\n",
    "                                                ignore_index=True).drop_duplicates()\n",
    "        if not SMAPE_ONLY: \n",
    "            mae_compilation_test = pd.concat([mae_compilation_test, mae_analyze_test],\n",
    "                                            ignore_index=True).drop_duplicates()\n",
    "            maev_compilation_test = pd.concat([maev_compilation_test, maev_analyze_test],\n",
    "                                            ignore_index=True).drop_duplicates()\n",
    "            mae_compilation_train = pd.concat([mae_compilation_train, mae_analyze_train],\n",
    "                                            ignore_index=True).drop_duplicates()\n",
    "            maev_compilation_train = pd.concat([maev_compilation_train, maev_analyze_train],\n",
    "                                            ignore_index=True).drop_duplicates()\n",
    "            smape_compilation_test = pd.concat([smape_compilation_test, smape_analyze_test],\n",
    "                                            ignore_index=True).drop_duplicates()\n",
    "            smape_compilation_train = pd.concat([smape_compilation_train, smape_analyze_train],\n",
    "                                                ignore_index=True).drop_duplicates()\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "    # Sauvegarde finale\n",
    "    os.makedirs(sizeDir, exist_ok=True)\n",
    "    std_mae_compilation_test.to_csv(std_mae_test_file_path, index=False)\n",
    "    std_mae_compilation_train.to_csv(std_mae_train_file_path, index=False)\n",
    "    if not SMAPE_ONLY:\n",
    "        mae_compilation_test.to_csv(mae_test_file_path, index=False)\n",
    "        maev_compilation_test.to_csv(maev_test_file_path, index=False)\n",
    "        mae_compilation_train.to_csv(mae_train_file_path, index=False)\n",
    "        maev_compilation_train.to_csv(maev_train_file_path, index=False)\n",
    "        smape_compilation_test.to_csv(smape_test_file_path, index=False)\n",
    "        smape_compilation_train.to_csv(smape_train_file_path, index=False)\n",
    "        \n",
    "\n",
    "# Parallelized analysis method (excluding num_tests from parallelization)\n",
    "def analyse_method(sample_sizes, disease_ratios, num_tests, robust_methods,diseases, metrics, harmonization_method, SYNTHETIC_SITES_VERSION, n_jobs=-1):\n",
    "    # Generate all task combinations (excluding num_tests)\n",
    "    tasks = [\n",
    "        (disease, sample_size, disease_ratio, num_test, harmonization_method, SYNTHETIC_SITES_VERSION, metrics, robust_methods)\n",
    "        for disease in diseases\n",
    "        for sample_size in sample_sizes\n",
    "        for disease_ratio in disease_ratios\n",
    "        for num_test in range(num_tests)\n",
    "    ]\n",
    "\n",
    "    # Run all combinations in parallel and collect file paths\n",
    "    Parallel(n_jobs=n_jobs)(delayed(process_analysis)(*task) for task in tasks)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonization_method= \"gmm\"\n",
    "\n",
    "SYNTHETIC_SITES_VERSION = \"v1\"\n",
    "\n",
    "metrics = get_metrics()\n",
    "#diseases = get_diseases(True)\n",
    "diseases = [\"ALL\"]\n",
    "robust_methods = [\n",
    "                \"IQR\",\n",
    "                \"MAD\",\n",
    "                \"MLP3_ALL_5\",\n",
    "                ]\n",
    "\n",
    "sample_sizes = [5,10,20,30,100,150]  # Diff√©rentes tailles d'√©chantillon\n",
    "sample_sizes = [30,100,150]  # Diff√©rentes tailles d'√©chantillon\n",
    "sample_sizes = [100]  # Diff√©rentes tailles d'√©chantillon\n",
    "disease_ratios = [0.03, 0.1, 0.3, 0.5, 0.7, 0.8]  # Diff√©rents pourcentages de malades\n",
    "num_tests = 20  # Nombre de tests √† effectuer pour chaque combinaison\n",
    "n_jobs_number=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_method(sample_sizes, disease_ratios, num_tests, robust_methods,diseases, metrics, harmonization_method, SYNTHETIC_SITES_VERSION, n_jobs=n_jobs_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
