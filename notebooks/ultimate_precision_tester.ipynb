{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS and UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from robust_evaluation_tools.robust_utils import get_complete_combination, get_diseases, add_nb_patients_and_diseased\n",
    "from robust_evaluation_tools.robust_outlier_detection import find_outliers, analyze_detection_performance, scatter_plot_with_colors\n",
    "from robust_evaluation_tools.synthectic_sites_generations import generate_sites\n",
    "from robust_evaluation_tools.robust_analysis import calculate_precision_by_bundle\n",
    "\n",
    "MAINFOLDER = \"RESULTS/PRECISION_TEST\"\n",
    "SYNTHETIC_SITES = f\"{MAINFOLDER}/SYNTHETIC_SITES\"\n",
    "\n",
    "ANALYSIS_FOLDER = f\"{MAINFOLDER}/ANALYSIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sites_for_disease(disease, SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, sample_sizes, disease_ratios, num_tests):\n",
    "    # Load data for the disease\n",
    "    data_path = path = os.path.join('DONNES','COMPILATIONS', f'{disease}_combination_all_metrics_CamCAN.csv.gz')\n",
    "\n",
    "    # Define site directory\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, disease)\n",
    "\n",
    "    # Generate synthetic sites\n",
    "    generate_sites(sample_sizes, disease_ratios, num_tests, directory_site, data_path, disease=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "method= \"classic\"\n",
    "SYNTHETIC_SITES_VERSION = \"v1\"\n",
    "\n",
    "diseases = get_diseases(True)\n",
    "# diseases = ['SYN_0.1']\n",
    "# robust_methods = ['IQR', 'MAD', 'MAD_MEAN']\n",
    "robust_methods = ['MAD_MEAN', \"IQR\"]\n",
    "\n",
    "print('do')\n",
    "\n",
    "\n",
    "#sample_sizes = [30, 50, 100, 150, 200, 300]  # Différentes tailles d'échantillon\n",
    "#disease_ratios = [0.1, 0.2, 0.3, 0.4, 0.5, 0.7]  # Différents pourcentages de malades\n",
    "sample_sizes = [100]  # Différentes tailles d'échantillon\n",
    "disease_ratios = [0.3]  # Différents pourcentages de malades\n",
    "num_tests = 10  # Nombre de tests à effectuer pour chaque combinaison\n",
    "\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(generate_sites_for_disease)(disease, SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, sample_sizes, disease_ratios, num_tests)\n",
    "    for disease in diseases\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for robust_method in robust_methods:\n",
    "#     directory = os.path.join(MAINFOLDER, robust_method)\n",
    "#     # Initialize DataFrames to store the results\n",
    "#     outliers_compilation = pd.DataFrame()\n",
    "#     detection_metrics_summary = pd.DataFrame()\n",
    "#     for disease in diseases:\n",
    "#         directory_disease = os.path.join(directory, disease)\n",
    "#         directory_site = os.path.join(SYNTHETIC_SITES ,SYNTHETIC_SITES_VERSION, disease)\n",
    "#         for sample_size in sample_sizes:\n",
    "#             for disease_ratio in disease_ratios:        \n",
    "#                 sizeDir = os.path.join(directory_disease, f\"{sample_size}_{int(disease_ratio*100)}\")\n",
    "#                 sizeDir_site = os.path.join(directory_site, f\"{sample_size}_{int(disease_ratio*100)}\")\n",
    "#                 for i in range(num_tests):\n",
    "#                     tempDir = os.path.join(sizeDir, f\"{i}\")\n",
    "#                     tempDir_site = os.path.join(sizeDir_site, f\"{i}\")\n",
    "#                     os.makedirs(tempDir, exist_ok=True)\n",
    "\n",
    "#                     train_file_name = f\"train_{sample_size}_{int(disease_ratio*100)}_{i}_all.csv\"\n",
    "#                     test_file_name = f\"test_{sample_size}_{int(disease_ratio*100)}_{i}_all.csv\"\n",
    "                    \n",
    "#                     # Sauvegarder l'échantillon dans un fichier temporaire\n",
    "#                     temp_file = os.path.join(tempDir_site,train_file_name )\n",
    "#                     train_df = pd.read_csv(temp_file)\n",
    "#                     train_df = train_df[~train_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "#                     train_df.to_csv(os.path.join(tempDir,train_file_name ), index=False)\n",
    "\n",
    "#                     test_file = os.path.join(tempDir_site, test_file_name)\n",
    "#                     test_df = pd.read_csv(test_file)\n",
    "#                     test_df = test_df[~test_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "#                     test_df.to_csv(os.path.join(tempDir,test_file_name ), index=False)\n",
    "\n",
    "\n",
    "\n",
    "#                     outliers_idx = find_outliers(train_df, robust_method)\n",
    "#                     detection_performance = analyze_detection_performance(outliers_idx, train_df)\n",
    "#                     scatter_plot_with_colors(train_df, outliers_idx,  'mean_no_cov', sizeDir ,f'Scatter_{robust_method}_{disease}_{sample_size}_{int(disease_ratio*100)}_{i}', f'Scatter for method {robust_method} disease: {disease}, with {sample_size} patients, {disease_ratio * 100} % of sick #{i}')\n",
    "\n",
    "#                     detection_performance['disease'] = disease\n",
    "\n",
    "#                     outliers = train_df.loc[outliers_idx]\n",
    "                    \n",
    "\n",
    "#                     detection_metrics_summary = pd.concat([detection_metrics_summary, detection_performance])\n",
    "#                     outliers_compilation = pd.concat([outliers_compilation, outliers])\n",
    "#     # Save the metrics and distances compilation DataFrames to CSV files\n",
    "#     detection_metrics_summary.to_csv(os.path.join(directory, \"detection_metrics_summary.csv\"), index=False)\n",
    "#     outliers_compilation.to_csv(os.path.join(directory, \"outliers_compilation.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Function to process one combination of robust_method, disease, sample_size, and disease_ratio\n",
    "def process_combination(robust_method, disease, sample_size, disease_ratio, MAINFOLDER, SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, num_tests):\n",
    "    directory = os.path.join(MAINFOLDER, robust_method, disease)\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, disease)\n",
    "\n",
    "    sizeDir = os.path.join(directory, f\"{sample_size}_{int(disease_ratio*100)}\")\n",
    "    sizeDir_site = os.path.join(directory_site, f\"{sample_size}_{int(disease_ratio*100)}\")\n",
    "\n",
    "    detection_metrics_files = []\n",
    "    outliers_files = []\n",
    "\n",
    "    for i in range(num_tests):\n",
    "        tempDir = os.path.join(sizeDir, f\"{i}\")\n",
    "        tempDir_site = os.path.join(sizeDir_site, f\"{i}\")\n",
    "        os.makedirs(tempDir, exist_ok=True)\n",
    "\n",
    "        train_file_name = f\"train_{sample_size}_{int(disease_ratio*100)}_{i}_all.csv\"\n",
    "        test_file_name = f\"test_{sample_size}_{int(disease_ratio*100)}_{i}_all.csv\"\n",
    "\n",
    "        # Load and filter training dataset\n",
    "        temp_file = os.path.join(tempDir_site, train_file_name)\n",
    "        train_df = pd.read_csv(temp_file)\n",
    "        train_df = train_df[~train_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "        train_df.to_csv(os.path.join(tempDir, train_file_name), index=False)\n",
    "\n",
    "        # Load and filter test dataset\n",
    "        test_file = os.path.join(tempDir_site, test_file_name)\n",
    "        test_df = pd.read_csv(test_file)\n",
    "        test_df = test_df[~test_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "        test_df.to_csv(os.path.join(tempDir, test_file_name), index=False)\n",
    "\n",
    "        # Outlier detection\n",
    "        outliers_idx = find_outliers(train_df, robust_method)\n",
    "        detection_performance = analyze_detection_performance(outliers_idx, train_df)\n",
    "\n",
    "        \n",
    "\n",
    "        # Scatter plot for visualization\n",
    "        scatter_plot_with_colors(\n",
    "            train_df, outliers_idx, 'mean_no_cov', sizeDir,\n",
    "            f'Scatter_{robust_method}_{disease}_{sample_size}_{int(disease_ratio*100)}_{i}',\n",
    "            f'Scatter for method {robust_method} disease: {disease}, with {sample_size} patients, {disease_ratio * 100} % of sick #{i}'\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        detection_performance['disease'] = disease\n",
    "        outliers = train_df.loc[outliers_idx]\n",
    "\n",
    "        detection_performance['method'] = robust_method\n",
    "        outliers['method'] = robust_method\n",
    "\n",
    "\n",
    "        detection_file = os.path.join(sizeDir, f\"detection_metrics_summary_{sample_size}_{int(disease_ratio*100)}_{i}.csv\")\n",
    "        outliers_file = os.path.join(sizeDir, f\"outliers_compilation_{sample_size}_{int(disease_ratio*100)}_{i}.csv\")\n",
    "\n",
    "        detection_performance.to_csv(detection_file, index=False)\n",
    "        outliers.to_csv(outliers_file, index=False)\n",
    "\n",
    "        detection_metrics_files.append(detection_file)\n",
    "        outliers_files.append(outliers_file)\n",
    "\n",
    "    return detection_metrics_files, outliers_files\n",
    "\n",
    "# Generate all task combinations\n",
    "tasks = [\n",
    "    (robust_method, disease, sample_size, disease_ratio, MAINFOLDER, SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, num_tests)\n",
    "    for robust_method in robust_methods\n",
    "    for disease in diseases\n",
    "    for sample_size in sample_sizes\n",
    "    for disease_ratio in disease_ratios\n",
    "]\n",
    "\n",
    "# Run all combinations in parallel and collect file paths\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_combination)(*task) for task in tasks\n",
    ")\n",
    "\n",
    "print(f\"Final results saved in {MAINFOLDER}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten file lists\n",
    "detection_metrics_files = [file for sublist in results for file in sublist[0]]\n",
    "outliers_files = [file for sublist in results for file in sublist[1]]\n",
    "\n",
    "# Read and concatenate all detection_metrics_summary files\n",
    "detection_metrics_summary = pd.concat([pd.read_csv(file) for file in detection_metrics_files], ignore_index=True)\n",
    "\n",
    "# Read and concatenate all outliers_compilation files\n",
    "outliers_compilation = pd.concat([pd.read_csv(file) for file in outliers_files], ignore_index=True)\n",
    "\n",
    "# Save final concatenated files\n",
    "detection_metrics_summary.to_csv(os.path.join(MAINFOLDER, \"detection_metrics_summary.csv\"), index=False)\n",
    "outliers_compilation.to_csv(os.path.join(MAINFOLDER, \"outliers_compilation.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exemple d'utilisation\n",
    "# precision_df = calculate_precision_by_bundle(pd.read_csv(os.path.join(MAINFOLDER, robust_method, \"detection_metrics_summary.csv\")))\n",
    "# precision_df = precision_df.sort_values(by='precision', ascending=False)\n",
    "# precision_df.to_csv(os.path.join(directory_disease, \"metrics_per_bundle.csv\"), index=True)\n",
    "# precision_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_df = precision_df.sort_values(by='f1_score', ascending=False)\n",
    "# precision_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the combined data\n",
    "data_combined = pd.read_csv(os.path.join(MAINFOLDER,'detection_metrics_summary.csv'))\n",
    "\n",
    "results_folder = os.path.join(MAINFOLDER, 'DETECTION_PERFORMANCE_BOXPLOTS')\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "for disease in diseases:\n",
    "    disease_data = data_combined[data_combined['disease'] == disease]\n",
    "    \n",
    "    # Filter the relevant columns\n",
    "    filtered_data = disease_data[['metric', 'overall', 'site', 'method']]\n",
    "    \n",
    "    # Extract metrics of interest\n",
    "    metrics_of_interest = ['precision', 'f1_score', 'recall', 'false_positives']\n",
    "    filtered_data = filtered_data[filtered_data['metric'].isin(metrics_of_interest)]\n",
    "    \n",
    "    # Group sites by unique patient-malade combination\n",
    "    filtered_data['site_group'] = filtered_data['site'].str.extract(r'(\\d+_patients_\\d+_percent)')[0]\n",
    "    \n",
    "    # Set up the plot style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, metric in enumerate(metrics_of_interest):\n",
    "        metric_data = filtered_data[filtered_data['metric'] == metric]\n",
    "    \n",
    "        # Create the boxplot\n",
    "        sns.boxplot(\n",
    "            x='site_group',\n",
    "            y='overall',\n",
    "            hue='method',  # Add the method as a hue\n",
    "            data=metric_data,\n",
    "            showfliers=False,  # Remove outliers for clarity\n",
    "            ax=axes[i]\n",
    "        )\n",
    "    \n",
    "        # Customize the plot\n",
    "        axes[i].set_title(f'Boxplot of {metric} across patient-malade combinations (by method) for {disease}', fontsize=16)\n",
    "        axes[i].set_xlabel('Patient-Malade Combination', fontsize=12)\n",
    "        axes[i].set_ylabel('Overall Value', fontsize=12)\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        axes[i].legend(title='Method', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_folder,f'{disease}_detection_performance.png'))\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = add_nb_patients_and_diseased(data_combined)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'site' and 'num_diseased' columns\n",
    "data_combinedCopy = data_combined.copy()\n",
    "data_combinedCopy = data_combinedCopy.drop(columns=['site', 'num_diseased'], errors='ignore')\n",
    "data_combinedCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_df = (\n",
    "    data_combinedCopy\n",
    "    .groupby(['num_patients', 'disease_ratio', 'disease', 'metric', 'method'])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "mean_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
