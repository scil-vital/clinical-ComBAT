{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS and UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "import os\n",
    "\n",
    "from scripts import combat_info\n",
    "from scripts import combat_quick_apply\n",
    "from scripts import combat_quick_QC\n",
    "\n",
    "\n",
    "CAMCAN = \"./DONNES/CamCAN.md.raw.csv.gz\"\n",
    "COMPILATION = \"./DONNES/adni_compilation.csv.gz\"\n",
    "\n",
    "SYNTHETIC_SITES = \"ROBUST/SYNTHETIC_SITES\"\n",
    "\n",
    "MAINFOLDER = \"ROBUST\"\n",
    "\n",
    "RAWFOLDER = \"RAW\"\n",
    "\n",
    "ANALYSISFOLDER = \"ANALYSIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(mov_data_file):\n",
    "    [df,bundles] = combat_info.info(mov_data_file)\n",
    "    nb_hc = int(re.findall('HC\\(n=(\\d+)',df[\"DetailInfos\"][\"Disease\"])[0])\n",
    "    nb_total = df[\"DetailInfos\"][\"Number of Subject\"]\n",
    "    nb_sick = nb_total - nb_hc\n",
    "    return [nb_total,nb_hc,nb_sick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bundles(mov_data_file):\n",
    "    return combat_info.get_bundles(mov_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_text(x):\n",
    "    return \"NoRobust\" if x == 'No' else x\n",
    "\n",
    "def rwp_text(x):\n",
    "    return \"RWP\" if x else \"NoRWP\"\n",
    "def get_site(mov_data_file):\n",
    "    mov_data = pd.read_csv(mov_data_file)\n",
    "    return mov_data.site.unique()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nb_patients_and_diseased(df):\n",
    "  df['num_patients'] = df['site'].str.extract(r'(\\d+)_patients')[0].astype(int)\n",
    "  df['disease_ratio'] = df['site'].str.extract(r'(\\d+)_percent')[0].astype(int)\n",
    "  df['num_diseased'] = (df['num_patients'] * df['disease_ratio']/100).astype(int)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(df1,df2, title, bundle='mni_MCP'):\n",
    "    df1_bundle = df1[df1['bundle'] == bundle]\n",
    "    df2_bundle = df2[df2['bundle'] == bundle]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(df1_bundle['age'], df1_bundle['mean'], label='Train', alpha=0.5, color='green')\n",
    "    plt.scatter(df2_bundle['age'], df2_bundle['mean'], label='Test', alpha=0.5, color='red')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Mean')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SITE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(file_path, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Split the DataFrame into training and testing sets, ensuring the same proportion of HC and non-HC patients\n",
    "    and that data from the same sid are in the same dataset.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the CSV file to split.\n",
    "    test_size (float): The proportion of the dataset to include in the test split.\n",
    "    random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Training set.\n",
    "    pd.DataFrame: Testing set.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Group by 'sid' and get unique sids\n",
    "    unique_sids = df.groupby('sid').first().reset_index()\n",
    "    \n",
    "    # Split the unique sids into train and test sets\n",
    "    train_sids, test_sids = train_test_split(unique_sids, test_size=test_size, random_state=random_state, stratify=unique_sids['disease'])\n",
    "    \n",
    "    # Create train and test DataFrames by filtering the original DataFrame\n",
    "    train_df = df[df['sid'].isin(train_sids['sid'])]\n",
    "    test_df = df[df['sid'].isin(test_sids['sid'])]\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_patients(df, num_patients, disease_ratio,index):\n",
    "    # Lire le fichier CSV dans un DataFrame\n",
    "    \n",
    "    # Calculer le nombre de patients malades et sains\n",
    "    num_diseased = int(num_patients * disease_ratio)\n",
    "    num_healthy = num_patients - num_diseased\n",
    "    \n",
    "    # Filtrer les patients en santé (HC) et malades\n",
    "    healthy_patients = df[df['disease'] == 'HC']\n",
    "    diseased_patients = df[df['disease'] != 'HC']\n",
    "    \n",
    "    # S'assurer qu'il y a assez de patients pour chaque catégorie\n",
    "    if len(healthy_patients['sid'].unique()) < num_healthy or len(diseased_patients['sid'].unique()) < num_diseased:\n",
    "        raise ValueError(\"Nombre insuffisant de patients en santé ou malades pour l'échantillon demandé.\")\n",
    "    \n",
    "    # Sélectionner un échantillon aléatoire de patients sains et malades\n",
    "    sampled_healthy = healthy_patients.groupby('sid').sample(frac=1).head(num_healthy * df['bundle'].nunique())\n",
    "    sampled_diseased = diseased_patients.groupby('sid').sample(frac=1).head(num_diseased * df['bundle'].nunique())\n",
    "    \n",
    "    # Combiner les échantillons pour obtenir le DataFrame final\n",
    "    sampled_df = pd.concat([sampled_healthy, sampled_diseased])\n",
    "    # Modifier les valeurs de 'site' pour toutes les lignes\n",
    "    sampled_df['site'] = f\"{num_patients}_patients_{int(disease_ratio*100)}_percent_{index}\"\n",
    "    \n",
    "    # Retourner le DataFrame final\n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_biaised_data(df1, df2, \n",
    "                additive_uniform_low=-3, additive_uniform_high=3, \n",
    "                multiplicative_uniform_low=0.5, multiplicative_uniform_high=2, \n",
    "                additive_std_low=0.01, additive_std_high=0.1, \n",
    "                multiplicative_std_low=0.01, multiplicative_std_high=0.1):\n",
    "    \"\"\"\n",
    "    Génère des biais additifs et multiplicatifs pour chaque bundle en fonction de df1, puis applique ces biais à df1 et df2\n",
    "    de manière indépendante en tenant compte des covariables (âge, sexe, latéralité) et en centrant les résidus.\n",
    "\n",
    "    Parameters:\n",
    "    - df1, df2 (pd.DataFrame): Les DataFrames sur lesquels appliquer les biais.\n",
    "    - additive_uniform_low, additive_uniform_high : paramètres pour le biais additif.\n",
    "    - multiplicative_uniform_low, multiplicative_uniform_high : paramètres pour le biais multiplicatif.\n",
    "    - additive_std_low, additive_std_high : paramètres pour l'écart-type du biais additif.\n",
    "    - multiplicative_std_low, multiplicative_std_high : paramètres pour l'écart-type du biais multiplicatif.\n",
    "\n",
    "    Returns:\n",
    "    - tuple : Deux DataFrames avec les biais appliqués indépendamment.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionnaires pour stocker les biais par bundle\n",
    "    additive_bias_per_bundle = {}\n",
    "    multiplicative_bias_per_bundle = {}\n",
    "\n",
    "    # # Tirer les moyennes de biais de distributions uniformes pour le bundle\n",
    "    additive_mean = np.random.uniform(low=additive_uniform_low, high=additive_uniform_high)\n",
    "    multiplicative_mean = np.random.uniform(low=multiplicative_uniform_low, high=multiplicative_uniform_high)\n",
    "    \n",
    "    # # Tirer les écarts-types de biais de distributions uniformes pour le bundle\n",
    "    additive_std = np.random.uniform(low=additive_std_low, high=additive_std_high)\n",
    "    multiplicative_std = np.random.uniform(low=multiplicative_std_low, high=multiplicative_std_high)\n",
    "\n",
    "    # Calcul des biais pour chaque bundle unique dans df1\n",
    "    for bundle in df1['bundle'].unique(): \n",
    "        # Générer un biais additif et multiplicatif spécifique au bundle\n",
    "        additive_bias_per_bundle[bundle] = np.random.normal(loc=additive_mean, scale=additive_std)\n",
    "        multiplicative_bias_per_bundle[bundle] = np.random.normal(loc=multiplicative_mean, scale=multiplicative_std)\n",
    "   \n",
    "    # Appliquer les biais indépendamment à df1 et df2 en utilisant les mêmes biais générés\n",
    "    combined = pd.concat([df1, df2], ignore_index=True)\n",
    "    biased_df = apply_bias(combined, additive_bias_per_bundle, multiplicative_bias_per_bundle)\n",
    "    biased_df1 = biased_df[biased_df['sid'].isin(df1['sid'])]\n",
    "    biased_df2 = biased_df[biased_df['sid'].isin(df2['sid'])]\n",
    "    bias_parameters = {\n",
    "        'additive_mean': additive_mean,\n",
    "        'multiplicative_mean': multiplicative_mean,\n",
    "        'additive_std': additive_std,\n",
    "        'multiplicative_std': multiplicative_std\n",
    "    }\n",
    "    \n",
    "    return biased_df1, biased_df2, additive_bias_per_bundle, multiplicative_bias_per_bundle, bias_parameters\n",
    "\n",
    "def apply_bias(dataframe, additive_bias_per_bundle, multiplicative_bias_per_bundle):\n",
    "    biased_df = dataframe.copy()\n",
    "    \n",
    "    # Application de la régression et des biais pour chaque bundle unique\n",
    "    for bundle in biased_df['bundle'].unique():\n",
    "        # Filtrer le DataFrame pour le bundle actuel\n",
    "        bundle_df = biased_df[biased_df['bundle'] == bundle]\n",
    "\n",
    "        # Préparer les covariables pour la régression\n",
    "        X = bundle_df[['age', 'sex', 'handedness']]\n",
    "        y = bundle_df['mean']\n",
    "        \n",
    "        # Ajuster le modèle de régression linéaire pour le bundle\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        # Calculer les prédictions et les résidus pour le bundle\n",
    "        predicted_mean = model.predict(X)\n",
    "        residuals = y - predicted_mean\n",
    "\n",
    "        # Récupérer les biais pour le bundle actuel\n",
    "        additive_bias = additive_bias_per_bundle[bundle]\n",
    "        multiplicative_bias = multiplicative_bias_per_bundle[bundle]\n",
    "        \n",
    "        # Appliquer les biais aux résidus centrés et réintégrer les effets des covariables\n",
    "        biased_means_bundle = residuals * multiplicative_bias + additive_bias * np.std(residuals) + predicted_mean\n",
    "        biased_df.loc[biased_df['bundle'] == bundle, 'mean'] = biased_means_bundle\n",
    "    \n",
    "    # Assigner les valeurs biaisées calculées au DataFrame\n",
    "    return biased_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE SITES\n",
    "def generate_sites(sample_sizes, disease_ratios, num_tests, SYNTHETIC_SITES_VERSION):\n",
    "    directory = os.path.join(SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION)\n",
    "    train_df, test_df = split_train_test(COMPILATION, test_size=0.2, random_state=42)\n",
    "    # Initialize DataFrames to store the results\n",
    "    for sample_size in sample_sizes:\n",
    "        for disease_ratio in disease_ratios:  \n",
    "            sizeDir = os.path.join(directory, f\"{sample_size}_{int(disease_ratio*100)}\")\n",
    "            for i in range(num_tests):\n",
    "                \n",
    "                tempDir = os.path.join(sizeDir, f\"{i}\")\n",
    "                os.makedirs(tempDir, exist_ok=True)\n",
    "\n",
    "                train_df_biaised, test_df_biaised, gammas, deltas, parameters= generate_biaised_data(train_df, test_df)\n",
    "\n",
    "                sampled_df_biaied =  sample_patients(train_df_biaised, sample_size, disease_ratio,i)\n",
    "\n",
    "                # Sauvegarder l'échantillon dans un fichier temporaire\n",
    "                temp_train_file = os.path.join(tempDir, f\"train_{sample_size}_{int(disease_ratio*100)}_{i}.csv\")\n",
    "                sampled_df_biaied.to_csv(temp_train_file, index=False)\n",
    "                \n",
    "                temp_test_file = os.path.join(tempDir, f\"test_{sample_size}_{int(disease_ratio*100)}_{i}.csv\")\n",
    "                test_df_biaised.to_csv(temp_test_file, index=False)\n",
    "\n",
    "                # Sauvegarde dans un fichier JSON\n",
    "                with open(os.path.join(tempDir,'parameters.json'), 'w') as file:\n",
    "                    json.dump({'parameters': parameters, 'gammas': gammas, 'deltas': deltas}, file, indent=4)\n",
    "\n",
    "                cmd = (\n",
    "                    \"scripts/combat_visualize_data.py\"\n",
    "                    + \" \"\n",
    "                    + COMPILATION\n",
    "                    + \" \"\n",
    "                    + temp_train_file\n",
    "                    + \" --out_dir \"\n",
    "                    + os.path.join(tempDir, \"VIZ\")\n",
    "                    + \" -f\"\n",
    "                    + \" --bundles all\"\n",
    "                )\n",
    "                subprocess.call(cmd, shell=True)\n",
    "                cmd = (\n",
    "                    \"scripts/combat_visualize_data.py\"\n",
    "                    + \" \"\n",
    "                    + COMPILATION\n",
    "                    + \" \"\n",
    "                    + temp_test_file\n",
    "                    + \" --out_dir \"\n",
    "                    + os.path.join(tempDir, \"VIZ_TEST\")\n",
    "                    + \" -f\"\n",
    "                    + \" --bundles all\"\n",
    "                )\n",
    "                subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HARMONIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(mov_data_file, robust, rwp, directory, hc,):\n",
    "    ###########\n",
    "    ### fit ###\n",
    "    ###########\n",
    "    output_model_filename = (\n",
    "            get_site(mov_data_file)\n",
    "            + \".\"\n",
    "            + metric\n",
    "            + \".\"\n",
    "            + method\n",
    "            + \".\"\n",
    "            + robust_text(robust)\n",
    "            + \".\"\n",
    "            + rwp_text(rwp)\n",
    "            + \".model.csv\"\n",
    "        )\n",
    "    cmd = (\n",
    "        \"scripts/combat_quick_fit.py\"\n",
    "        + \" \"\n",
    "        + CAMCAN\n",
    "        + \" \"\n",
    "        + mov_data_file\n",
    "        + \" --out_dir \"\n",
    "        + directory\n",
    "        + \" --output_model_filename \"\n",
    "        + output_model_filename\n",
    "        + \" --method \"\n",
    "        + method\n",
    "        + \" --robust \"\n",
    "        + robust\n",
    "        + \" -f \"\n",
    "    )\n",
    "    if rwp:\n",
    "        cmd += ' --rwp'\n",
    "    if hc: \n",
    "        cmd += ' --hc'\n",
    "    subprocess.call(cmd, shell=True)\n",
    "    return output_model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(mov_data_file, model_filename, robust, rwp, directory):\n",
    "    output_filename = os.path.join(\n",
    "            directory,\n",
    "            get_site(mov_data_file)\n",
    "            + \".\"\n",
    "            + metric\n",
    "            + \".\"\n",
    "            + method\n",
    "            + \".\"\n",
    "            + robust_text(robust)\n",
    "            + \".\"\n",
    "            + rwp_text(rwp)\n",
    "            + \".csv\"\n",
    "        )\n",
    "    combat_quick_apply.apply(mov_data_file, model_filename, output_filename)\n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_harmonization(f, new_f, directory):\n",
    "    cmd = (\n",
    "        \"scripts/combat_visualize_harmonization.py\"\n",
    "        + \" \"\n",
    "        + CAMCAN\n",
    "        + \" \"\n",
    "        + f\n",
    "        + \" \"\n",
    "        + new_f\n",
    "        + \" --out_dir \"\n",
    "        + directory\n",
    "        #+ \" --bundles all\"\n",
    "        + \" -f\"\n",
    "    )\n",
    "    subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QC(output_filename, output_model_filename):\n",
    "    return combat_quick_QC.QC(CAMCAN,output_filename, output_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_compilation(df):\n",
    "    # Charger le DataFrame COMPILATION\n",
    "    compilation_df = pd.read_csv(COMPILATION)\n",
    "    \n",
    "    # Filtrer les patients de COMPILATION qui sont dans df en utilisant les sid\n",
    "    common_sids = df['sid'].unique()\n",
    "    filtered_compilation_df = compilation_df[compilation_df['sid'].isin(common_sids)]\n",
    "    \n",
    "    # Initialiser une liste pour stocker les résultats\n",
    "    comparison_df = pd.DataFrame()\n",
    "\n",
    "    # Comparer la différence absolue de la colonne mean par bundle\n",
    "    for bundle in df['bundle'].unique():\n",
    "        df_bundle = df[df['bundle'] == bundle]\n",
    "        compilation_bundle = filtered_compilation_df[filtered_compilation_df['bundle'] == bundle]\n",
    "        \n",
    "        # Fusionner les deux DataFrames sur les colonnes 'sid' et 'bundle'\n",
    "        merged_df = pd.merge(df_bundle, compilation_bundle, on=['sid', 'bundle'], suffixes=('_df', '_compilation'))\n",
    "        \n",
    "        # Calculer la différence absolue de la colonne mean\n",
    "        merged_df['abs_diff_mean'] = (merged_df['mean_df'] - merged_df['mean_compilation']).abs()\n",
    "        # Calculer la somme des différences absolues pour le bundle\n",
    "        comparison_df[bundle] = merged_df['abs_diff_mean']\n",
    "           \n",
    "    # Ajouter le site au DataFrame\n",
    "    mean_df = pd.DataFrame(comparison_df.mean()).transpose()\n",
    "    \n",
    "    return mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_presentation(directory):\n",
    "    # Create a presentation object\n",
    "    prs = Presentation()\n",
    "    \n",
    "    # Define the subdirectories\n",
    "    subdirs = [\"hc\", \"NoRobust\", \"robust\", \"robust_rwp\"]\n",
    "    # Get the list of images\n",
    "    images = [img for img in os.listdir(os.path.join(directory, subdirs[0])) if method in img and img.endswith('.png')]\n",
    "    \n",
    "    for img in images:\n",
    "        slide_layout = prs.slide_layouts[5]  # Use a blank slide layout\n",
    "        slide = prs.slides.add_slide(slide_layout)\n",
    "        \n",
    "        for i, subdir in enumerate(subdirs):\n",
    "            img_path = os.path.join(directory, subdir, img)\n",
    "            left = Inches(0.5 + (i % 2) * 4.5)  # Positioning images in two columns\n",
    "            top = Inches(0.2 + (i // 2) * 3.5)  # Positioning images in two rows with more space between rows\n",
    "            \n",
    "            # Add text above the image\n",
    "            text_box = slide.shapes.add_textbox(left, top, width=Inches(4), height=Inches(0.5))\n",
    "            text_frame = text_box.text_frame\n",
    "            text_frame.text = subdir\n",
    "            \n",
    "            # Add the image\n",
    "            slide.shapes.add_picture(img_path, left, top + Inches(0.5), width=Inches(4))\n",
    "    \n",
    "    # Save the presentation\n",
    "    prs.save(os.path.join(directory, 'harmonization_results.pptx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distances(directory, site, hc_dists, no_robust_dists, robust_dists, robust_rwp_dists):\n",
    "    comparison_results = {\n",
    "        \"hc_vs_no_robust\": (np.array(hc_dists) - np.array(no_robust_dists))/np.array(no_robust_dists)*100,\n",
    "        \"robust_vs_no_robust\": (np.array(robust_dists) - np.array(no_robust_dists))/np.array(no_robust_dists)*100,\n",
    "        \"robust_rwp_vs_no_robust\": (np.array(robust_rwp_dists) - np.array(no_robust_dists))/np.array(no_robust_dists)*100\n",
    "    }\n",
    "    df = pd.DataFrame(comparison_results)\n",
    "    \n",
    "    # Calculer le nombre de comparaisons négatives et positives, et les moyennes et médianes\n",
    "    results = []\n",
    "    for method in comparison_results.keys():\n",
    "        negative_values = df[method][df[method] < 0]\n",
    "        positive_values = df[method][df[method] >= 0]\n",
    "        \n",
    "        num_negative = len(negative_values)\n",
    "        num_positive = len(positive_values)\n",
    "        \n",
    "        mean_negative = negative_values.mean() if num_negative > 0 else 0\n",
    "        mean_positive = positive_values.mean() if num_positive > 0 else 0\n",
    "        \n",
    "        median_negative = negative_values.median() if num_negative > 0 else 0\n",
    "        median_positive = positive_values.median() if num_positive > 0 else 0\n",
    "        \n",
    "        mean_difference = df[method].mean()\n",
    "        \n",
    "        results.append({\n",
    "            \"site\": site,\n",
    "            \"comparaison\": method,\n",
    "            \"Nb comp. nég.\": num_negative,\n",
    "            \"Nb comp. pos.\": num_positive,\n",
    "            \"Moy. tot.\": mean_difference,\n",
    "            \"Moy. val. nég.\": mean_negative,\n",
    "            \"Moy. val. pos.\": mean_positive,\n",
    "            \"Méd. val. nég.\": median_negative,\n",
    "            \"Méd. val. pos.\": median_positive\n",
    "        })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(os.path.join(directory, f\"{site}_comparison_results.csv\"), index=False)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize(f_train, f_test, directory, robust, rwp,hc):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f_train)\n",
    "    \n",
    "    # Fit the model\n",
    "    output_model_filename = fit(f_train, robust, rwp, directory, hc)\n",
    "    output_model_filename = os.path.join(directory, output_model_filename)\n",
    "    # Apply the model\n",
    "    output_filename = apply(f_test, output_model_filename, robust, rwp, directory) \n",
    "    \n",
    "    # Perform quality control\n",
    "    dists, bundle_names = QC(output_filename, output_model_filename)\n",
    "    dists_df = pd.DataFrame([dists], columns=bundle_names)\n",
    "    dists_df['site'] = get_site(f_train)\n",
    "    \n",
    "    # Visualize the harmonization\n",
    "    visualize_harmonization(f_test, output_filename, directory)\n",
    "\n",
    "    mea = compare_with_compilation(pd.read_csv(output_filename))\n",
    "    mea['site'] = get_site(f_train)\n",
    "    \n",
    "    # If robust is not \"No\", load metrics and outliers\n",
    "    if robust != \"No\":\n",
    "        metrics_filename = os.path.join(directory, f\"metrics_{get_site(f_train)}_{robust_text(robust)}_{rwp_text(rwp)}.csv\")\n",
    "        outliers_filename = os.path.join(directory, f\"outliers_{get_site(f_train)}_{robust_text(robust)}_{rwp_text(rwp)}.csv\")\n",
    "        \n",
    "        # Load metrics from CSV file\n",
    "        loaded_metrics = pd.read_csv(metrics_filename, index_col=0)\n",
    "        \n",
    "        # Load outliers from CSV file\n",
    "        loaded_outliers_df = pd.read_csv(outliers_filename, index_col=0)\n",
    "        \n",
    "        return [dists_df, mea, loaded_metrics, loaded_outliers_df]\n",
    "    return[dists_df, mea, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_site(f_train,f_test, robust, directory):\n",
    "    # 4 harmonization\n",
    "    harmonization_hc = harmonize(f_train, f_test, os.path.join(directory, \"hc\"), \"No\", False, True)\n",
    "    harmonization_no_robust = harmonize(f_train, f_test, os.path.join(directory, \"NoRobust\"), \"No\", False, False)\n",
    "    harmonization_robust = harmonize(f_train, f_test, os.path.join(directory, \"robust\"), robust, False, False)\n",
    "    harmonization_robust_rwp = harmonize(f_train, f_test, os.path.join(directory, \"robust_rwp\"), robust, True, False)\n",
    "\n",
    "\n",
    "    create_presentation(directory)\n",
    "\n",
    "    #dists_analyze = compare_distances(directory, get_site(f_train), harmonization_hc[0], harmonization_no_robust[0], harmonization_robust[0], harmonization_robust_rwp[0])\n",
    "    # Combine distances in a single DataFrame\n",
    "    distances_combined = pd.concat([harmonization_hc[0], harmonization_no_robust[0], harmonization_robust[0], harmonization_robust_rwp[0]], ignore_index=True)\n",
    "    distances_combined['method'] = ['hc', 'no_robust', 'robust', 'robust_rwp']\n",
    "\n",
    "    # Combine MEA in a single DataFrame\n",
    "    mea_combined = pd.concat([harmonization_hc[1], harmonization_no_robust[1], harmonization_robust[1], harmonization_robust_rwp[1]], ignore_index=True)\n",
    "    mea_combined['method'] = ['hc', 'no_robust', 'robust', 'robust_rwp']\n",
    "\n",
    "\n",
    "    #TODO bundles et analyze outliers\n",
    "    return distances_combined, mea_combined, harmonization_robust[2], harmonization_robust[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#Analyse Method\n",
    "def analyse_method(sample_sizes, disease_ratios, num_tests, robust_method, SYNTHETIC_SITES_VERSION):\n",
    "    # Split the data into training and testing sets\n",
    "    directory = os.path.join(MAINFOLDER, robust_method)\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES ,SYNTHETIC_SITES_VERSION)\n",
    "    train_df, test_df = split_train_test(COMPILATION, test_size=0.2, random_state=42)\n",
    "    # Initialize DataFrames to store the results\n",
    "    metrics_compilation = pd.DataFrame()\n",
    "    dists_compilation = pd.DataFrame()\n",
    "    mea_compilation = pd.DataFrame()\n",
    "    outliers_compilation = pd.DataFrame()\n",
    "    for sample_size in sample_sizes:\n",
    "        for disease_ratio in disease_ratios:        \n",
    "            sizeDir = os.path.join(directory, f\"{sample_size}_{int(disease_ratio*100)}\")\n",
    "            sizeDir_site = os.path.join(directory_site, f\"{sample_size}_{int(disease_ratio*100)}\")\n",
    "            for i in range(num_tests):\n",
    "                tempDir = os.path.join(sizeDir, f\"{i}\")\n",
    "                tempDir_site = os.path.join(sizeDir_site, f\"{i}\")\n",
    "                os.makedirs(tempDir, exist_ok=True)\n",
    "\n",
    "                train_file_name = f\"train_{sample_size}_{int(disease_ratio*100)}_{i}.csv\"\n",
    "                test_file_name = f\"test_{sample_size}_{int(disease_ratio*100)}_{i}.csv\"\n",
    "                \n",
    "                # Sauvegarder l'échantillon dans un fichier temporaire\n",
    "                temp_file = os.path.join(tempDir_site,train_file_name )\n",
    "                train_df = pd.read_csv(temp_file)\n",
    "                train_df.to_csv(os.path.join(tempDir,train_file_name ), index=False)\n",
    "\n",
    "                test_file = os.path.join(tempDir_site, test_file_name)\n",
    "                test_df = pd.read_csv(test_file)\n",
    "                test_df.to_csv(os.path.join(tempDir,test_file_name ), index=False)\n",
    "\n",
    "                \n",
    "                # Analyser le site pour le nouvel échantillon\n",
    "                dists_analyze, mea_analyze, metrics, outliers = analyse_site(temp_file, test_file, robust_method, tempDir)\n",
    "                metrics_compilation = pd.concat([metrics_compilation, metrics])\n",
    "                dists_compilation = pd.concat([dists_compilation, dists_analyze])\n",
    "                mea_compilation = pd.concat([mea_compilation, mea_analyze])\n",
    "                outliers_compilation = pd.concat([outliers_compilation, outliers])\n",
    "    # Save the metrics and distances compilation DataFrames to CSV files\n",
    "    metrics_compilation.to_csv(os.path.join(directory, \"metrics_compilation.csv\"), index=False)\n",
    "    dists_compilation.to_csv(os.path.join(directory, \"dists_compilation.csv\"), index=False)\n",
    "    mea_compilation.to_csv(os.path.join(directory, \"mea_compilation.csv\"), index=False)\n",
    "    outliers_compilation.to_csv(os.path.join(directory, \"outliers_compilation.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBUST/SYNTHETIC_SITES/v1/150_30/0/train_150_30_0.csv\n",
      "HC only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model and data site don't match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "      Mean Bhattacharrya distance: 0.050998 (min: 0.009495, max: 0.077729)\n",
      "ROBUST/SYNTHETIC_SITES/v1/150_30/0/train_150_30_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model and data site don't match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n",
      "HC only\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m num_tests \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Nombre de tests à effectuer pour chaque combinaison\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#generate_sites(sample_sizes, disease_ratios, num_tests, SYNTHETIC_SITES_VERSION)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43manalyse_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisease_ratios\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_tests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSYNTHETIC_SITES_VERSION\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 35\u001b[0m, in \u001b[0;36manalyse_method\u001b[0;34m(sample_sizes, disease_ratios, num_tests, robust_method, SYNTHETIC_SITES_VERSION)\u001b[0m\n\u001b[1;32m     31\u001b[0m test_df\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tempDir,test_file_name ), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Analyser le site pour le nouvel échantillon\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m dists_analyze, mea_analyze, metrics, outliers \u001b[38;5;241m=\u001b[39m \u001b[43manalyse_site\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempDir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m metrics_compilation \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([metrics_compilation, metrics])\n\u001b[1;32m     37\u001b[0m dists_compilation \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([dists_compilation, dists_analyze])\n",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m, in \u001b[0;36manalyse_site\u001b[0;34m(f_train, f_test, robust, directory)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyse_site\u001b[39m(f_train,f_test, robust, directory):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# 4 harmonization\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     harmonization_hc \u001b[38;5;241m=\u001b[39m harmonize(f_train, f_test, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhc\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m     harmonization_no_robust \u001b[38;5;241m=\u001b[39m \u001b[43mharmonize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNoRobust\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     harmonization_robust \u001b[38;5;241m=\u001b[39m harmonize(f_train, f_test, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrobust\u001b[39m\u001b[38;5;124m\"\u001b[39m), robust, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     harmonization_robust_rwp \u001b[38;5;241m=\u001b[39m harmonize(f_train, f_test, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrobust_rwp\u001b[39m\u001b[38;5;124m\"\u001b[39m), robust, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m, in \u001b[0;36mharmonize\u001b[0;34m(f_train, f_test, directory, robust, rwp, hc)\u001b[0m\n\u001b[1;32m      9\u001b[0m output_filename \u001b[38;5;241m=\u001b[39m apply(f_test, output_model_filename, robust, rwp, directory) \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Perform quality control\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m dists, bundle_names \u001b[38;5;241m=\u001b[39m \u001b[43mQC\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_model_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m dists_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([dists], columns\u001b[38;5;241m=\u001b[39mbundle_names)\n\u001b[1;32m     14\u001b[0m dists_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_site(f_train)\n",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m, in \u001b[0;36mQC\u001b[0;34m(output_filename, output_model_filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mQC\u001b[39m(output_filename, output_model_filename):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcombat_quick_QC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCAMCAN\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_model_filename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_QC.py:120\u001b[0m, in \u001b[0;36mQC\u001b[0;34m(ref_data_file, mov_data_file, model_file, ignore_bundles, degree_qc)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ref_site \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(ref_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msite\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    118\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel site and reference data site don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m dists \u001b[38;5;241m=\u001b[39m \u001b[43mQC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bundles_bhattacharyya_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmov_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(mov_data\u001b[38;5;241m.\u001b[39msid\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m      Mean Bhattacharrya distance: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m (min: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, max: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;241m%\u001b[39m (np\u001b[38;5;241m.\u001b[39mmean(dists), np\u001b[38;5;241m.\u001b[39mmin(dists), np\u001b[38;5;241m.\u001b[39mmax(dists))\n\u001b[1;32m    127\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/QuickCombat.py:147\u001b[0m, in \u001b[0;36mQuickCombat.get_bundles_bhattacharyya_distance\u001b[0;34m(self, ref_data, mov_data)\u001b[0m\n\u001b[1;32m    144\u001b[0m dists \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bundle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbundle_names:\n\u001b[1;32m    146\u001b[0m     dists\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 147\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bundle_bhattacharyya_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmov_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dists\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/QuickCombat.py:167\u001b[0m, in \u001b[0;36mQuickCombat.get_bundle_bhattacharyya_distance\u001b[0;34m(self, ref_data, mov_data, bundle_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03mReturns the Bhattacharyya distance for one bundle.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m bundle_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbundle_names)\u001b[38;5;241m.\u001b[39mindex(bundle_name)\n\u001b[0;32m--> 167\u001b[0m ref_data, mov_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmov_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m design_ref, y_ref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_design_matrices(ref_data)\n\u001b[1;32m    171\u001b[0m covariate_effect_ref \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\n\u001b[1;32m    172\u001b[0m     design_ref[bundle_idx][\u001b[38;5;241m1\u001b[39m:, :]\u001b[38;5;241m.\u001b[39mtranspose(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_ref[bundle_idx]\n\u001b[1;32m    173\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/QuickCombat.py:89\u001b[0m, in \u001b[0;36mQuickCombat.prepare_data\u001b[0;34m(self, ref_data, mov_data, HC_only)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, ref_data, mov_data, HC_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    Validate and prepare the input sites data before the model fit.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    Data are sorted, the limit age range is applied and 'HC' are selected.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m        Prepared moving site input data.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     ref_data \u001b[38;5;241m=\u001b[39m ref_data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbundle\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massert_data(mov_data)\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/QuickHarmonizationMethod.py:82\u001b[0m, in \u001b[0;36mQuickHarmonizationMethod.assert_data\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing column \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m c \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bundle \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mbundle\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m---> 82\u001b[0m     df1 \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbundle == @bundle and disease == \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_sex_covariate:\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m df1\u001b[38;5;241m.\u001b[39msex\u001b[38;5;241m.\u001b[39munique():\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/frame.py:4811\u001b[0m, in \u001b[0;36mDataFrame.query\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4809\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4810\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 4811\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4813\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   4814\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[res]\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/frame.py:4937\u001b[0m, in \u001b[0;36mDataFrame.eval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4934\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   4935\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolvers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolvers\u001b[39m\u001b[38;5;124m\"\u001b[39m, ())) \u001b[38;5;241m+\u001b[39m resolvers\n\u001b[0;32m-> 4937\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/eval.py:336\u001b[0m, in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# get our (possibly passed-in) scope\u001b[39;00m\n\u001b[1;32m    328\u001b[0m env \u001b[38;5;241m=\u001b[39m ensure_scope(\n\u001b[1;32m    329\u001b[0m     level \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    330\u001b[0m     global_dict\u001b[38;5;241m=\u001b[39mglobal_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m    334\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m parsed_expr \u001b[38;5;241m=\u001b[39m \u001b[43mExpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumexpr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    339\u001b[0m     is_extension_array_dtype(parsed_expr\u001b[38;5;241m.\u001b[39mterms\u001b[38;5;241m.\u001b[39mreturn_type)\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(parsed_expr\u001b[38;5;241m.\u001b[39mterms, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moperand_types\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m     )\n\u001b[1;32m    345\u001b[0m ):\n\u001b[1;32m    346\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine has switched to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m because numexpr does not support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextension array dtypes. Please set your engine to python manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    350\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    351\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:809\u001b[0m, in \u001b[0;36mExpr.__init__\u001b[0;34m(self, expr, engine, parser, env, level)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m parser\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visitor \u001b[38;5;241m=\u001b[39m PARSERS[parser](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser)\n\u001b[0;32m--> 809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:828\u001b[0m, in \u001b[0;36mExpr.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    825\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;124;03m    Parse an expression.\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_visitor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:412\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:418\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Module\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly a single expression is allowed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    417\u001b[0m expr \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mbody[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:412\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:421\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Expr\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit_Expr\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:412\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:746\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_BoolOp\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_evaluate_binop(op, node\u001b[38;5;241m.\u001b[39mop, lhs, rhs)\n\u001b[1;32m    745\u001b[0m operands \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisitor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:739\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_BoolOp.<locals>.visitor\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisitor\u001b[39m(x, y):\n\u001b[0;32m--> 739\u001b[0m     lhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_visit_binop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m     rhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_visit_binop(y)\n\u001b[1;32m    742\u001b[0m     op, op_class, lhs, rhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_transform_eq_ne(node, lhs, rhs)\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:735\u001b[0m, in \u001b[0;36mBaseExprVisitor._try_visit_binop\u001b[0;34m(self, bop)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bop, (Op, Term)):\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bop\n\u001b[0;32m--> 735\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:412\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/pandas/core/computation/expr.py:716\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Compare\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m comps \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mcomparators\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# base case: we have something like a CMP b\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcomps\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    717\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslate_In(ops[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    718\u001b[0m     binop \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mBinOp(op\u001b[38;5;241m=\u001b[39mop, left\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39mleft, right\u001b[38;5;241m=\u001b[39mcomps[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "site_group = 'ADNI'\n",
    "robust_method = 'IQR'\n",
    "metric = \"md\"\n",
    "method= \"classic\"\n",
    "\n",
    "SYNTHETIC_SITES_VERSION = \"v1\"\n",
    "\n",
    "\n",
    "sample_sizes = [30, 50, 100, 150, 200,300]  # Différentes tailles d'échantillon\n",
    "disease_ratios = [0.1, 0.3, 0.5, 0.7]  # Différents pourcentages de malades\n",
    "#sample_sizes = [150, 300]  # Différentes tailles d'échantillon\n",
    "#disease_ratios = [0.3]  # Différents pourcentages de malades\n",
    "num_tests = 10  # Nombre de tests à effectuer pour chaque combinaison\n",
    "\n",
    "#generate_sites(sample_sizes, disease_ratios, num_tests, SYNTHETIC_SITES_VERSION)\n",
    "\n",
    "#analyse_method(sample_sizes, disease_ratios, num_tests, robust_method, SYNTHETIC_SITES_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne par site\n",
    "# Nothing really interesting so far\n",
    "directory = os.path.join(MAINFOLDER, robust_method)\n",
    "dists_compilation = pd.read_csv(os.path.join(directory, \"dists_compilation.csv\"))\n",
    "metrics_compilation = pd.read_csv(os.path.join(directory, \"metrics_compilation.csv\"))\n",
    "directory = os.path.join(directory, ANALYSISFOLDER)\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "dists_compilation['site'] = dists_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "metrics_compilation['site'] = metrics_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "\n",
    "# Display the means by site\n",
    "dists_means_by_site = dists_compilation.groupby(['site','method']).mean().reset_index()\n",
    "metrics_means_by_site = metrics_compilation.groupby(['site', 'metric']).mean().reset_index()\n",
    "\n",
    "metrics_means_by_site.to_csv(os.path.join(directory, \"metrics_compilation_mean.csv\"), index=False)\n",
    "dists_means_by_site.to_csv(os.path.join(directory, \"dists_compilation_mean.csv\"), index=False)\n",
    "print(\"FINI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYZE BEST BUNDLES for F1, precision etc\n",
    "def calculate_precision_by_bundle(df):\n",
    "    \"\"\"\n",
    "    Calcule le score de précision par bundle.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Le DataFrame contenant les données avec les colonnes 'bundle' et 'is_malade'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame avec les bundles et leurs scores de précision respectifs.\n",
    "    \"\"\"\n",
    "    total = pd.DataFrame()\n",
    "    df = add_nb_patients_and_diseased(df)\n",
    "\n",
    "    for bundle_column in df.columns:\n",
    "        if bundle_column in ['site','metric','num_patients','disease_ratio','num_diseased']:\n",
    "            continue # Skip non-numeric columns\n",
    "        bundle_df = df[[bundle_column, 'metric']].copy()\n",
    "        grouped_df = bundle_df.groupby(['metric']).mean().reset_index()\n",
    "        grouped_df.set_index('metric', inplace=True)\n",
    "        total = pd.concat([total, grouped_df.T])\n",
    "        \n",
    "    return total\n",
    "# Exemple d'utilisation\n",
    "precision_df = calculate_precision_by_bundle(pd.read_csv(os.path.join(MAINFOLDER, robust_method, \"metrics_compilation.csv\")))\n",
    "precision_df = precision_df.sort_values(by='precision', ascending=False)\n",
    "precision_df.to_csv(os.path.join(directory, \"metrics_per_bundle.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_df = precision_df.sort_values(by='precision', ascending=False)\n",
    "precision_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_df = precision_df.sort_values(by='f1_score', ascending=False)\n",
    "precision_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNT BUNDLES PER OUTLIERS\n",
    "def count_bundles_per_outliers(df):\n",
    "    \"\"\"\n",
    "    Analyze outliers in the DataFrame and calculate the percentage of SIDs with a certain number of occurrences.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing 'sid', 'is_outlier', and 'is_sick' columns.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with the percentage of SIDs with a certain number of occurrences for sick and healthy groups.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Count the number of occurrences of each SID\n",
    "    # Count the number of occurrences of each combination of SID and site\n",
    "    sid_counts = df.groupby(['sid', 'site', 'is_malade']).size().reset_index(name='count_bundle')\n",
    "    \n",
    "    # Divide the dataset into two groups: sick and healthy\n",
    "    sick_sids = sid_counts[sid_counts['is_malade'] == 1]\n",
    "    healthy_sids = sid_counts[sid_counts['is_malade'] == 0]\n",
    "    \n",
    "    # Calculate the percentage of SIDs with a certain number of occurrences for sick group\n",
    "    sick_counts = sick_sids.groupby(['count_bundle']).size().reset_index(name='prct_occurence')\n",
    "    sick_counts['prct_occurence'] = sick_counts['prct_occurence']/sick_counts['prct_occurence'].sum()*100\n",
    "    # Calculate the percentage of SIDs with a certain number of occurrences for healthy group\n",
    "    healthy_counts = healthy_sids.groupby(['count_bundle']).size().reset_index(name='prct_occurence')\n",
    "    healthy_counts['prct_occurence'] = healthy_counts['prct_occurence']/healthy_counts['prct_occurence'].sum()*100\n",
    "\n",
    "    total = pd.merge(sick_counts, healthy_counts, on=['count_bundle'], suffixes=('_sick', '_healthy'))\n",
    "    \n",
    "    return total\n",
    "\n",
    "# Example usage\n",
    "bundles_per_outliers = count_bundles_per_outliers(pd.read_csv(os.path.join(MAINFOLDER, robust_method, \"outliers_compilation.csv\")))\n",
    "bundles_per_outliers.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATION BOX PLOT POUR DISTANCES\n",
    "def plot_bundle(df, prct, directory):\n",
    "    \"\"\"\n",
    "    Crée un graphique pour chaque bundle dans le DataFrame donné.\n",
    "    L'axe des X représente le nombre de patients et l'axe des Y représente la moyenne de la colonne du bundle.\n",
    "    La courbe inclut une zone indiquant l'écart-type (std).\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Le DataFrame contenant les données.\n",
    "    bundle_column (str): Le nom de la colonne du bundle à utiliser pour le graphique.\n",
    "    \"\"\"\n",
    "    directory = os.path.join(directory, \"DISTANCES_PLOTS\", str(prct))\n",
    "    df = df[df['disease_ratio'] == prct *100]\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    for bundle_column in df.columns:\n",
    "        if bundle_column in ['site','method','num_patients','disease_ratio','num_diseased']:\n",
    "            continue # Skip non-numeric columns\n",
    "        bundle_df = df[[bundle_column, 'site', 'method','num_patients','disease_ratio','num_diseased']].copy()\n",
    "        methods = [\"hc\", \"no_robust\", \"robust\", \"robust_rwp\"]\n",
    "        colors = ['blue', 'green', 'red', 'purple']\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        width = 0.2  # the width of the bars\n",
    "        x = np.arange(len(bundle_df['num_patients'].unique()))  # the label locations\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "        for i, (method, color) in enumerate(zip(methods, colors)):\n",
    "            method_df = bundle_df[bundle_df['method'] == method]\n",
    "            data = [method_df[method_df['num_patients'] == patients][bundle_column].values \n",
    "                    for patients in bundle_df['num_patients'].unique()]\n",
    "            \n",
    "            # Ensure there is data for each num_patients\n",
    "            if any(len(d) > 0 for d in data):\n",
    "                positions = x + i * width  # Shift positions for each method\n",
    "                ax.boxplot(data, positions=positions, widths=0.15, patch_artist=True, \n",
    "                        boxprops=dict(facecolor=color, color=color),\n",
    "                        medianprops=dict(color='black'))\n",
    "                \n",
    "        ax.set_xlabel('Nombre de patients')\n",
    "        ax.set_ylabel('Valeurs')\n",
    "        ax.set_title(f'Boxplots pour le bundle: {bundle_column} avec {prct * 100}% de malades')\n",
    "        ax.set_xticks(x + width * (len(methods) - 1) / 2)\n",
    "        ax.set_xticklabels(bundle_df['num_patients'].unique())\n",
    "        ax.legend(handles=[plt.Line2D([0], [0], color=color, lw=4, label=f'Method: {method}') for method, color in zip(methods, colors)])\n",
    "        plt.savefig(os.path.join(directory, f'{bundle_column}_boxplot.png'))\n",
    "        plt.close()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "distances_df = pd.read_csv(os.path.join(MAINFOLDER, robust_method, \"dists_compilation.csv\"))\n",
    "add_nb_patients_and_diseased(distances_df)\n",
    "disease_ratios = [0.1, 0.3, 0.5, 0.7]\n",
    "for disease_ratio in disease_ratios:\n",
    "    plot_bundle(distances_df, disease_ratio, os.path.join(MAINFOLDER, robust_method, ANALYSISFOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATION BOX PLOT POUR MEA\n",
    "def plot_bundle(df, prct, directory):\n",
    "    \"\"\"\n",
    "    Crée un graphique pour chaque bundle dans le DataFrame donné.\n",
    "    L'axe des X représente le nombre de patients et l'axe des Y représente la moyenne de la colonne du bundle.\n",
    "    La courbe inclut une zone indiquant l'écart-type (std).\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Le DataFrame contenant les données.\n",
    "    bundle_column (str): Le nom de la colonne du bundle à utiliser pour le graphique.\n",
    "    \"\"\"\n",
    "    directory = os.path.join(directory, \"MEA_PLOTS\", str(prct))\n",
    "    df = df[df['disease_ratio'] == prct *100]\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    for bundle_column in df.columns:\n",
    "        if bundle_column in ['site','method','num_patients','disease_ratio','num_diseased']:\n",
    "            continue # Skip non-numeric columns\n",
    "        bundle_df = df[[bundle_column, 'site', 'method','num_patients','disease_ratio','num_diseased']].copy()\n",
    "        methods = [\"hc\", \"no_robust\", \"robust\", \"robust_rwp\"]\n",
    "        colors = ['blue', 'green', 'red', 'purple']\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        width = 0.2  # the width of the bars\n",
    "        x = np.arange(len(bundle_df['num_patients'].unique()))  # the label locations\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "        for i, (method, color) in enumerate(zip(methods, colors)):\n",
    "            method_df = bundle_df[bundle_df['method'] == method]\n",
    "            data = [method_df[method_df['num_patients'] == patients][bundle_column].values \n",
    "                    for patients in bundle_df['num_patients'].unique()]\n",
    "            \n",
    "            # Ensure there is data for each num_patients\n",
    "            if any(len(d) > 0 for d in data):\n",
    "                positions = x + i * width  # Shift positions for each method\n",
    "                ax.boxplot(data, positions=positions, widths=0.15, patch_artist=True, \n",
    "                        boxprops=dict(facecolor=color, color=color),\n",
    "                        medianprops=dict(color='black'))\n",
    "                \n",
    "        ax.set_xlabel('Nombre de patients')\n",
    "        ax.set_ylabel('Valeurs')\n",
    "        ax.set_title(f'Boxplots pour le bundle: {bundle_column} avec {prct * 100}% de malades')\n",
    "        ax.set_xticks(x + width * (len(methods) - 1) / 2)\n",
    "        ax.set_xticklabels(bundle_df['num_patients'].unique())\n",
    "        ax.legend(handles=[plt.Line2D([0], [0], color=color, lw=4, label=f'Method: {method}') for method, color in zip(methods, colors)])\n",
    "        plt.savefig(os.path.join(directory, f'{bundle_column}_boxplot.png'))\n",
    "        plt.close()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "mea_df = pd.read_csv(os.path.join(MAINFOLDER, robust_method, \"mea_compilation.csv\"))\n",
    "add_nb_patients_and_diseased(mea_df)\n",
    "disease_ratios = [0.1, 0.3, 0.5, 0.7]\n",
    "for disease_ratio in disease_ratios:\n",
    "    plot_bundle(mea_df, disease_ratio, os.path.join(MAINFOLDER, robust_method, ANALYSISFOLDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # TEST ADD BIAIS\n",
    "# # Split the data into training and testing sets\n",
    "# directory = os.path.join(MAINFOLDER, \"testBiais\")\n",
    "# os.makedirs(directory, exist_ok=True)\n",
    "# train_df, test_df = split_train_test(CAMCAN, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Generate biased data\n",
    "# # Save the original non-biased data to temporary files\n",
    "# temp_train_file_original = os.path.join(directory, \"temp_train_original.csv\")\n",
    "# temp_test_file_original = os.path.join(directory, \"temp_test_original.csv\")\n",
    "# train_df.to_csv(temp_train_file_original, index=False)\n",
    "# test_df.to_csv(temp_test_file_original, index=False)\n",
    "\n",
    "# # Generate biased data\n",
    "# sampled_df_biaied, test_df_biaised, gammas,deltas, ruffles= generate_biaised_data(train_df, test_df)\n",
    "\n",
    "# # Save the biased data to temporary files\n",
    "# temp_train_file = os.path.join(directory, \"temp_train_biased.csv\")\n",
    "# temp_test_file = os.path.join(directory, \"temp_test_biased.csv\")\n",
    "# sampled_df_biaied.to_csv(temp_train_file, index=False)\n",
    "# test_df_biaised.to_csv(temp_test_file, index=False)\n",
    "\n",
    "# # Run the combat_visualize_data script\n",
    "# outname_train = os.path.join(\"visualize_train\")\n",
    "# cmd = (\n",
    "#     \"scripts/combat_visualize_data.py\"\n",
    "#     + \" \"\n",
    "#     + temp_train_file_original\n",
    "#     + \" \"\n",
    "#     + temp_train_file\n",
    "#     + \" --out_dir \"\n",
    "#     + directory\n",
    "#     + \" --outname \"\n",
    "#     + outname_train\n",
    "#     + \" -f\"\n",
    "#     + \" --bundles all\"\n",
    "# )\n",
    "# subprocess.call(cmd, shell=True)\n",
    "\n",
    "# # Display gammas and deltas along with their mean and standard deviation\n",
    "# print(\"Gammas:\", gammas)\n",
    "# print(\"Deltas:\", deltas)\n",
    "# gammas = list(gammas.values())\n",
    "# deltas = list(deltas.values())\n",
    "# print(\"\\nGamma Statistics:\")\n",
    "# print(f\"Mean: {np.mean(gammas)}, Std: {np.std(gammas)}\")\n",
    "\n",
    "# print(\"\\nDelta Statistics:\")\n",
    "# print(f\"Mean: {np.mean(deltas)}, Std: {np.std(deltas)}\")\n",
    "# print(\"Ruffles:\", ruffles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST Powerpoint generation\n",
    "# d  = os.path.join(MAINFOLDER, robust_method, \"adni_100_Philips_3T\")\n",
    "# create_presentation(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST the sample_patients function with compilation data data\n",
    "# sampled_df = sample_patients(COMPILATION, num_patients=100, disease_ratio=0.5)\n",
    "# print(sampled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_metrics(\"ROBUST/IQR/50_30/0/\", \"50_patients_30_percent_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the dists_compilation and metrics_compilation CSV files\n",
    "# dists_compilation_path = os.path.join(directory, \"dists_compilation.csv\")\n",
    "# metrics_compilation_path = os.path.join(directory, \"metrics_compilation.csv\")\n",
    "\n",
    "# dists_compilation = pd.read_csv(dists_compilation_path)\n",
    "# metrics_compilation = pd.read_csv(metrics_compilation_path)\n",
    "\n",
    "# # Change the site column\n",
    "# dists_compilation['site'] = dists_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "# metrics_compilation['site'] = metrics_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "\n",
    "# # Display the means by site\n",
    "# dists_means_by_site = dists_compilation.groupby(['site','comparaison']).mean()\n",
    "# metrics_means_by_site = metrics_compilation.groupby('site').mean()\n",
    "\n",
    "# print(dists_means_by_site)\n",
    "# print(metrics_means_by_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FIX METRICS COMPILATION\n",
    "# directory = os.path.join(MAINFOLDER, robust_method)\n",
    "# df = pd.read_csv(os.path.join(directory, \"metrics_compilation.csv\"))\n",
    "\n",
    "# # Group by the site\n",
    "# grouped = df.groupby('site')\n",
    "\n",
    "# # Process each site\n",
    "# cleaned_dfs = []\n",
    "# for site, group in grouped:\n",
    "#     # Reset index for easier manipulation\n",
    "#     group = group.reset_index(drop=True)\n",
    "    \n",
    "#     # # The first row is the \"bundle row\" (new column names)\n",
    "#     # new_columns = group.iloc[0].values  # Extract column names from the first row\n",
    "#     # new_columns[-1] = 'site'\n",
    "#     # group = group.iloc[1:]  # Remove the first row\n",
    "    \n",
    "#     # # Assign new column names\n",
    "#     # group.columns = new_columns\n",
    "    \n",
    "#     # # Sort the columns alphabetically (excluding 'site')\n",
    "#     # sorted = group.sort_index(axis=1)\n",
    "#     # Add a new column 'nomm' with the value indicating the metric for each row\n",
    "#     metrics = ['tp', 'fp', 'tn', 'fn', 'precision', 'recall', 'taux_faux_positifs', 'f1_score']\n",
    "#     group['metric'] = metrics\n",
    "    \n",
    "#     # # Append the cleaned DataFrame for this site\n",
    "#     cleaned_dfs.append(group)\n",
    "\n",
    "# # Concatenate all cleaned DataFrames\n",
    "# final_df = pd.concat(cleaned_dfs, ignore_index=True)\n",
    "\n",
    "# # Save or display the result\n",
    "# final_df.to_csv(os.path.join(directory, \"metrics_compilation.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAL SITES\n",
    "# directory = os.path.join(MAINFOLDER, robust_method)\n",
    "# raw_directory = os.path.join(RAWFOLDER, site_group)\n",
    "# for filename in sorted(os.listdir(raw_directory)):\n",
    "#     f = os.path.join(raw_directory, filename)\n",
    "#     # checking if it is a file\n",
    "#     if os.path.isfile(f):\n",
    "#         analyse_site(f, robust_method, directory)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
