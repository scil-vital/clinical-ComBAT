{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS and UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")\n",
    "\n",
    "import os, math\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from scripts import combat_info\n",
    "from scripts import combat_quick_apply\n",
    "from scripts import combat_quick_QC\n",
    "from robust_evaluation_tools.robust_utils import get_site, robust_text, rwp_text, get_camcan_file, get_diseases, get_metrics, add_nb_patients_and_diseased, remove_covariates_effects_metrics\n",
    "from robust_evaluation_tools.robust_harmonization import fit, apply, visualize_harmonization, QC, compare_with_compilation, compare_with_compilation_SMAPE, compare_with_compilation_STD, create_presentation, compare_distances, compare_with_compilation_var\n",
    "from robust_evaluation_tools.synthectic_sites_generations import generate_sites\n",
    "from robust_evaluation_tools.robust_outlier_detection import z_score_detection, flag_sid\n",
    "from robust_evaluation_tools.robust_MLP import predict_malades_MLP\n",
    "\n",
    "MAINFOLDER = \"RESULTS/MAE_TEST\"\n",
    "SYNTHETIC_SITES = f\"{MAINFOLDER}/SYNTHETIC_SITES\"\n",
    "\n",
    "ANALYSIS_FOLDER = f\"{MAINFOLDER}/ANALYSIS\"\n",
    "\n",
    "robust_methods_for_analysis = [\"No\",\"raw\", \"IQR\",'MAD','MMS', 'VS', 'VS2', 'FLIP', 'Z_SCORE', \"Z_SCORE_IQR\", \"Z_SCORE_MAD\"]\n",
    "\n",
    "SMAPE_ONLY = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HARMONIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, directory, method, robust, rwp,hc, gt_train_file_name, gt_test_file_name):\n",
    "     \n",
    "    if method == 'robust':\n",
    "        dir =os.path.join(directory,robust)\n",
    "    else:\n",
    "        dir = os.path.join(directory,method)\n",
    "    print(f_train)\n",
    "    \n",
    "    if robust == 'raw':\n",
    "        output_filename_train = f_train\n",
    "        output_filename_test = f_test\n",
    "    else:\n",
    "        # Fit the model\n",
    "        output_model_filename = fit(f_train, ref_data_file, metric, harmonizartion_method, robust, rwp, dir, hc,)\n",
    "        # Apply the model\n",
    "        output_filename_train = apply(f_train, output_model_filename, metric, harmonizartion_method, robust, rwp, dir)\n",
    "        output_filename_test = apply(f_test, output_model_filename, metric, harmonizartion_method, robust, rwp, dir)\n",
    "    \n",
    "    # Visualize the harmonization\n",
    "    #visualize_harmonization(f_test, output_filename, ref_data_file, dir, bundles = '')\n",
    "    \n",
    "    std_mae_train = compare_with_compilation_STD(pd.read_csv(output_filename_train), pd.read_csv(gt_train_file_name))\n",
    "    std_mae_test = compare_with_compilation_STD(pd.read_csv(output_filename_test), pd.read_csv(gt_test_file_name))\n",
    "\n",
    "    if not SMAPE_ONLY:\n",
    "        smape_test = compare_with_compilation_SMAPE(pd.read_csv(output_filename_test), pd.read_csv(gt_test_file_name))\n",
    "        smape_train = compare_with_compilation_SMAPE(pd.read_csv(output_filename_train), pd.read_csv(gt_train_file_name))\n",
    "        \n",
    "        mae_test = compare_with_compilation(pd.read_csv(output_filename_test), pd.read_csv(gt_test_file_name))\n",
    "        maev_test = compare_with_compilation_var(pd.read_csv(output_filename_test), pd.read_csv(gt_test_file_name))\n",
    "\n",
    "        mae_train = compare_with_compilation(pd.read_csv(output_filename_train), pd.read_csv(gt_train_file_name))\n",
    "        maev_train = compare_with_compilation_var(pd.read_csv(output_filename_train), pd.read_csv(gt_train_file_name))\n",
    "    else:\n",
    "        mae_test = pd.DataFrame()\n",
    "        maev_test = pd.DataFrame()\n",
    "        mae_train = pd.DataFrame()\n",
    "        maev_train = pd.DataFrame()\n",
    "        smape_test = pd.DataFrame()\n",
    "        smape_train = pd.DataFrame()\n",
    "\n",
    "\n",
    "    mae_test['site'] = get_site(f_train)\n",
    "    mae_test['method'] = method\n",
    "    mae_test['robust_method'] = robust\n",
    "\n",
    "    maev_test['site'] = get_site(f_train)\n",
    "    maev_test['method'] = method\n",
    "    maev_test['robust_method'] = robust\n",
    "\n",
    "    mae_train['site'] = get_site(f_train)\n",
    "    mae_train['method'] = method\n",
    "    mae_train['robust_method'] = robust\n",
    "\n",
    "    maev_train['site'] = get_site(f_train)\n",
    "    maev_train['method'] = method\n",
    "    maev_train['robust_method'] = robust\n",
    "\n",
    "    smape_test['site'] = get_site(f_train)\n",
    "    smape_test['method'] = method\n",
    "    smape_test['robust_method'] = robust\n",
    "\n",
    "    smape_train['site'] = get_site(f_train)\n",
    "    smape_train['method'] = method\n",
    "    smape_train['robust_method'] = robust\n",
    "\n",
    "    std_mae_train['site'] = get_site(f_train)\n",
    "    std_mae_train['method'] = method\n",
    "    std_mae_train['robust_method'] = robust\n",
    "\n",
    "    std_mae_test['site'] = get_site(f_train)\n",
    "    std_mae_test['method'] = method\n",
    "    std_mae_test['robust_method'] = robust\n",
    "    \n",
    "    return mae_test, maev_test, mae_train, maev_train, smape_test, smape_train, std_mae_test, std_mae_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_site(f_train, f_test, robust_methods, directory, ref_data_file,\n",
    "                 metric, harmonizartion_method, gt_train_file_name, gt_test_file_name):\n",
    "    # Accumulateurs\n",
    "    df_mae_test_robust   = pd.DataFrame()\n",
    "    df_maev_test_robust  = pd.DataFrame()\n",
    "    df_mae_train_robust  = pd.DataFrame()\n",
    "    df_maev_train_robust = pd.DataFrame()\n",
    "    df_smape_test_robust = pd.DataFrame()\n",
    "    df_smape_train_robust = pd.DataFrame()\n",
    "    df_std_mae_test_robust = pd.DataFrame()\n",
    "    df_std_mae_train_robust = pd.DataFrame()\n",
    "\n",
    "    for robust in robust_methods:\n",
    "        if robust == \"raw\":\n",
    "            (mae_test, maev_test, mae_train, maev_train,\n",
    "             smape_test, smape_train, std_mae_test, std_mae_train) = harmonize(\n",
    "                 f_train, ref_data_file, metric, harmonizartion_method,\n",
    "                 f_test, directory, \"raw\", \"raw\", False, False, gt_train_file_name, gt_test_file_name)\n",
    "\n",
    "        elif robust == \"No\":\n",
    "            # hc‚Äëonly\n",
    "            (mae_test_hc, maev_test_hc, mae_train_hc, maev_train_hc,\n",
    "             smape_test_hc, smape_train_hc, std_mae_test_hc, std_mae_train_hc) = harmonize(\n",
    "                 f_train, ref_data_file, metric, harmonizartion_method,\n",
    "                 f_test, directory, \"hc\", \"No\", False, True, gt_train_file_name, gt_test_file_name)\n",
    "            # NoRobust\n",
    "            (mae_test_no, maev_test_no, mae_train_no, maev_train_no,\n",
    "             smape_test_no, smape_train_no, std_mae_test_no, std_mae_train_no) = harmonize(\n",
    "                 f_train, ref_data_file, metric, harmonizartion_method,\n",
    "                 f_test, directory, \"NoRobust\", \"No\", False, False, gt_train_file_name, gt_test_file_name)\n",
    "\n",
    "            mae_test   = pd.concat([mae_test_no,   mae_test_hc],   ignore_index=True)\n",
    "            maev_test  = pd.concat([maev_test_no,  maev_test_hc],  ignore_index=True)\n",
    "            mae_train  = pd.concat([mae_train_no,  mae_train_hc],  ignore_index=True)\n",
    "            maev_train = pd.concat([maev_train_no, maev_train_hc], ignore_index=True)\n",
    "            smape_test = pd.concat([smape_test_no, smape_test_hc], ignore_index=True)\n",
    "            smape_train = pd.concat([smape_train_no, smape_train_hc], ignore_index=True)\n",
    "            std_mae_test = pd.concat([std_mae_test_no, std_mae_test_hc], ignore_index=True)\n",
    "            std_mae_train = pd.concat([std_mae_train_no, std_mae_train_hc], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            (mae_test, maev_test, mae_train, maev_train,\n",
    "             smape_test, smape_train, std_mae_test, std_mae_train) = harmonize(\n",
    "                 f_train, ref_data_file, metric, harmonizartion_method,\n",
    "                 f_test, directory, \"robust\", robust, False, False, gt_train_file_name, gt_test_file_name)\n",
    "\n",
    "        # Empile tout\n",
    "        df_mae_test_robust   = pd.concat([df_mae_test_robust,   mae_test],   ignore_index=True)\n",
    "        df_maev_test_robust  = pd.concat([df_maev_test_robust,  maev_test],  ignore_index=True)\n",
    "        df_mae_train_robust  = pd.concat([df_mae_train_robust,  mae_train],  ignore_index=True)\n",
    "        df_maev_train_robust = pd.concat([df_maev_train_robust, maev_train], ignore_index=True)\n",
    "        df_smape_test_robust = pd.concat([df_smape_test_robust, smape_test], ignore_index=True)\n",
    "        df_smape_train_robust = pd.concat([df_smape_train_robust, smape_train], ignore_index=True)\n",
    "        df_std_mae_test_robust = pd.concat([df_std_mae_test_robust, std_mae_test], ignore_index=True)\n",
    "        df_std_mae_train_robust = pd.concat([df_std_mae_train_robust, std_mae_train], ignore_index=True)\n",
    "\n",
    "    return (df_mae_test_robust, df_maev_test_robust,\n",
    "            df_mae_train_robust, df_maev_train_robust,\n",
    "            df_smape_test_robust, df_smape_train_robust,\n",
    "            df_std_mae_test_robust, df_std_mae_train_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_analysis(disease, sample_size, disease_ratio, test_index,\n",
    "                     harmonization_method, SYNTHETIC_SITES_VERSION,\n",
    "                     metrics, robust_methods):\n",
    "    \n",
    "    # D√©finition des chemins\n",
    "    sizeDir = os.path.join(MAINFOLDER, f'PROCESS_{harmonization_method}', disease,\n",
    "                           f\"{sample_size}_{int(disease_ratio * 100)}\",\n",
    "                           f\"{test_index}\")\n",
    "    mae_test_file_path  = os.path.join(sizeDir, \"mae_compilation_test.csv\")\n",
    "    maev_test_file_path = os.path.join(sizeDir, \"maev_compilation_test.csv\")\n",
    "    mae_train_file_path = os.path.join(sizeDir, \"mae_compilation_train.csv\")\n",
    "    maev_train_file_path= os.path.join(sizeDir, \"maev_compilation_train.csv\")\n",
    "    smape_test_file_path = os.path.join(sizeDir, \"smape_compilation_test.csv\")\n",
    "    smape_train_file_path= os.path.join(sizeDir, \"smape_compilation_train.csv\")\n",
    "    std_mae_train_file_path = os.path.join(sizeDir, \"std_mae_compilation_train.csv\")\n",
    "    std_mae_test_file_path = os.path.join(sizeDir, \"std_mae_compilation_test.csv\")\n",
    "\n",
    "    # Chargement existant (ou vide)\n",
    "    def _load_if_exists(path):\n",
    "        return pd.read_csv(path) if os.path.isfile(path) else pd.DataFrame()\n",
    "\n",
    "    mae_compilation_test  = _load_if_exists(mae_test_file_path)\n",
    "    maev_compilation_test = _load_if_exists(maev_test_file_path)\n",
    "    mae_compilation_train = _load_if_exists(mae_train_file_path)\n",
    "    maev_compilation_train= _load_if_exists(maev_train_file_path)\n",
    "    smape_compilation_test = _load_if_exists(smape_test_file_path)\n",
    "    smape_compilation_train = _load_if_exists(smape_train_file_path)\n",
    "    std_mae_compilation_train = _load_if_exists(std_mae_train_file_path)\n",
    "    std_mae_compilation_test = _load_if_exists(std_mae_test_file_path)\n",
    "\n",
    "\n",
    "    robust_methods = [\"No\",\"raw\"] + robust_methods\n",
    "    # üí° V√©rification une seule fois au d√©but : est-ce que certaines m√©thodes sont d√©j√† pr√©sentes ?\n",
    "    if not std_mae_compilation_test.empty:\n",
    "        existing_methods = set(std_mae_compilation_test['robust_method'].unique())\n",
    "        missing_methods = [m for m in robust_methods if m not in existing_methods]\n",
    "\n",
    "        if not missing_methods:\n",
    "            print(f\"‚úîÔ∏è Toutes les m√©thodes d√©j√† trait√©es pour {disease} {sample_size}_{int(disease_ratio*100)} test_index {test_index}.\")\n",
    "            return (mae_test_file_path, maev_test_file_path,\n",
    "                    mae_train_file_path, maev_train_file_path,\n",
    "                    smape_test_file_path, smape_train_file_path,\n",
    "                    std_mae_test_file_path, std_mae_train_file_path\n",
    "                    )\n",
    "        \n",
    "        # ‚¨áÔ∏è on ne garde que les m√©thodes manquantes\n",
    "        robust_methods = missing_methods\n",
    "\n",
    "    # Si on est ici, c‚Äôest qu‚Äôil reste des m√©thodes √† faire\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, disease)\n",
    "    sizeDir_site   = os.path.join(directory_site, f\"{sample_size}_{int(disease_ratio * 100)}\")\n",
    "    tempDir_site   = os.path.join(sizeDir_site, f\"{test_index}\")\n",
    "\n",
    "    df_for_tags = pd.read_csv(os.path.join(tempDir_site, f\"train_{sample_size}_{int(disease_ratio * 100)}_{test_index}_all.csv\"))\n",
    "    df_for_tags = df_for_tags[~df_for_tags['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "    df_for_tags = remove_covariates_effects_metrics(df_for_tags)\n",
    "\n",
    "    z_score_sids = z_score_detection(df_for_tags)\n",
    "    \n",
    "    \n",
    "        # ‚Äî 1) Pr√©pare les pr√©dictions une seule fois ‚Äî\n",
    "    thresholds = [0.5, 0.6, 0.9, 0.95, 0.99]\n",
    "    models     = [\"mlp2_ALL\", \"mlp3_ALL\", \"mlp4_ALL\"]          # ajoute-en d‚Äôautres au besoin\n",
    "\n",
    "    preds = {f\"{m.upper()}_{str(int(t*100)).rstrip('0')}\": predict_malades_MLP(df_for_tags, m, threshold=t)\n",
    "         for m in models for t in thresholds}\n",
    "\n",
    "\n",
    "\n",
    "    for metric in metrics:\n",
    "        tempDir = os.path.join(sizeDir, metric)\n",
    "        os.makedirs(tempDir, exist_ok=True)\n",
    "\n",
    "        # Pr√©paration fichiers train/test\n",
    "        train_file_name = f\"train_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\"\n",
    "        test_file_name  = f\"test_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\"\n",
    "        gt_train_file_name = os.path.join(tempDir_site,f\"gt_train_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\")\n",
    "        gt_test_file_name  = os.path.join(tempDir_site,f\"gt_test_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\")\n",
    "\n",
    "        train_file = os.path.join(tempDir_site, train_file_name)\n",
    "        train_df = pd.read_csv(train_file)\n",
    "        train_df = train_df[~train_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "        train_df = train_df.drop(columns=['mean_no_cov', 'metric_bundle'])\n",
    "        train_df = flag_sid(train_df, z_score_sids, \"Z_SCORE\")\n",
    "        for label, sid_list in preds.items():\n",
    "            train_df = flag_sid(train_df, sid_list, label)\n",
    "\n",
    "\n",
    "        train_df[\"site\"] = disease + \"_\" + train_df[\"site\"]\n",
    "        new_train_file = os.path.join(tempDir, train_file_name)\n",
    "        train_df.to_csv(new_train_file, index=False)\n",
    "\n",
    "        test_file = os.path.join(tempDir_site, test_file_name)\n",
    "        test_df = pd.read_csv(test_file)\n",
    "        test_df = test_df[~test_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "        test_df = test_df.drop(columns=['mean_no_cov', 'metric_bundle'])\n",
    "        test_df[\"site\"] = train_df[\"site\"]\n",
    "        new_test_file = os.path.join(tempDir, test_file_name)\n",
    "        test_df.to_csv(new_test_file, index=False)\n",
    "\n",
    "        ref_data_file = get_camcan_file(metric)\n",
    "\n",
    "        # Lancement de l‚Äôanalyse pour toutes les m√©thodes manquantes\n",
    "        mae_analyze_test, maev_analyze_test, mae_analyze_train, maev_analyze_train, \\\n",
    "        smape_analyze_test, smape_analyze_train, std_mae_analyze_test, std_mae_analyze_train = analyse_site(\n",
    "            new_train_file, new_test_file, robust_methods, tempDir,\n",
    "            ref_data_file, metric, harmonization_method, gt_train_file_name, gt_test_file_name\n",
    "        )\n",
    "\n",
    "        # Ajout des infos\n",
    "        for df in [mae_analyze_test, maev_analyze_test, mae_analyze_train, maev_analyze_train, smape_analyze_test, smape_analyze_train, std_mae_analyze_test, std_mae_analyze_train]:\n",
    "            df['disease'] = disease\n",
    "            df['metric']  = metric\n",
    "\n",
    "        std_mae_compilation_test = pd.concat([std_mae_compilation_test, std_mae_analyze_test],\n",
    "                                                ignore_index=True).drop_duplicates()\n",
    "        std_mae_compilation_train = pd.concat([std_mae_compilation_train, std_mae_analyze_train],\n",
    "                                                ignore_index=True).drop_duplicates()\n",
    "        if not SMAPE_ONLY: \n",
    "            mae_compilation_test = pd.concat([mae_compilation_test, mae_analyze_test],\n",
    "                                            ignore_index=True).drop_duplicates()\n",
    "            maev_compilation_test = pd.concat([maev_compilation_test, maev_analyze_test],\n",
    "                                            ignore_index=True).drop_duplicates()\n",
    "            mae_compilation_train = pd.concat([mae_compilation_train, mae_analyze_train],\n",
    "                                            ignore_index=True).drop_duplicates()\n",
    "            maev_compilation_train = pd.concat([maev_compilation_train, maev_analyze_train],\n",
    "                                            ignore_index=True).drop_duplicates()\n",
    "            smape_compilation_test = pd.concat([smape_compilation_test, smape_analyze_test],\n",
    "                                            ignore_index=True).drop_duplicates()\n",
    "            smape_compilation_train = pd.concat([smape_compilation_train, smape_analyze_train],\n",
    "                                                ignore_index=True).drop_duplicates()\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "    # Sauvegarde finale\n",
    "    os.makedirs(sizeDir, exist_ok=True)\n",
    "    std_mae_compilation_test.to_csv(std_mae_test_file_path, index=False)\n",
    "    std_mae_compilation_train.to_csv(std_mae_train_file_path, index=False)\n",
    "    if not SMAPE_ONLY:\n",
    "        mae_compilation_test.to_csv(mae_test_file_path, index=False)\n",
    "        maev_compilation_test.to_csv(maev_test_file_path, index=False)\n",
    "        mae_compilation_train.to_csv(mae_train_file_path, index=False)\n",
    "        maev_compilation_train.to_csv(maev_train_file_path, index=False)\n",
    "        smape_compilation_test.to_csv(smape_test_file_path, index=False)\n",
    "        smape_compilation_train.to_csv(smape_train_file_path, index=False)\n",
    "        \n",
    "\n",
    "    return (mae_test_file_path, maev_test_file_path,\n",
    "            mae_train_file_path, maev_train_file_path,\n",
    "            smape_test_file_path, smape_train_file_path,\n",
    "            std_mae_test_file_path, std_mae_train_file_path)\n",
    "\n",
    "# Parallelized analysis method (excluding num_tests from parallelization)\n",
    "def analyse_method(sample_sizes, disease_ratios, num_tests, robust_methods,diseases, metrics, harmonization_method, SYNTHETIC_SITES_VERSION, n_jobs=-1):\n",
    "    # Generate all task combinations (excluding num_tests)\n",
    "    tasks = [\n",
    "        (disease, sample_size, disease_ratio, num_test, harmonization_method, SYNTHETIC_SITES_VERSION, metrics, robust_methods)\n",
    "        for disease in diseases\n",
    "        for sample_size in sample_sizes\n",
    "        for disease_ratio in disease_ratios\n",
    "        for num_test in range(num_tests)\n",
    "    ]\n",
    "\n",
    "    # Run all combinations in parallel and collect file paths\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(process_analysis)(*task) for task in tasks)\n",
    "\n",
    "    # Separate the list of tuples into four lists of file paths\n",
    "    mae_test_file_paths = [res[0] for res in results]\n",
    "    maev_test_file_paths = [res[1] for res in results]\n",
    "    mae_train_file_paths = [res[2] for res in results]\n",
    "    maev_train_file_paths = [res[3] for res in results]\n",
    "    smape_test_file_paths = [res[4] for res in results]\n",
    "    smape_train_file_paths = [res[5] for res in results]\n",
    "    std_mae_test_file_paths = [res[6] for res in results]\n",
    "    std_mae_train_file_paths = [res[7] for res in results]\n",
    "\n",
    "    # Concatenate all mae compilations for test datasets\n",
    "    mae_compilation_test_global = pd.concat(\n",
    "        [pd.read_csv(fpath) for fpath in mae_test_file_paths],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Concatenate all maev compilations for test datasets\n",
    "    maev_compilation_test_global = pd.concat(\n",
    "        [pd.read_csv(fpath) for fpath in maev_test_file_paths],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Concatenate all mae compilations for train datasets\n",
    "    mae_compilation_train_global = pd.concat(\n",
    "        [pd.read_csv(fpath) for fpath in mae_train_file_paths],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Concatenate all maev compilations for train datasets\n",
    "    maev_compilation_train_global = pd.concat(\n",
    "        [pd.read_csv(fpath) for fpath in maev_train_file_paths],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    smape_compilation_test_global = pd.concat(\n",
    "        [pd.read_csv(fpath) for fpath in smape_test_file_paths],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    smape_compilation_train_global = pd.concat(\n",
    "        [pd.read_csv(fpath) for fpath in smape_train_file_paths],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Final save of the four compiled DataFrames\n",
    "    directory = os.path.join(MAINFOLDER)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    mae_compilation_test_global.to_csv(os.path.join(directory, \"mae_compilation_test_global.csv\"), index=False)\n",
    "    maev_compilation_test_global.to_csv(os.path.join(directory, \"maev_compilation_test_global.csv\"), index=False)\n",
    "    mae_compilation_train_global.to_csv(os.path.join(directory, \"mae_compilation_train_global.csv\"), index=False)\n",
    "    maev_compilation_train_global.to_csv(os.path.join(directory, \"maev_compilation_train_global.csv\"), index=False)\n",
    "    smape_compilation_test_global.to_csv(os.path.join(directory, \"smape_compilation_test_global.csv\"), index=False)\n",
    "    smape_compilation_train_global.to_csv(os.path.join(directory, \"smape_compilation_train_global.csv\"), index=False)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sites_for_disease(disease, SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, sample_sizes, disease_ratios, num_tests, fixed_biais, n_jobs=-1):\n",
    "    # Load data for the disease\n",
    "    # data_path = os.path.join('DONNES_F','COMPILATIONS_AUG_3', f'{disease}_combination_all_metrics_CamCAN.csv.gz')\n",
    "    data_path = os.path.join('DONNES_MLP/evalutation_data_all_aug5.csv')\n",
    "    # Define site directory\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, disease)\n",
    "\n",
    "    # Generate synthetic sites\n",
    "    generate_sites(sample_sizes, disease_ratios, num_tests, directory_site, data_path, SYNTHETIC_SITES_VERSION, disease=disease,fixed_biais=fixed_biais, n_jobs=n_jobs )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonization_method= \"gmm\"\n",
    "\n",
    "SYNTHETIC_SITES_VERSION = \"v1\"\n",
    "\n",
    "metrics = get_metrics()\n",
    "#diseases = get_diseases(True)\n",
    "diseases = [\"ALL\"]\n",
    "robust_methods = [\n",
    "                \"MLP3_ALL_5\",\n",
    "                ]\n",
    "\n",
    "sample_sizes = [5,10,20,30,100,150]  # Diff√©rentes tailles d'√©chantillon\n",
    "sample_sizes = [30,100,150]  # Diff√©rentes tailles d'√©chantillon\n",
    "sample_sizes = [100]  # Diff√©rentes tailles d'√©chantillon\n",
    "disease_ratios = [0.03, 0.1, 0.3, 0.5, 0.7, 0.8]  # Diff√©rents pourcentages de malades\n",
    "num_tests = 20  # Nombre de tests √† effectuer pour chaque combinaison\n",
    "n_jobs_number=-1\n",
    "fixed_biais=True\n",
    "\n",
    "# for disease in diseases:\n",
    "#     generate_sites_for_disease(\n",
    "#         disease, SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, sample_sizes, disease_ratios, num_tests, fixed_biais, n_jobs_number\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/11/ad/train_100_3_11_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/0/ad/train_100_3_0_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/5/ad/train_100_3_5_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/17/ad/train_100_3_17_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/12/ad/train_100_3_12_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/3/ad/train_100_3_3_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_10/1/ad/train_100_10_1_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/6/ad/train_100_3_6_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/7/ad/train_100_3_7_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/2/ad/train_100_3_2_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/13/ad/train_100_3_13_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/10/ad/train_100_3_10_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_10/0/ad/train_100_10_0_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/4/ad/train_100_3_4_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/9/ad/train_100_3_9_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_10/2/ad/train_100_10_2_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/1/ad/train_100_3_1_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/14/ad/train_100_3_14_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/8/ad/train_100_3_8_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/18/ad/train_100_3_18_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/16/ad/train_100_3_16_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_10/3/ad/train_100_10_3_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/15/ad/train_100_3_15_ad.csv\n",
      "RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/19/ad/train_100_3_19_ad.csv\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_AST_LClusters unbalanced: mni_AST_R\n",
      "\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_CCMidClusters unbalanced: mni_CC_ForcepsMajor\n",
      "\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_F_L_RClusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_ICP_RClusters unbalanced: mni_AC\n",
      "\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_MdLF_RClusters unbalanced: mni_FPT_R\n",
      "\n",
      "Clusters unbalanced: mni_F_L_RClusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_ICP_LClusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_AST_R\n",
      "\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_OR_RClusters unbalanced: mni_CC\n",
      "\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_CCMidClusters unbalanced: mni_IFOF_L\n",
      "\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_MdLF_RClusters unbalanced: mni_OR_R\n",
      "\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_UF_RClusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_UF_L\n",
      "\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_ICP_LClusters unbalanced: mni_AF_R\n",
      "\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_AST_LClusters unbalanced: mni_CC\n",
      "\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_MCPClusters unbalanced: mni_AC\n",
      "\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_OPT_LClusters unbalanced: mni_FPT_L\n",
      "\n",
      "Clusters unbalanced: mni_F_L_RClusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_ILF_RClusters unbalanced: mni_ICP_R\n",
      "\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_IFOF_LClusters unbalanced: mni_MCP\n",
      "\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_STT_LClusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_AF_L\n",
      "\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_C_RClusters unbalanced: mni_OPT_L\n",
      "\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_OPT_RClusters unbalanced: mni_CCMid\n",
      "\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_OR_LClusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinorClusters unbalanced: mni_UF_L\n",
      "\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_PPT_LClusters unbalanced: mni_VOF_R\n",
      "\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_ICP_LClusters unbalanced: mni_AF_R\n",
      "\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_AST_LClusters unbalanced: mni_VOF_L\n",
      "\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_AST_LClusters unbalanced: mni_IFOF_L\n",
      "\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_ML_RClusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_UF_R\n",
      "\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_AF_RClusters unbalanced: mni_CC\n",
      "\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_OPT_LClusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_AST_RClusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_AF_R\n",
      "\n",
      "\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_F_L_RClusters unbalanced: mni_MCP\n",
      "\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_ICP_LClusters unbalanced: mni_CCMid\n",
      "\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_C_RClusters unbalanced: mni_FPT_L\n",
      "\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_CST_RClusters unbalanced: mni_AF_R\n",
      "\n",
      "Clusters unbalanced: mni_F_L_RClusters unbalanced: mni_FPT_R\n",
      "\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_AF_RClusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_ML_L\n",
      "\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_FPT_RClusters unbalanced: mni_C_R\n",
      "\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_IFOF_RClusters unbalanced: mni_SCP\n",
      "\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_FPT_LClusters unbalanced: mni_AF_L\n",
      "\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFAClusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_UF_L\n",
      "\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFAClusters unbalanced: mni_ICP_L\n",
      "\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_AST_LClusters unbalanced: mni_ICP_R\n",
      "\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_FPT_RClusters unbalanced: mni_CST_R\n",
      "\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_MCPClusters unbalanced: mni_MCP\n",
      "\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajorClusters unbalanced: mni_CC\n",
      "\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_C_LClusters unbalanced: mni_OR_R\n",
      "\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFAClusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_FPT_LClusters unbalanced: mni_MdLF_R\n",
      "\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_AF_RClusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_AF_R\n",
      "\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_OPT_LClusters unbalanced: mni_FPT_L\n",
      "\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_ILF_LClusters unbalanced: mni_UF_L\n",
      "\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_F_L_RClusters unbalanced: mni_AST_R\n",
      "\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_UF_RClusters unbalanced: mni_AST_L\n",
      "\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_MCPClusters unbalanced: mni_F_L_R\n",
      "\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_OR_LClusters unbalanced: mni_ILF_R\n",
      "\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_CCClusters unbalanced: mni_ML_L\n",
      "\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_ICP_RClusters unbalanced: mni_OR_R\n",
      "\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_PPT_LClusters unbalanced: mni_CC_ForcepsMajor\n",
      "\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_ICP_RClusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_ILF_LClusters unbalanced: mni_SLF_L\n",
      "\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_C_LClusters unbalanced: mni_CST_R\n",
      "\n",
      "Clusters unbalanced: mni_OR_LClusters unbalanced: mni_STT_R\n",
      "\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFAClusters unbalanced: mni_C_L\n",
      "\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_ICP_RClusters unbalanced: mni_F_L_R\n",
      "\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_AF_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_ACClusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_CC\n",
      "\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_AF_LClusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_OR_LClusters unbalanced: mni_VOF_L\n",
      "\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_AF_RClusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_CST_R\n",
      "\n",
      "Clusters unbalanced: mni_AST_LClusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_AST_RClusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_ML_R\n",
      "\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_PPT_RClusters unbalanced: mni_F_L_R\n",
      "\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_MdLF_LClusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_STT_RClusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_OPT_LClusters unbalanced: mni_IFOF_L\n",
      "\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_AC\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_AF_L\n",
      "Clusters unbalanced: mni_ML_L\n",
      "Clusters unbalanced: mni_OR_LClusters unbalanced: mni_AF_R\n",
      "\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_AST_L\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_AST_R\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_CC\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_CCMid\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_CC_ForcepsMajor\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_CC_ForcepsMinor\n",
      "Clusters unbalanced: mni_CST_L\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_CST_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_C_L\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_STT_R"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 278, in <module>\n",
      "    main()\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_fit.py\", line 271, in main\n",
      "    QC.fit(ref_data, mov_data, args.hc)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 543, in fit\n",
      "    mov_data_processed, details = self._legacy_preprocess(mov_data, training=True)\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 473, in _legacy_preprocess\n",
      "    best_feature, split_df, _, gmm_params = _fit_best_gmm_feature(\n",
      "  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/GmmCombatLegacy.py\", line 94, in _fit_best_gmm_feature\n",
      "    raise ValueError(\"No valid Gaussian mixture fits were produced.\")\n",
      "ValueError: No valid Gaussian mixture fits were produced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clusters unbalanced: mni_C_R\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_FPT_L\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_FPT_R\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_F_L_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_ICP_L\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_ICP_R\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_IFOF_L\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_IFOF_R\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_IIT_mask_skeletonFA\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_ILF_L\n",
      "Clusters unbalanced: mni_VOF_R\n",
      "Clusters unbalanced: mni_ILF_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_MCP\n",
      "Clusters unbalanced: mni_VOF_RClusters unbalanced: mni_ML_L\n",
      "\n",
      "Clusters unbalanced: mni_ML_R\n",
      "Clusters unbalanced: mni_MdLF_L\n",
      "Clusters unbalanced: mni_MdLF_R\n",
      "Clusters unbalanced: mni_OPT_L\n",
      "Clusters unbalanced: mni_OPT_R\n",
      "Clusters unbalanced: mni_OR_L\n",
      "Clusters unbalanced: mni_OR_R\n",
      "Clusters unbalanced: mni_PPT_L\n",
      "Clusters unbalanced: mni_PPT_R\n",
      "Clusters unbalanced: mni_SCP\n",
      "Clusters unbalanced: mni_SLF_L\n",
      "Clusters unbalanced: mni_SLF_R\n",
      "Clusters unbalanced: mni_STT_L\n",
      "Clusters unbalanced: mni_STT_R\n",
      "Clusters unbalanced: mni_UF_L\n",
      "Clusters unbalanced: mni_UF_R\n",
      "Clusters unbalanced: mni_VOF_L\n",
      "Clusters unbalanced: mni_VOF_R\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/5/ad/hc/ALL_100_patients_3_percent_5.ad.gmm2.NoRobust.NoRWP.model.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/tmp/ipykernel_136123/681707299.py\", line 105, in process_analysis\n  File \"/tmp/ipykernel_136123/334591928.py\", line 23, in analyse_site\n  File \"/tmp/ipykernel_136123/34391960.py\", line 16, in harmonize\n  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/robust_evaluation_tools/robust_harmonization.py\", line 87, in apply\n    combat_quick_apply.apply(mov_data_file, model_filename, output_filename)\n  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/scripts/combat_quick_apply.py\", line 84, in apply\n    QC = from_model_filename(model)\n  File \"/home/local/USHERBROOKE/davy3001/Documents/COMBAT/Jodoin/Combat_robust/clinical_combat/harmonization/__init__.py\", line 117, in from_model_filename\n    with open(model_filename) as f:\nFileNotFoundError: [Errno 2] No such file or directory: 'RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/5/ad/hc/ALL_100_patients_3_percent_5.ad.gmm2.NoRobust.NoRWP.model.csv'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m harmonization_method\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgmm2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43manalyse_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisease_ratios\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_tests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust_methods\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdiseases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mharmonization_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSYNTHETIC_SITES_VERSION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs_number\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 166\u001b[0m, in \u001b[0;36manalyse_method\u001b[0;34m(sample_sizes, disease_ratios, num_tests, robust_methods, diseases, metrics, harmonization_method, SYNTHETIC_SITES_VERSION, n_jobs)\u001b[0m\n\u001b[1;32m    157\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    158\u001b[0m     (disease, sample_size, disease_ratio, num_test, harmonization_method, SYNTHETIC_SITES_VERSION, metrics, robust_methods)\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m disease \u001b[38;5;129;01min\u001b[39;00m diseases\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m num_test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tests)\n\u001b[1;32m    163\u001b[0m ]\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Run all combinations in parallel and collect file paths\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_analysis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Separate the list of tuples into four lists of file paths\u001b[39;00m\n\u001b[1;32m    169\u001b[0m mae_test_file_paths \u001b[38;5;241m=\u001b[39m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/COMBAT/Jodoin/Combat_robust/.robust/lib/python3.10/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RESULTS/MAE_TEST/PROCESS_gmm2/ALL/100_3/5/ad/hc/ALL_100_patients_3_percent_5.ad.gmm2.NoRobust.NoRWP.model.csv'"
     ]
    }
   ],
   "source": [
    "harmonization_method= \"gmm2\"\n",
    "analyse_method(sample_sizes, disease_ratios, num_tests, robust_methods,diseases, metrics, harmonization_method, SYNTHETIC_SITES_VERSION, n_jobs=n_jobs_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mae_or_maev_compilations(mainfolder, diseases, sample_sizes, disease_ratios, num_tests, mae_or_maev='mae'):\n",
    "    tests, trains = [], []\n",
    "    for d in diseases:\n",
    "        for s in sample_sizes:\n",
    "            for r in disease_ratios:\n",
    "                for i in range(num_tests):\n",
    "                    base = os.path.join(mainfolder, f'PROCESS_{harmonization_method}', d, f\"{s}_{int(r*100)}\", str(i))\n",
    "                    test_path  = os.path.join(base, f\"{mae_or_maev}_compilation_test.csv\")\n",
    "                    train_path = os.path.join(base, f\"{mae_or_maev}_compilation_train.csv\")\n",
    "                    if os.path.isfile(test_path):\n",
    "                        tests.append(pd.read_csv(test_path))\n",
    "                    if os.path.isfile(train_path):\n",
    "                        trains.append(pd.read_csv(train_path))\n",
    "    df_test  = pd.concat(tests,  ignore_index=True) if tests  else pd.DataFrame()\n",
    "    df_train = pd.concat(trains, ignore_index=True) if trains else pd.DataFrame()\n",
    "    return df_test, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compilation(mae_or_maev: str,\n",
    "                     split: str,\n",
    "                     *,\n",
    "                     mainfolder: str,\n",
    "                     diseases: list[str],\n",
    "                     sample_sizes: list[int],\n",
    "                     disease_ratios: list[int],\n",
    "                     num_tests: int) -> pd.DataFrame:\n",
    "    if mae_or_maev not in {\"mae\", \"maev\"}:\n",
    "        raise ValueError(\"mae_or_maev doit √™tre 'mae' ou 'maev'\")\n",
    "    if split not in {\"test\", \"train\"}:\n",
    "        raise ValueError(\"split doit √™tre 'test' ou 'train'\")\n",
    "\n",
    "    df_test, df_train = load_mae_or_maev_compilations(\n",
    "        mainfolder,\n",
    "        diseases,\n",
    "        sample_sizes,\n",
    "        disease_ratios,\n",
    "        num_tests,\n",
    "        mae_or_maev=mae_or_maev\n",
    "    )\n",
    "    return df_test if split == \"test\" else df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_compilation_train_all = load_compilation(\"mae\", \"train\",\n",
    "                      mainfolder=MAINFOLDER,\n",
    "                      diseases=diseases,\n",
    "                      sample_sizes=sample_sizes,\n",
    "                      disease_ratios=disease_ratios,\n",
    "                      num_tests=num_tests)\n",
    "mae_compilation_test_all = load_compilation(\"mae\", \"test\",\n",
    "                      mainfolder=MAINFOLDER,\n",
    "                      diseases=diseases,\n",
    "                      sample_sizes=sample_sizes,\n",
    "                      disease_ratios=disease_ratios,\n",
    "                      num_tests=num_tests)\n",
    "maev_compilation_train_all = load_compilation(\"maev\", \"train\",\n",
    "                      mainfolder=MAINFOLDER,\n",
    "                      diseases=diseases,\n",
    "                      sample_sizes=sample_sizes,\n",
    "                      disease_ratios=disease_ratios,\n",
    "                      num_tests=num_tests)\n",
    "maev_compilation_test_all = load_compilation(\"maev\", \"test\",\n",
    "                      mainfolder=MAINFOLDER,\n",
    "                      diseases=diseases,\n",
    "                      sample_sizes=sample_sizes,\n",
    "                      disease_ratios=disease_ratios,\n",
    "                      num_tests=num_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean std\n",
    "\n",
    "def plot_mea_mean_std(df, sample_size, disease, metric, directory, dataset_type):\n",
    "    # Dossier de sortie\n",
    "    directory = os.path.join(directory, \"MAE_PLOTS_MEAN\", disease, metric,\n",
    "                             str(sample_size), dataset_type, \"ALL_BUNDLES\")\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Filtre\n",
    "    df_filtered = df[\n",
    "        (df['num_patients'] == sample_size) &\n",
    "        (df['disease'] == disease) &\n",
    "        (df['metric'] == metric)\n",
    "    ].copy()\n",
    "\n",
    "    # M√©thodes robustes\n",
    "    robust_methods = [m for m in df_filtered['robust_method'].dropna().unique()\n",
    "                      if m not in [\"No\", \"raw\"]]\n",
    "\n",
    "    base_methods = [\"hc\", \"NoRobust\"]\n",
    "    robust_base_methods = [\"robust\"]\n",
    "    methods = base_methods + [f\"{rb}_{rm}\" for rb in robust_base_methods\n",
    "                              for rm in robust_methods]\n",
    "\n",
    "    # Couleurs\n",
    "    method_colors = {\"raw\": \"grey\", \"hc\": \"green\", \"NoRobust\": \"red\"}\n",
    "    palette = sns.color_palette(\"viridis\", len(robust_methods))\n",
    "    for i, rm in enumerate(robust_methods):\n",
    "        method_colors[f\"robust_{rm}\"] = palette[i]\n",
    "\n",
    "    # Colonnes bundle -> long format\n",
    "    ignored = ['site', 'method', 'num_patients', 'disease_ratio',\n",
    "               'num_diseased', 'metric', 'disease', 'robust_method']\n",
    "    bundle_cols = [c for c in df_filtered.columns if c not in ignored]\n",
    "\n",
    "    df_long = df_filtered.melt(\n",
    "        id_vars=ignored,\n",
    "        value_vars=bundle_cols,\n",
    "        var_name='bundle',\n",
    "        value_name='mae'\n",
    "    )\n",
    "\n",
    "    unique_ratios = sorted(df_long['disease_ratio'].unique())\n",
    "    x = np.arange(len(unique_ratios))\n",
    "    group_width = 0.8\n",
    "    n_methods = len(methods)\n",
    "    offset = group_width / n_methods\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    for i_m, method in enumerate(methods):\n",
    "        if \"_\" in method and method != \"no_robust\":\n",
    "            method_base, robust_type = method.split(\"_\", 1)\n",
    "            sub = df_long[\n",
    "                (df_long['method'] == method_base) &\n",
    "                (df_long['robust_method'] == robust_type)\n",
    "            ]\n",
    "        else:\n",
    "            sub = df_long[df_long['method'] == method]\n",
    "\n",
    "        means = []\n",
    "        stds = []\n",
    "        for ratio in unique_ratios:\n",
    "            vals = sub[sub['disease_ratio'] == ratio]['mae'].dropna()\n",
    "            means.append(vals.mean())\n",
    "            stds.append(vals.std())\n",
    "\n",
    "        positions = x - group_width / 2 + (i_m + 0.5) * offset\n",
    "        color = method_colors.get(method, \"black\")\n",
    "\n",
    "        ax.errorbar(\n",
    "            positions,\n",
    "            means,\n",
    "            yerr=stds,\n",
    "            fmt='o',\n",
    "            capsize=4,\n",
    "            markersize=5,\n",
    "            color=color,\n",
    "            ecolor=color,\n",
    "            label=method\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel('Prct de patients malades')\n",
    "    ax.set_ylabel('MAE')\n",
    "    ax.set_title(\n",
    "        f\"MAE moyenne ¬± √©cart‚Äëtype, tous bundles confondus\\n\"\n",
    "        f\"Maladie‚ÄØ: {disease}   |   Metric‚ÄØ: {metric}\\n\"\n",
    "        f\"Nb patients‚ÄØ: {sample_size}   |   Dataset‚ÄØ: {dataset_type}\"\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(unique_ratios)\n",
    "\n",
    "    # L√©gende sans doublons\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(),\n",
    "              loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(directory, 'all_bundles_mean_std.png'),\n",
    "                bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Touts les bundles confondu\n",
    "\n",
    "def plot_mea_all_bundles(df, sample_size, disease, metric, directory, dataset_type):\n",
    "    # Dossier de sortie\n",
    "    directory = os.path.join(directory, \"MAE_PLOTS\", disease, metric,\n",
    "                             str(sample_size), dataset_type, \"ALL_BUNDLES\")\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Filtre de base\n",
    "    df_filtered = df[\n",
    "        (df['num_patients'] == sample_size) &\n",
    "        (df['disease'] == disease) &\n",
    "        (df['metric'] == metric)\n",
    "    ].copy()\n",
    "\n",
    "    # M√©thodes robustes disponibles\n",
    "    robust_methods = [m for m in df_filtered['robust_method'].dropna().unique()\n",
    "                      if m not in [\"No\", \"raw\"]]\n",
    "\n",
    "    base_methods = [\"hc\", \"NoRobust\"]\n",
    "    robust_base_methods = [\"robust\"]\n",
    "    methods = base_methods + [f\"{rb}_{rm}\" for rb in robust_base_methods\n",
    "                              for rm in robust_methods]\n",
    "\n",
    "    # Couleurs\n",
    "    method_colors = {\"raw\": \"grey\", \"hc\": \"green\", \"NoRobust\": \"red\"}\n",
    "    robust_palette = sns.color_palette(\"viridis\", len(robust_methods))\n",
    "    for i, rm in enumerate(robust_methods):\n",
    "        method_colors[f\"robust_{rm}\"] = robust_palette[i]\n",
    "\n",
    "    # Colonnes non‚Äëbundle\n",
    "    ignored = ['site', 'method', 'num_patients', 'disease_ratio',\n",
    "               'num_diseased', 'metric', 'disease', 'robust_method']\n",
    "    bundle_cols = [c for c in df_filtered.columns if c not in ignored]\n",
    "\n",
    "    # On met tous les bundles ensemble dans une seule colonne ¬´ mae ¬ª\n",
    "    df_long = df_filtered.melt(\n",
    "        id_vars=ignored,\n",
    "        value_vars=bundle_cols,\n",
    "        var_name='bundle',\n",
    "        value_name='mae'\n",
    "    )\n",
    "\n",
    "    unique_ratios = sorted(df_long['disease_ratio'].unique())\n",
    "    x = np.arange(len(unique_ratios))\n",
    "    group_width = 0.8\n",
    "    n_methods = len(methods)\n",
    "    box_width = group_width / n_methods\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    for i_m, method in enumerate(methods):\n",
    "        if \"_\" in method and method != \"no_robust\":\n",
    "            method_base, robust_type = method.split(\"_\", 1)\n",
    "            method_df = df_long[\n",
    "                (df_long['method'] == method_base) &\n",
    "                (df_long['robust_method'] == robust_type)\n",
    "            ]\n",
    "        else:\n",
    "            method_df = df_long[df_long['method'] == method]\n",
    "\n",
    "        data = [\n",
    "            method_df[method_df['disease_ratio'] == ratio]['mae'].dropna().values\n",
    "            for ratio in unique_ratios\n",
    "        ]\n",
    "\n",
    "        positions = x - group_width / 2 + (i_m + 0.5) * box_width\n",
    "        color = method_colors.get(method, \"black\")\n",
    "\n",
    "        if any(len(d) > 0 for d in data):\n",
    "            ax.boxplot(\n",
    "                data,\n",
    "                positions=positions,\n",
    "                widths=box_width * 0.8,\n",
    "                patch_artist=True,\n",
    "                boxprops=dict(facecolor=color, color=color),\n",
    "                medianprops=dict(color='black')\n",
    "            )\n",
    "\n",
    "    ax.set_xlabel('Prct de patients malades')\n",
    "    ax.set_ylabel('MAE')\n",
    "    ax.set_title(\n",
    "        f\"MAE de l‚Äôharmonisation, tous bundles confondus\\n\"\n",
    "        f\"Maladie‚ÄØ: {disease}   |   Metric‚ÄØ: {metric}\\n\"\n",
    "        f\"Nb patients‚ÄØ: {sample_size}   |   Dataset‚ÄØ: {dataset_type}\"\n",
    "    )\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(unique_ratios)\n",
    "\n",
    "    legend_handles = [\n",
    "        plt.Line2D([0], [0], color=method_colors[m], lw=3, label=f'{m}')\n",
    "        for m in methods\n",
    "    ]\n",
    "    ax.legend(handles=legend_handles, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(directory, 'all_bundles_boxplot.png'),\n",
    "                bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mea(df, sample_size, disease, metric, directory, dataset_type):\n",
    "    directory = os.path.join(directory, \"MAE_PLOTS\", disease, metric, str(sample_size), dataset_type)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    df_filtered = df[\n",
    "        (df['num_patients'] == sample_size) & \n",
    "        (df['disease'] == disease) & \n",
    "        (df['metric'] == metric)\n",
    "    ]\n",
    "\n",
    "    # M√©thodes de base + m√©thodes robustes\n",
    "    robust_methods = [m for m in df_filtered['robust_method'].dropna().unique() if m not in [\"No\", \"raw\"]]\n",
    "\n",
    "\n",
    "    #base_methods = [\"raw\", \"hc\", \"no_robust\"]\n",
    "    base_methods = [\"hc\", \"NoRobust\"]\n",
    "    #robust_base_methods = [\"robust\", \"robust_rwp\"]\n",
    "    robust_base_methods = [\"robust\"]\n",
    "    methods = base_methods + [f\"{rb}_{rm}\" for rb in robust_base_methods for rm in robust_methods]\n",
    "    \n",
    "    # Couleurs\n",
    "    method_colors = {\n",
    "        \"raw\": \"grey\",\n",
    "        \"hc\": \"green\",\n",
    "        \"NoRobust\": \"red\"\n",
    "    }\n",
    "    robust_palette = sns.color_palette(\"viridis\", len(robust_methods))\n",
    "    robust_rwp_palette = sns.color_palette(\"magma\", len(robust_methods))\n",
    "    for i, rm in enumerate(robust_methods):\n",
    "        method_colors[f\"robust_{rm}\"] = robust_palette[i]\n",
    "        method_colors[f\"robust_rwp_{rm}\"] = robust_rwp_palette[i]\n",
    "\n",
    "    # Boucle sur les \"bundles\"\n",
    "    for bundle_column in df_filtered.columns:\n",
    "        # On ignore les colonnes non-num√©riques\n",
    "        if bundle_column in ['site', 'method', 'num_patients', 'disease_ratio',\n",
    "                             'num_diseased', 'metric', 'disease', 'robust_method']:\n",
    "            continue\n",
    "\n",
    "        bundle_df = df_filtered[[bundle_column, 'site', 'method', 'num_patients',\n",
    "                                 'disease_ratio', 'num_diseased', 'robust_method']].copy()\n",
    "        unique_ratios = sorted(bundle_df['disease_ratio'].unique())  # Tri√© pour √™tre s√ªr de l'ordre\n",
    "\n",
    "        # *** ICI on param√®tre la figure + le positionnement ***\n",
    "        fig, ax = plt.subplots(figsize=(14, 7))  # Ajuster au besoin\n",
    "\n",
    "        # Abscisses pour chaque ratio\n",
    "        x = np.arange(len(unique_ratios))\n",
    "        \n",
    "        # Largeur totale allou√©e pour le ¬´‚ÄØgroupe‚ÄØ¬ª de m√©thodes √† chaque ratio\n",
    "        group_width = 0.8  \n",
    "        # On r√©partit cette largeur entre toutes les m√©thodes\n",
    "        n_methods = len(methods)\n",
    "        box_width = group_width / n_methods\n",
    "\n",
    "        # Trac√© des boxplots pour chaque m√©thode\n",
    "        for i_m, method in enumerate(methods):\n",
    "            if \"_\" in method and method != \"no_robust\":\n",
    "                method_base, robust_type = method.split(\"_\", 1)\n",
    "                method_df = bundle_df[\n",
    "                    (bundle_df['method'] == method_base) & \n",
    "                    (bundle_df['robust_method'] == robust_type)\n",
    "                ]\n",
    "            else:\n",
    "                method_df = bundle_df[bundle_df['method'] == method]\n",
    "\n",
    "            # On pr√©pare la liste de valeurs par ratio\n",
    "            data = [\n",
    "                method_df[method_df['disease_ratio'] == ratio][bundle_column].values \n",
    "                for ratio in unique_ratios\n",
    "            ]\n",
    "            data = [[x for x in row if not (isinstance(x, float) and math.isnan(x))] for row in data]\n",
    "\n",
    "            # Positions: on centre autour de chaque x\n",
    "            # Exemple: x - group_width/2 + (i_m+0.5)*box_width\n",
    "            positions = x - group_width/2 + (i_m + 0.5)*box_width\n",
    "\n",
    "            color = method_colors.get(method, \"black\")\n",
    "            \n",
    "            # S‚Äôil y a au moins un point de donn√©es\n",
    "            if any(len(d) > 0 for d in data):\n",
    "                ax.boxplot(\n",
    "                    data,\n",
    "                    positions=positions,\n",
    "                    widths=box_width * 0.8,  # L√©g√®rement plus petit que box_width\n",
    "                    patch_artist=True,\n",
    "                    boxprops=dict(facecolor=color, color=color),\n",
    "                    medianprops=dict(color='black')\n",
    "                )\n",
    "\n",
    "        ax.set_xlabel('Prct de patients malades')\n",
    "        ax.set_ylabel('MAE')\n",
    "        ax.set_title(\n",
    "            f\"MAE de l'harmonization selon le pourcentage de patients malades\\n\"\n",
    "            f\"Maladie: {disease}  |  Metric: {metric}  |  Bundle: {bundle_column}\\n\"\n",
    "            f\"Nb patient total: {sample_size} Context: {dataset_type}\"\n",
    "        )\n",
    "\n",
    "        # On place les ticks au milieu de chaque groupe (i.e. sur x)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(unique_ratios)\n",
    "\n",
    "        # L√©gende manuelle\n",
    "        legend_handles = [\n",
    "            plt.Line2D([0], [0], color=method_colors[m], lw=3, label=f'Method: {m}')\n",
    "            for m in methods\n",
    "        ]\n",
    "        ax.legend(handles=legend_handles, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(directory, f'{bundle_column}_boxplot.png'), bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_meav(df, sample_size, disease, metric, directory, dataset_type):\n",
    "    directory = os.path.join(directory, \"MAEV_PLOTS\", disease, metric, str(sample_size), dataset_type)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    df_filtered = df[\n",
    "        (df['num_patients'] == sample_size) & \n",
    "        (df['disease'] == disease) & \n",
    "        (df['metric'] == metric)\n",
    "    ]\n",
    "\n",
    "    # M√©thodes de base + m√©thodes robustes\n",
    "    robust_methods = [m for m in df_filtered['robust_method'].dropna().unique() if m not in [\"No\", \"raw\"]]\n",
    "\n",
    "    #base_methods = [\"raw\", \"hc\", \"no_robust\"]\n",
    "    base_methods = [\"hc\", \"NoRobust\"]\n",
    "    #robust_base_methods = [\"robust\", \"robust_rwp\"]\n",
    "    robust_base_methods = [\"robust\"]\n",
    "    methods = base_methods + [f\"{rb}_{rm}\" for rb in robust_base_methods for rm in robust_methods]\n",
    "    \n",
    "    # Couleurs\n",
    "    method_colors = {\n",
    "        \"raw\": \"grey\",\n",
    "        \"hc\": \"green\",\n",
    "        \"NoRobust\": \"red\"\n",
    "    }\n",
    "    robust_palette = sns.color_palette(\"viridis\", len(robust_methods))\n",
    "    robust_rwp_palette = sns.color_palette(\"magma\", len(robust_methods))\n",
    "    for i, rm in enumerate(robust_methods):\n",
    "        method_colors[f\"robust_{rm}\"] = robust_palette[i]\n",
    "        method_colors[f\"robust_rwp_{rm}\"] = robust_rwp_palette[i]\n",
    "\n",
    "    # Boucle sur les \"bundles\"\n",
    "    for bundle_column in df_filtered.columns:\n",
    "        # On ignore les colonnes non-num√©riques\n",
    "        if bundle_column in ['site', 'method', 'num_patients', 'disease_ratio',\n",
    "                             'num_diseased', 'metric', 'disease', 'robust_method']:\n",
    "            continue\n",
    "\n",
    "        bundle_df = df_filtered[[bundle_column, 'site', 'method', 'num_patients',\n",
    "                                 'disease_ratio', 'num_diseased', 'robust_method']].copy()\n",
    "        unique_ratios = sorted(bundle_df['disease_ratio'].unique())  # Tri√© pour √™tre s√ªr de l'ordre\n",
    "\n",
    "        # *** ICI on param√®tre la figure + le positionnement ***\n",
    "        fig, ax = plt.subplots(figsize=(14, 7))  # Ajuster au besoin\n",
    "\n",
    "        # Abscisses pour chaque ratio\n",
    "        x = np.arange(len(unique_ratios))\n",
    "        \n",
    "        # Largeur totale allou√©e pour le ¬´‚ÄØgroupe‚ÄØ¬ª de m√©thodes √† chaque ratio\n",
    "        group_width = 0.8  \n",
    "        # On r√©partit cette largeur entre toutes les m√©thodes\n",
    "        n_methods = len(methods)\n",
    "        box_width = group_width / n_methods\n",
    "\n",
    "        # Trac√© des boxplots pour chaque m√©thode\n",
    "        for i_m, method in enumerate(methods):\n",
    "            if \"_\" in method and method != \"no_robust\":\n",
    "                method_base, robust_type = method.rsplit(\"_\", 1)\n",
    "                method_df = bundle_df[\n",
    "                    (bundle_df['method'] == method_base) & \n",
    "                    (bundle_df['robust_method'] == robust_type)\n",
    "                ]\n",
    "            else:\n",
    "                method_df = bundle_df[bundle_df['method'] == method]\n",
    "\n",
    "            # On pr√©pare la liste de valeurs par ratio\n",
    "            data = [\n",
    "                method_df[method_df['disease_ratio'] == ratio][bundle_column].values \n",
    "                for ratio in unique_ratios\n",
    "            ]\n",
    "\n",
    "            # Positions: on centre autour de chaque x\n",
    "            # Exemple: x - group_width/2 + (i_m+0.5)*box_width\n",
    "            positions = x - group_width/2 + (i_m + 0.5)*box_width\n",
    "\n",
    "            color = method_colors.get(method, \"black\")\n",
    "            \n",
    "            # S‚Äôil y a au moins un point de donn√©es\n",
    "            if any(len(d) > 0 for d in data):\n",
    "                ax.boxplot(\n",
    "                    data,\n",
    "                    positions=positions,\n",
    "                    widths=box_width * 0.8,  # L√©g√®rement plus petit que box_width\n",
    "                    patch_artist=True,\n",
    "                    boxprops=dict(facecolor=color, color=color),\n",
    "                    medianprops=dict(color='black')\n",
    "                )\n",
    "\n",
    "        ax.set_xlabel('Prct de patients malades')\n",
    "        ax.set_ylabel('MAEV')\n",
    "        ax.set_title(\n",
    "            f\"MAEV de l'harmonization selon le pourcentage de patients malades\\n\"\n",
    "            f\"Maladie: {disease}  |  Metric: {metric}  |  Bundle: {bundle_column}\\n\"\n",
    "            f\"Nb patient total: {sample_size} Context: {dataset_type}\"\n",
    "        )\n",
    "\n",
    "        # On place les ticks au milieu de chaque groupe (i.e. sur x)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(unique_ratios)\n",
    "\n",
    "        # L√©gende manuelle\n",
    "        legend_handles = [\n",
    "            plt.Line2D([0], [0], color=method_colors[m], lw=3, label=f'Method: {m}')\n",
    "            for m in methods\n",
    "        ]\n",
    "        ax.legend(handles=legend_handles, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(directory, f'{bundle_column}_boxplot.png'), bbox_inches=\"tight\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS EXEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXEC DES PLOTS DE MAE\n",
    "\n",
    "datasets = {\n",
    "    \"train\": mae_compilation_train_all,\n",
    "    \"test\":  mae_compilation_test_all\n",
    "}\n",
    "\n",
    "for dataset_type, mae_df in datasets.items():\n",
    "    add_nb_patients_and_diseased(mae_df)\n",
    "\n",
    "    tasks = [\n",
    "        (mae_df, sample_size, disease, metric, ANALYSIS_FOLDER, dataset_type)\n",
    "        for disease in diseases\n",
    "        for sample_size in sample_sizes\n",
    "        for metric in metrics\n",
    "    ]\n",
    "\n",
    "    Parallel(n_jobs=-1)(\n",
    "        delayed(plot_mea_all_bundles)(*task) for task in tasks\n",
    "    )\n",
    "\n",
    "    # Parallel(n_jobs=-1)(\n",
    "    #     delayed(plot_mea_mean_std)(*task) for task in tasks\n",
    "    # )\n",
    "\n",
    "    #     # Run all tasks in parallel\n",
    "    # Parallel(n_jobs=-1)(\n",
    "    #     delayed(plot_mea)(*task) for task in tasks\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXEC DES PLOTS DE MAEV\n",
    "datasets = {\n",
    "    \"train\": maev_compilation_train_all,\n",
    "    \"test\": maev_compilation_test_all\n",
    "}\n",
    "# Process each dataset (train and test) separately\n",
    "for dataset_type, maev_df in datasets.items():\n",
    "    add_nb_patients_and_diseased(maev_df)\n",
    "\n",
    "    # Generate all task combinations\n",
    "    tasks = [\n",
    "        (maev_df, sample_size, disease, metric, ANALYSIS_FOLDER, dataset_type)\n",
    "        for disease in diseases\n",
    "        for sample_size in sample_sizes\n",
    "        for metric in metrics\n",
    "    ]\n",
    "\n",
    "    # # Run all tasks in parallel\n",
    "    # Parallel(n_jobs=-1)(\n",
    "    #     delayed(plot_meav)(*task) for task in tasks\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(ANALYSIS_FOLDER, 'DIFF'), exist_ok=True)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1. Charger le CSV\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "df = mae_compilation_train_all\n",
    "df = df[df[\"method\"] != \"robust_rwp\"]\n",
    "df = df[df[\"method\"] != \"raw\"]\n",
    "\n",
    "meta_cols   = [\"site\", \"method\", \"robust_method\", \"disease\", \"metric\"]\n",
    "bundle_cols = [c for c in df.columns if c not in meta_cols]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 2. Pr√©parer la baseline (NoRobust / No)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "baseline_key  = (df[\"method\"] == \"NoRobust\") & (df[\"robust_method\"] == \"No\")\n",
    "baseline_df   = df[baseline_key].copy()\n",
    "\n",
    "# On renomme les colonnes bundle ‚Üí bundle_base pour pouvoir merger\n",
    "base_rename = {b: f\"{b}_base\" for b in bundle_cols}\n",
    "baseline_df  = baseline_df[[\"disease\", \"site\", \"metric\"] + bundle_cols].rename(columns=base_rename)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 3. Fusionner pour avoir, sur chaque ligne, les valeurs baseline\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "df = df.merge(baseline_df, on=[\"disease\", \"site\", \"metric\"], how=\"left\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 4. Diff√©rence bundle-par-bundle  (robust ‚àí baseline)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "diff_cols = []\n",
    "for b in bundle_cols:\n",
    "    diff_col = f\"{b}_diff\"\n",
    "    df[diff_col] = df[b] - df[f\"{b}_base\"]\n",
    "    diff_cols.append(diff_col)\n",
    "\n",
    "# Moyenne des diff√©rences sur l‚Äôensemble des bundles\n",
    "df[\"diff_mean\"] = df[diff_cols].mean(axis=1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 5. √âtiquettes de m√©thode pour le tableau final\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def label_row(r):\n",
    "    if (r[\"method\"] == \"hc\") and (r[\"robust_method\"] == \"No\"):\n",
    "        return \"hc\"\n",
    "    return r[\"robust_method\"]          # MMS, raw, etc.\n",
    "\n",
    "df[\"method_label\"] = df.apply(label_row, axis=1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 6. Agr√©gation finale  (moyenne des diff_mean)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "group_cols = [\"disease\", \"site\", \"metric\", \"method_label\"]\n",
    "agg = df.groupby(group_cols)[\"diff_mean\"].mean()\n",
    "\n",
    "# Pivot ‚Üí colonnes = method_label\n",
    "table = agg.unstack(\"method_label\")\n",
    "\n",
    "# R√©-ordonner pour mettre \"hc\" en premier (si pr√©sent)\n",
    "cols = [\"hc\"] + [c for c in table.columns if c != \"hc\"]\n",
    "table = table[cols]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 7. Affichage ou export\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for disease in table.index.get_level_values(\"disease\").unique():\n",
    "    subt = table.xs(disease, level=\"disease\")\n",
    "    print(f\"\\n===== Disease : {disease} =====\")\n",
    "    print(subt.round(6))        # arrondi pour lisibilit√©\n",
    "    subt.to_csv(os.path.join(ANALYSIS_FOLDER,'DIFF', f\"diff_MAE_{disease}.csv\"))  # Save in the main folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1. Charger le CSV\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "df = mae_compilation_train_all\n",
    "df = df[df[\"method\"] != \"robust_rwp\"]\n",
    "df = df[df[\"method\"] != \"raw\"]\n",
    "\n",
    "meta_cols   = [\"site\", \"method\", \"robust_method\", \"disease\", \"metric\"]\n",
    "bundle_cols = [c for c in df.columns if c not in meta_cols]\n",
    "\n",
    "# Colonnes m√©ta vs. bundles\n",
    "meta_cols   = [\"site\", \"method\", \"robust_method\", \"disease\", \"metric\"]\n",
    "bundle_cols = [c for c in df.columns if c not in meta_cols]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 2. Passer en format ¬´ long ¬ª  ‚Üí 1 ligne = 1 bundle\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "long_df = (\n",
    "    df\n",
    "    .melt(id_vars=meta_cols, value_vars=bundle_cols,\n",
    "          var_name=\"bundle\", value_name=\"mae\")\n",
    ")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 3. Baseline  (NoRobust / No)  -> mae_base\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "base_mask = (long_df[\"method\"] == \"NoRobust\") & (long_df[\"robust_method\"] == \"No\")\n",
    "base_df   = (\n",
    "    long_df[base_mask]\n",
    "    .rename(columns={\"mae\": \"mae_base\"})\n",
    "    .loc[:, [\"disease\", \"site\", \"metric\", \"bundle\", \"mae_base\"]]\n",
    ")\n",
    "\n",
    "# Fusionner pour ajouter la colonne mae_base\n",
    "long_df = long_df.merge(base_df,\n",
    "                        on=[\"disease\", \"site\", \"metric\", \"bundle\"],\n",
    "                        how=\"left\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 4. Diff√©rence bundle-par-bundle\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "long_df[\"diff\"] = long_df[\"mae\"] - long_df[\"mae_base\"]\n",
    "\n",
    "# √âtiquette de m√©thode : ¬´ hc ¬ª ou le robust_method\n",
    "def label(r):\n",
    "    return \"hc\" if (r[\"method\"] == \"hc\" and r[\"robust_method\"] == \"No\") else r[\"robust_method\"]\n",
    "\n",
    "long_df[\"method_label\"] = long_df.apply(label, axis=1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 5. Tableau final  (index = site-metric-bundle, colonnes = m√©thode)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "pivot = (\n",
    "    long_df\n",
    "    .pivot_table(index=[\"disease\", \"site\", \"metric\", \"bundle\"],\n",
    "                 columns=\"method_label\",\n",
    "                 values=\"diff\",\n",
    "                 aggfunc=\"mean\")          # si jamais il y a des doublons\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# Mettre ¬´ hc ¬ª en premier si pr√©sent\n",
    "cols = [\"hc\"] + [c for c in pivot.columns if c != \"hc\"]\n",
    "pivot = pivot[cols]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 6. Afficher / sauver\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for disease in pivot.index.get_level_values(\"disease\").unique():\n",
    "    sub = pivot.xs(disease, level=\"disease\")\n",
    "    print(f\"\\n===== Disease : {disease} =====\")\n",
    "    print(sub.round(6))          # arrondi pour la lisibilit√©\n",
    "    sub.to_csv(os.path.join(ANALYSIS_FOLDER,'DIFF', f\"diff_MAE_per_bundle_{disease}.csv\"))  # Save in the main folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import CellIsRule\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1) Fonctions \"CSV ‚Üí Styler\" et \"CSV ‚Üí Excel\"\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def style_diff_csv(csv_path: str, n_index_cols: int = 3, tol: float = 0.0):\n",
    "    \"\"\"\n",
    "    Charge un CSV pivot√© et renvoie un Styler color√© (affichage Jupyter).\n",
    "    n_index_cols = nb de colonnes d'index (ex.: site, metric, bundle = 3).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, index_col=list(range(n_index_cols)))\n",
    "    return _style_diff_df(df, tol)\n",
    "\n",
    "def excel_diff_csv(csv_path: str, excel_path: str,\n",
    "                   n_index_cols: int = 3, tol: float = 0.0):\n",
    "    \"\"\"\n",
    "    Charge un CSV pivot√© et √©crit un Excel color√©.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, index_col=list(range(n_index_cols)))\n",
    "    _excel_diff_df(df, excel_path, tol)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 2) Impl√©mentations \"bas niveau\" (utilis√©es ci-dessus)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def _style_diff_df(df: pd.DataFrame, tol: float):\n",
    "    hc_present = 'hc' in df.columns\n",
    "\n",
    "    def _row_style(row):\n",
    "        hc_val = row['hc'] if hc_present else np.nan\n",
    "        out = []\n",
    "        for v in row:\n",
    "            if pd.isna(v):\n",
    "                out.append('')\n",
    "            elif v > 0:\n",
    "                out.append('background-color:#ffcccc')\n",
    "            elif hc_present and v <= hc_val + tol:\n",
    "                out.append('background-color:#ccffcc')\n",
    "            else:\n",
    "                out.append('')\n",
    "        return out\n",
    "\n",
    "    return df.style.apply(_row_style, axis=1)\n",
    "\n",
    "def _excel_diff_df(df: pd.DataFrame, path: str, tol: float):\n",
    "    with pd.ExcelWriter(path, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, sheet_name='diff')\n",
    "        ws = writer.sheets['diff']\n",
    "\n",
    "        nrows = df.shape[0] + 1                # + ent√™te\n",
    "        nindex = len(df.index.names)\n",
    "        first_col = 2 + nindex\n",
    "        last_col  = first_col + df.shape[1] - 1\n",
    "\n",
    "        red   = PatternFill(start_color=\"FFFFCCCC\", end_color=\"FFFFCCCC\", fill_type=\"solid\")\n",
    "        green = PatternFill(start_color=\"FFCCFFCC\", end_color=\"FFCCFFCC\", fill_type=\"solid\")\n",
    "\n",
    "        # Rouge: valeur > 0\n",
    "        for col in range(first_col, last_col + 1):\n",
    "            letter = get_column_letter(col)\n",
    "            ws.conditional_formatting.add(\n",
    "                f\"{letter}2:{letter}{nrows}\",\n",
    "                CellIsRule(operator='greaterThan', formula=['0'], fill=red)\n",
    "            )\n",
    "\n",
    "        # Vert: valeur ‚â§ hc + tol\n",
    "        if 'hc' in df.columns:\n",
    "            hc_idx = list(df.columns).index('hc')\n",
    "            hc_letter = get_column_letter(first_col + hc_idx)\n",
    "            for col in range(first_col, last_col + 1):\n",
    "                letter = get_column_letter(col)\n",
    "                formula = [f\"{letter}2<={hc_letter}2+{tol}\"]\n",
    "                ws.conditional_formatting.add(\n",
    "                    f\"{letter}2:{letter}{nrows}\",\n",
    "                    CellIsRule(operator='lessThanOrEqual', formula=formula, fill=green)\n",
    "                )\n",
    "    print(f\"Excel enregistr√© : {path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 3) Exemple d‚Äôutilisation\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the files generated in the last two cells\n",
    "diff_mae_files = [\n",
    "    os.path.join(ANALYSIS_FOLDER,'DIFF', f\"diff_MAE_{disease}.csv\")\n",
    "    for disease in diseases\n",
    "]\n",
    "\n",
    "diff_mae_per_bundle_files = [\n",
    "    os.path.join(ANALYSIS_FOLDER,'DIFF',f\"diff_MAE_per_bundle_{disease}.csv\")\n",
    "    for disease in pivot.index.get_level_values(\"disease\").unique()\n",
    "]\n",
    "\n",
    "# Combine the lists of files\n",
    "generated_files = diff_mae_files + diff_mae_per_bundle_files\n",
    "\n",
    "# Print the list of generated files\n",
    "print(\"Generated files:\")\n",
    "for file in generated_files:\n",
    "    print(file)\n",
    "    styler = style_diff_csv(file, n_index_cols=3, tol=1e-4)\n",
    "    excel_file = file.replace(\".csv\", \"_colored.xlsx\")\n",
    "    excel_diff_csv(file, excel_file, n_index_cols=3, tol=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 2. Helpers\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def _ensure(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "\n",
    "def heatmap_auto(df, methods, out_dir, rows_per_chunk=250):\n",
    "    \"\"\"Cr√©e une ou plusieurs heatmaps robustes.\"\"\"\n",
    "    pivot = df.set_index(\"bundle\")[methods].sort_index()\n",
    "    n_rows = len(pivot)\n",
    "    n_chunks = math.ceil(n_rows / rows_per_chunk)\n",
    "    for i in range(n_chunks):\n",
    "        chunk = pivot.iloc[i*rows_per_chunk:(i+1)*rows_per_chunk]\n",
    "        h = max(4, len(chunk)*0.2)\n",
    "        plt.figure(figsize=(12, h))\n",
    "        sns.heatmap(chunk, cmap=\"RdYlGn_r\", center=0, linewidths=.1)\n",
    "        plt.title(f\"Œî MAE ‚Äì bundles √ó m√©thodes (part {i+1}/{n_chunks})\")\n",
    "        fname = f\"heatmap_part_{i+1:02d}.png\" if n_chunks > 1 else \"heatmap.png\"\n",
    "        plt.savefig(os.path.join(out_dir, fname), dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def boxplot_methods(df, methods, out_dir):\n",
    "    melted = df.melt(id_vars=[\"bundle\"], value_vars=methods,\n",
    "                     var_name=\"method\", value_name=\"diff_mae\")\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    sns.boxplot(data=melted, x=\"method\", y=\"diff_mae\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.axhline(0, ls=\"--\", c=\"grey\")\n",
    "    plt.title(\"Distribution des Œî MAE par m√©thode\")\n",
    "    plt.savefig(os.path.join(out_dir, \"boxplot_methods.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def barchart_mean(df, methods, out_dir):\n",
    "    means = df[methods].mean().sort_values()\n",
    "    means.plot(kind=\"barh\", figsize=(6, max(4, len(means)*.4)))\n",
    "    plt.axvline(0, ls=\"--\", c=\"grey\")\n",
    "    plt.xlabel(\"Œî MAE moyen (n√©gatif = mieux)\")\n",
    "    plt.title(\"Performance moyenne par m√©thode\")\n",
    "    plt.savefig(os.path.join(out_dir, \"barchart_mean.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def radars_per_site(df, methods, out_dir):\n",
    "    sites = df[\"site\"].unique()\n",
    "    n = len(methods)\n",
    "    angles = np.linspace(0, 2*np.pi, n, endpoint=False)\n",
    "    for s in sites:\n",
    "        stats = df[df[\"site\"] == s][methods].mean()\n",
    "        vals = np.concatenate([stats.values, stats.values[:1]])\n",
    "        angs = np.append(angles, angles[0])\n",
    "        fig = plt.figure(figsize=(6, 6))\n",
    "        ax = fig.add_subplot(111, polar=True)\n",
    "        ax.plot(angs, vals, marker=\"o\")\n",
    "        ax.fill(angs, vals, alpha=.25)\n",
    "        ax.set_xticks(angles)\n",
    "        ax.set_xticklabels(methods, size=7)\n",
    "        ax.set_title(f\"Profil Œî MAE ‚Äì {s}\")\n",
    "        plt.savefig(os.path.join(out_dir, f\"radar_{s}.png\"), dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def scatters_raw_vs_method(df, methods, out_dir):\n",
    "    base = \"hc\"\n",
    "    for m in methods:\n",
    "        if m in (\"hc\", base):\n",
    "            continue\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.scatter(df[base], df[m], alpha=.5, s=15)\n",
    "        plt.axhline(0, ls=\"--\", c=\"grey\")\n",
    "        plt.axvline(0, ls=\"--\", c=\"grey\")\n",
    "        plt.xlabel(\"Œî MAE raw\")\n",
    "        plt.ylabel(f\"Œî MAE {m}\")\n",
    "        plt.title(f\"raw vs {m}\")\n",
    "        plt.savefig(os.path.join(out_dir, f\"scatter_raw_vs_{m}.png\"), dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 3. Ex√©cution multi‚Äëdiseases\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "autosplit_rows  = 250\n",
    "for disease in diseases:\n",
    "    csv_path = os.path.join(ANALYSIS_FOLDER, \"DIFF\", f\"diff_MAE_per_bundle_{disease}.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(\"‚ö†Ô∏è  CSV introuvable¬†:\", csv_path)\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    methods = [c for c in df.columns if c not in (\"site\", \"metric\", \"bundle\")]\n",
    "\n",
    "    root = os.path.join(ANALYSIS_FOLDER, \"VIS_OUTPUT\", disease)\n",
    "    heat_dir   = _ensure(os.path.join(root, \"heatmaps\"))\n",
    "    box_dir    = _ensure(os.path.join(root, \"boxplots\"))\n",
    "    bar_dir    = _ensure(os.path.join(root, \"bar_charts\"))\n",
    "    radar_dir  = _ensure(os.path.join(root, \"radars\"))\n",
    "    scatter_dir= _ensure(os.path.join(root, \"scatters\"))\n",
    "\n",
    "    # heatmap_auto(df, methods, heat_dir, rows_per_chunk=autosplit_rows)\n",
    "    boxplot_methods(df, methods, box_dir)\n",
    "    barchart_mean(df, methods, bar_dir)\n",
    "    radars_per_site(df, methods, radar_dir)\n",
    "    scatters_raw_vs_method(df, methods, scatter_dir)\n",
    "\n",
    "    print(f\"‚úÖ¬†{disease}¬†‚Üí graphes dans¬†{os.path.abspath(root)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TOP_N = 5   \n",
    "\n",
    "for disease in diseases:\n",
    "    csv_path = os.path.join(ANALYSIS_FOLDER, \"DIFF\", f\"diff_MAE_per_bundle_{disease}.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(\"‚ö†Ô∏è  CSV introuvable :\", csv_path)\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    methods = [c for c in df.columns if c not in (\"site\", \"metric\", \"bundle\")]\n",
    "\n",
    "    # Reshape longue pour simplifier l'extraction\n",
    "    long = df.melt(id_vars=[\"site\", \"metric\", \"bundle\"], value_vars=methods,\n",
    "                   var_name=\"method\", value_name=\"diff_mae\")\n",
    "\n",
    "    # Garder seulement les cas o√π diff_mae est non‚Äënul / non‚ÄëNaN\n",
    "    long = long.dropna(subset=[\"diff_mae\"])\n",
    "\n",
    "    worst_list = []\n",
    "    for m in methods:\n",
    "        top_bad = long[long[\"method\"] == m].nlargest(TOP_N, \"diff_mae\")\n",
    "        worst_list.append(top_bad)\n",
    "\n",
    "    worst_df = pd.concat(worst_list, ignore_index=True)\n",
    "\n",
    "    # Tri final pour lisibilit√©: par m√©thode puis diff_mae d√©croissant\n",
    "    worst_df = worst_df.sort_values([\"method\", \"diff_mae\"], ascending=[True, False])\n",
    "\n",
    "    out_csv = os.path.join(ANALYSIS_FOLDER, f\"{disease}_worst_cases_top{TOP_N}.csv\")\n",
    "    worst_df.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"‚úÖ {disease}: CSV des {TOP_N} pires cas par m√©thode ‚Üí {out_csv}\")\n",
    "    display_cols = [\"method\", \"diff_mae\", \"site\", \"metric\", \"bundle\"]\n",
    "    print(worst_df[display_cols])  # aper√ßu rapide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # TEST ADD BIAIS\n",
    "# # Split the data into training and testing sets\n",
    "# directory = os.path.join(MAINFOLDER, \"testBiais\")\n",
    "# os.makedirs(directory, exist_ok=True)\n",
    "# train_df, test_df = split_train_test(CAMCAN, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Generate biased data\n",
    "# # Save the original non-biased data to temporary files\n",
    "# temp_train_file_original = os.path.join(directory, \"temp_train_original.csv\")\n",
    "# temp_test_file_original = os.path.join(directory, \"temp_test_original.csv\")\n",
    "# train_df.to_csv(temp_train_file_original, index=False)\n",
    "# test_df.to_csv(temp_test_file_original, index=False)\n",
    "\n",
    "# # Generate biased data\n",
    "# sampled_df_biaied, test_df_biaised, gammas,deltas, ruffles= generate_biaised_data(train_df, test_df)\n",
    "\n",
    "# # Save the biased data to temporary files\n",
    "# temp_train_file = os.path.join(directory, \"temp_train_biased.csv\")\n",
    "# temp_test_file = os.path.join(directory, \"temp_test_biased.csv\")\n",
    "# sampled_df_biaied.to_csv(temp_train_file, index=False)\n",
    "# test_df_biaised.to_csv(temp_test_file, index=False)\n",
    "\n",
    "# # Run the combat_visualize_data script\n",
    "# outname_train = os.path.join(\"visualize_train\")\n",
    "# cmd = (\n",
    "#     \"scripts/combat_visualize_data.py\"\n",
    "#     + \" \"\n",
    "#     + temp_train_file_original\n",
    "#     + \" \"\n",
    "#     + temp_train_file\n",
    "#     + \" --out_dir \"\n",
    "#     + directory\n",
    "#     + \" --outname \"\n",
    "#     + outname_train\n",
    "#     + \" -f\"\n",
    "#     + \" --bundles all\"\n",
    "# )\n",
    "# subprocess.call(cmd, shell=True)\n",
    "\n",
    "# # Display gammas and deltas along with their mean and standard deviation\n",
    "# print(\"Gammas:\", gammas)\n",
    "# print(\"Deltas:\", deltas)\n",
    "# gammas = list(gammas.values())\n",
    "# deltas = list(deltas.values())\n",
    "# print(\"\\nGamma Statistics:\")\n",
    "# print(f\"Mean: {np.mean(gammas)}, Std: {np.std(gammas)}\")\n",
    "\n",
    "# print(\"\\nDelta Statistics:\")\n",
    "# print(f\"Mean: {np.mean(deltas)}, Std: {np.std(deltas)}\")\n",
    "# print(\"Ruffles:\", ruffles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST Powerpoint generation\n",
    "# d  = os.path.join(MAINFOLDER, robust_method, \"adni_100_Philips_3T\")\n",
    "# create_presentation(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST the sample_patients function with compilation data data\n",
    "# sampled_df = sample_patients(COMPILATION, num_patients=100, disease_ratio=0.5)\n",
    "# print(sampled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_metrics(\"ROBUST/IQR/50_30/0/\", \"50_patients_30_percent_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the dists_compilation and metrics_compilation CSV files\n",
    "# dists_compilation_path = os.path.join(directory, \"dists_compilation.csv\")\n",
    "# metrics_compilation_path = os.path.join(directory, \"metrics_compilation.csv\")\n",
    "\n",
    "# dists_compilation = pd.read_csv(dists_compilation_path)\n",
    "# metrics_compilation = pd.read_csv(metrics_compilation_path)\n",
    "\n",
    "# # Change the site column\n",
    "# dists_compilation['site'] = dists_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "# metrics_compilation['site'] = metrics_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "\n",
    "# # Display the means by site\n",
    "# dists_means_by_site = dists_compilation.groupby(['site','comparaison']).mean()\n",
    "# metrics_means_by_site = metrics_compilation.groupby('site').mean()\n",
    "\n",
    "# print(dists_means_by_site)\n",
    "# print(metrics_means_by_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FIX METRICS COMPILATION\n",
    "# directory = os.path.join(MAINFOLDER, robust_method)\n",
    "# df = pd.read_csv(os.path.join(directory, \"metrics_compilation.csv\"))\n",
    "\n",
    "# # Group by the site\n",
    "# grouped = df.groupby('site')\n",
    "\n",
    "# # Process each site\n",
    "# cleaned_dfs = []\n",
    "# for site, group in grouped:\n",
    "#     # Reset index for easier manipulation\n",
    "#     group = group.reset_index(drop=True)\n",
    "    \n",
    "#     # # The first row is the \"bundle row\" (new column names)\n",
    "#     # new_columns = group.iloc[0].values  # Extract column names from the first row\n",
    "#     # new_columns[-1] = 'site'\n",
    "#     # group = group.iloc[1:]  # Remove the first row\n",
    "    \n",
    "#     # # Assign new column names\n",
    "#     # group.columns = new_columns\n",
    "    \n",
    "#     # # Sort the columns alphabetically (excluding 'site')\n",
    "#     # sorted = group.sort_index(axis=1)\n",
    "#     # Add a new column 'nomm' with the value indicating the metric for each row\n",
    "#     metrics = ['tp', 'fp', 'tn', 'fn', 'precision', 'recall', 'taux_faux_positifs', 'f1_score']\n",
    "#     group['metric'] = metrics\n",
    "    \n",
    "#     # # Append the cleaned DataFrame for this site\n",
    "#     cleaned_dfs.append(group)\n",
    "\n",
    "# # Concatenate all cleaned DataFrames\n",
    "# final_df = pd.concat(cleaned_dfs, ignore_index=True)\n",
    "\n",
    "# # Save or display the result\n",
    "# final_df.to_csv(os.path.join(directory, \"metrics_compilation.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAL SITES\n",
    "# directory = os.path.join(MAINFOLDER, robust_method)\n",
    "# raw_directory = os.path.join(RAWFOLDER, site_group)\n",
    "# for filename in sorted(os.listdir(raw_directory)):\n",
    "#     f = os.path.join(raw_directory, filename)\n",
    "#     # checking if it is a file\n",
    "#     if os.path.isfile(f):\n",
    "#         analyse_site(f, robust_method, directory)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
