{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Générer les sites synthétiques (MLP et harmonisation)\n",
    "\n",
    "Ce notebook produit des sites synthétiques à partir des compilations MLP et harmonisées en utilisant `robust_evaluation_tools.synthectic_sites_generations.generate_sites`.\n",
    "Chaque configuration crée 12 dossiers (3 tailles d'échantillon × 2 ratios de malades × 2 répétitions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports et configuration\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path('.').resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# Décommente si les dépendances manquent\n",
    "# !pip install joblib scikit-learn\n",
    "\n",
    "from robust_evaluation_tools.synthectic_sites_generations import generate_sites\n",
    "\n",
    "try:\n",
    "    import joblib  # noqa: F401\n",
    "    import sklearn  # noqa: F401\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\"Installe joblib et scikit-learn (pip install joblib scikit-learn)\") from exc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres communs (12 dossiers par dataset)\n",
    "sample_sizes = [100]  # 1 taille\n",
    "disease_ratios = [0.03, 0.1, 0.3, 0.5, 0.7, 0.8]    # 2 ratios (0% et 50% malades)\n",
    "num_tests = 40                  # 2 répétitions => 3*2*2 = 12 dossiers\n",
    "synthetic_version = 'v1'       # 'v1' ou 'v2' selon le pipeline\n",
    "disease = 'ALL'           # 'ALL', 'ASTMIX' ou une maladie précise (ex: 'AD')\n",
    "fixed_bias = False\n",
    "n_jobs = -1                     # -1 pour tous les coeurs\n",
    "\n",
    "camcan_hc_only = True         # Filtrer les HC hors CamCAN\n",
    "include_camcan = True        # Inclure les compilations avec CamCAN\n",
    "compilation_suffix = '.with_camcan' if include_camcan else ''\n",
    "\n",
    "# Choix de l'augmentation (None pour utiliser les données originales, ou un entier -> *_AUG_{n})\n",
    "augmentation_copies = 5\n",
    "augmentation_suffix = f\"_AUG_{augmentation_copies}\" if augmentation_copies else ''\n",
    "\n",
    "def build_dataset_config(base_name: str):\n",
    "    input_dir = Path(f\"DONNES/processed/compilation/classic/{base_name}{augmentation_suffix}\")\n",
    "    return {\n",
    "        'name': f\"{base_name}{augmentation_suffix}\",\n",
    "        'data_path': input_dir / f\"compilation.all_metrics{compilation_suffix}.csv.gz\",\n",
    "        'output_dir': Path(f\"DONNES/processed/synthetic_sites/{base_name}{augmentation_suffix}/{disease}\"),\n",
    "    }\n",
    "\n",
    "datasets = [\n",
    "    build_dataset_config('mlp'),\n",
    "    build_dataset_config('harmonized'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aperçu des datasets (premières lignes)\n",
    "for cfg in datasets:\n",
    "    print(f\"Dataset: {cfg['name']} -> {cfg['data_path']}\")\n",
    "    display(pd.read_csv(cfg['data_path']).head(3))\n",
    "    print('-'*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération des sites synthétiques pour chaque dataset\n",
    "for cfg in datasets:\n",
    "    cfg['output_dir'].mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\\nGénération pour {cfg['name']} -> {cfg['output_dir']}\\n\")\n",
    "    generate_sites(\n",
    "        sample_sizes=sample_sizes,\n",
    "        disease_ratios=disease_ratios,\n",
    "        num_tests=num_tests,\n",
    "        directory=str(cfg['output_dir']),\n",
    "        data_path=str(cfg['data_path']),\n",
    "        SYNTHETIC_SITES_VERSION=synthetic_version,\n",
    "        disease=disease,\n",
    "        camcan_hc_only=camcan_hc_only,\n",
    "        fixed_biais=fixed_bias,\n",
    "        n_jobs=n_jobs,\n",
    "    )\n",
    "    print(f\"Terminé : {cfg['output_dir'].resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résumé des dossiers et fichiers générés\n",
    "from collections import Counter\n",
    "\n",
    "for cfg in datasets:\n",
    "    generated_dirs = sorted([p for p in cfg['output_dir'].glob('*') if p.is_dir()])\n",
    "    print(f\"\\n{cfg['name']} -> {len(generated_dirs)} dossiers générés (attendu: 12)\")\n",
    "    for d in generated_dirs:\n",
    "        csv_count = len(list(d.rglob('*.csv')))\n",
    "        print(f\"  {d.relative_to(PROJECT_ROOT)} : {csv_count} fichiers csv\")\n",
    "    sample_csvs = sorted(cfg['output_dir'].rglob('*.csv'))\n",
    "    if sample_csvs:\n",
    "        print(f\"Aperçu du premier fichier pour {cfg['name']}: {sample_csvs[0]}\")\n",
    "        display(pd.read_csv(sample_csvs[0]).head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
